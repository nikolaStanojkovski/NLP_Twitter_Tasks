{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data_Science_Project_186007_181076.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "SIbwCS7Mo_b2",
        "y1nEl3edx8a4",
        "P_kyOh7AUBTk",
        "Ai9ELGpiWqs0",
        "s-decMxkVNYj",
        "AC-fYAW_ZmE7",
        "d8fCzZKGda2H",
        "ap2xGAtcdiY8",
        "E5O3wHFVdoRa",
        "ErQuJFSWd0Ko",
        "_1XkC4CBd9Fc",
        "J1JE9_DxeCx8",
        "J-8VM72V2jKG",
        "QZTKLSWfgxLF",
        "AWlLkWbzKOag",
        "j13iiBXpJbRQ",
        "MxWeqrlmJ-RN",
        "-gLSNYQLKadw",
        "1QyVcEcHKoJa",
        "c8OSm-kILM_o",
        "Tya-cB0ALWYz",
        "ixqJB3n7LhRQ",
        "ffYP7EOMLsUA",
        "ezeIMHk72uxe",
        "eBFKAhM1jUXD",
        "46o3edJ7jYz7",
        "QYzYCln1k0eC",
        "hCmUjkJGlcCf",
        "-rGaE5Xslr_C",
        "CSlZkHvvlu9t",
        "HAX-HJz0l6TM",
        "cJ_RrFNpmCTS",
        "F7oMAhaNmQW8",
        "EzqMVclMmYry",
        "Y0TB9jlC2z70",
        "_fGeH8qR4ftY",
        "J19u8yXY4o95",
        "eUQGTNTs4sg_",
        "amIERp164v2J",
        "LWROiXO767wx",
        "MdvDi22-7DcR",
        "fb-GWEcJ7PwN",
        "tcPPG4Eg7d5n",
        "iLZEC7Q17oMA",
        "-dzIlycq7uPt",
        "SpgPcWXF25Fm",
        "0LfTxhjaOfVL",
        "S3O0y5qmO1Gz",
        "6IKc_w0OQUVQ",
        "uPKq_lPaQ6vR",
        "i90A5mgfRMSD",
        "wFgEdNDBRVxD",
        "vmAtwXIbRf9x",
        "Ry_IorLNRnbi",
        "lhvrzsWjR4Bn",
        "bk8ZTQqaRyfr",
        "1ZpYUuLN29vk",
        "hTQNqhl4xjOj",
        "jYl4AWPcxnOS",
        "FpVwEyd55c2U",
        "fqD0_91o-CWt",
        "nVfeL4QF-OAD",
        "gWPQd9UJ-Tvv",
        "6vbFAL6s-ecD",
        "3C8d5-V8eOx8",
        "XRV0Dxv9-6Zv",
        "Y6MckM5k3CCd"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f185c8c8a5a04d2f89e62097bfa2df8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_84e59d0f34b64d919d9f77501126a5ed",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_bdcafa65546d4ba4874001211444375c",
              "IPY_MODEL_4ca01ce18c624c10817836c3428f6ad8"
            ]
          }
        },
        "84e59d0f34b64d919d9f77501126a5ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bdcafa65546d4ba4874001211444375c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_acba8e00bcb34dbd9c2be7196c847ee3",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 898823,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 898823,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_987542270ce94752bd6a5941a67d5bf9"
          }
        },
        "4ca01ce18c624c10817836c3428f6ad8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_55c8ec4f0a3249e5863e43147345f7e1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 899k/899k [00:00&lt;00:00, 1.14MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b09be2f9c1fa4cd4aa33c8b0364d6118"
          }
        },
        "acba8e00bcb34dbd9c2be7196c847ee3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "987542270ce94752bd6a5941a67d5bf9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "55c8ec4f0a3249e5863e43147345f7e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b09be2f9c1fa4cd4aa33c8b0364d6118": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4c75ed6cf56e4fdf9465457b16a5f74b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9a32bfb7053a48e6a7ac80e6f0db2f3b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5cea3a21f3a34f1d826aba5561f7c6e6",
              "IPY_MODEL_996bfe27c147491ca33709cc75202b0c"
            ]
          }
        },
        "9a32bfb7053a48e6a7ac80e6f0db2f3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5cea3a21f3a34f1d826aba5561f7c6e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1e221cecf8c6401a833cfc46e7a90c40",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 456318,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 456318,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_92f220f133324a9889b58e2a8b587767"
          }
        },
        "996bfe27c147491ca33709cc75202b0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_05c8629af3904ce49f680e7a5a9eacbc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 456k/456k [00:01&lt;00:00, 250kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b1502be8c17a403690418b751c58e72b"
          }
        },
        "1e221cecf8c6401a833cfc46e7a90c40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "92f220f133324a9889b58e2a8b587767": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "05c8629af3904ce49f680e7a5a9eacbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b1502be8c17a403690418b751c58e72b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3ae1f5af37e44a608688d85c025e7269": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_44f83a80734c42e995192ab1723a0891",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d18b3c33fbda4b90b6dcc13c9e6257b7",
              "IPY_MODEL_ac83c700a1b94cb58bbdcc577d53f21f"
            ]
          }
        },
        "44f83a80734c42e995192ab1723a0891": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d18b3c33fbda4b90b6dcc13c9e6257b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f55f5ac698c4418eb0854a70ee511666",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1355863,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1355863,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b60146833b014a8f8fcd821e0254e96b"
          }
        },
        "ac83c700a1b94cb58bbdcc577d53f21f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_11dfb73cbf93465398672b914c221ef1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 3.09MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fda51457ad354c3e8e2af81fd201e96d"
          }
        },
        "f55f5ac698c4418eb0854a70ee511666": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b60146833b014a8f8fcd821e0254e96b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "11dfb73cbf93465398672b914c221ef1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fda51457ad354c3e8e2af81fd201e96d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fbbbf2241b1a4d08af9bac7c67820061": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_aa3e8e1e930e4a45b2dd56e974ceb180",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d0be76c18ec2478586a065ffccd083ce",
              "IPY_MODEL_884c0ec6b37a4ef1ad40a03b5fd13a71"
            ]
          }
        },
        "aa3e8e1e930e4a45b2dd56e974ceb180": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d0be76c18ec2478586a065ffccd083ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a39b640e30ba47f8a51602fee2c47390",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 482,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 482,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c3243ebefe094b92aa4f787d14ad7243"
          }
        },
        "884c0ec6b37a4ef1ad40a03b5fd13a71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9b10037ad3dd455faba447c5f856522e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 482/482 [00:28&lt;00:00, 16.8B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f5cf6abd5e4746d493d46ca118c7d2b7"
          }
        },
        "a39b640e30ba47f8a51602fee2c47390": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c3243ebefe094b92aa4f787d14ad7243": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9b10037ad3dd455faba447c5f856522e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f5cf6abd5e4746d493d46ca118c7d2b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4c8caeef507c49b19f28745ae735cba3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b80118f1030945f6bced3a7b80adc59c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d81fb0f4d6e044a197cf04d2f28cc230",
              "IPY_MODEL_cf10b233005e42379f8b10f3eae16621"
            ]
          }
        },
        "b80118f1030945f6bced3a7b80adc59c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d81fb0f4d6e044a197cf04d2f28cc230": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_71e5635daf614d37b4ceb7272256b907",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1425941629,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1425941629,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d6cd625203074a228783a50e2bd5d087"
          }
        },
        "cf10b233005e42379f8b10f3eae16621": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_74caa60d16ef4643ae9365575773acb4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.43G/1.43G [00:26&lt;00:00, 53.6MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_55c4c800234e4cedae10c023066db1d1"
          }
        },
        "71e5635daf614d37b4ceb7272256b907": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d6cd625203074a228783a50e2bd5d087": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "74caa60d16ef4643ae9365575773acb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "55c4c800234e4cedae10c023066db1d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "45b10068935e4d5ba16d976293280912": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e53c0c747d6b400792482f44dca7fa78",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ef7bed9506f0461a9b37e905a95da7c2",
              "IPY_MODEL_49fdac4886ca466293ae6aa7b82f95b4"
            ]
          }
        },
        "e53c0c747d6b400792482f44dca7fa78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ef7bed9506f0461a9b37e905a95da7c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_52360d705cbf4eabbf1b7e84ca8eb227",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ed9eba1d0a494b84b13148c9df4a4f79"
          }
        },
        "49fdac4886ca466293ae6aa7b82f95b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_31cd5abf7e324f23ad5a38a8be26e466",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1/1 [3:12:04&lt;00:00, 11524.44s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9d800e2864a543799e02ec203c58820f"
          }
        },
        "52360d705cbf4eabbf1b7e84ca8eb227": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ed9eba1d0a494b84b13148c9df4a4f79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "31cd5abf7e324f23ad5a38a8be26e466": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9d800e2864a543799e02ec203c58820f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f8dab7ab0a3e4b24a94f5e17d32fe6b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_93bcb4fcca704ab98f3d0d1aa2cfa18d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b699e240811944a4a50173a5f5a7a55b",
              "IPY_MODEL_a816b669176d4221be430792385ce629"
            ]
          }
        },
        "93bcb4fcca704ab98f3d0d1aa2cfa18d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b699e240811944a4a50173a5f5a7a55b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c0433edf6d1d40868b3d87138e02550a",
            "_dom_classes": [],
            "description": "Epoch 1: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 7560,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 7560,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_310258bd358b43a2857e5d13524b9035"
          }
        },
        "a816b669176d4221be430792385ce629": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_77692829f0ce4e8382d57b68135ad5f8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 7560/7560 [3:02:06&lt;00:00,  1.44s/it, training_loss=0.717]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5c00917228a249e897dcd0cbba9e810c"
          }
        },
        "c0433edf6d1d40868b3d87138e02550a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "310258bd358b43a2857e5d13524b9035": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "77692829f0ce4e8382d57b68135ad5f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5c00917228a249e897dcd0cbba9e810c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "42c7363e0bb1469b9dfdc983080cc1b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f1a9095b789c48978a25c68bbb8e259d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f382c70ca8a14717884eabe2b02026c5",
              "IPY_MODEL_ee96c6e1d50040928ba604f0f5e9ae6a"
            ]
          }
        },
        "f1a9095b789c48978a25c68bbb8e259d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f382c70ca8a14717884eabe2b02026c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d6d29a939a6547c88154a8fbdff609b8",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 334,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 334,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5a366921b9a549d2a783968baa53f701"
          }
        },
        "ee96c6e1d50040928ba604f0f5e9ae6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_eb00cccdbb6a4fe1bb932ad0adfcb015",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 334/334 [09:58&lt;00:00,  1.79s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_58a6c3962b5446d3b1ecb99547908466"
          }
        },
        "d6d29a939a6547c88154a8fbdff609b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5a366921b9a549d2a783968baa53f701": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "eb00cccdbb6a4fe1bb932ad0adfcb015": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "58a6c3962b5446d3b1ecb99547908466": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIbwCS7Mo_b2"
      },
      "source": [
        "# <font size=6> **Data Science Project by Nikola Stanojkovski && Ines Lesnovska** </font>\n",
        "\n",
        "<font color = 'Orange' size = 4 > Seven NLP Tasks With Twitter Datasets </font>\n",
        "\n",
        "<br/>\n",
        "\n",
        "# <font size=6> **Проект по \"Вовед во науката за податоци\" изработен од Никола Станојковски и Инес Лесновска** </font>\n",
        "\n",
        "<font color = 'Orange' size = 4 > Седум задачи за обработка на природен јазик со податоци од твитови </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IILujlbyiJN"
      },
      "source": [
        "## <font color=\"Orange\" size=5> Source: https://www.kaggle.com/arashnic/7-nlp-tasks-with-tweets </font>\n",
        "\n",
        "### <font color=\"Orange\" size=4> Context </font>\n",
        "\n",
        "<font color=\"blue\" size=3>The experimental landscape in natural language processing for social media is too fragmented. Each year, new shared tasks and datasets are proposed, ranging from classics like sentiment analysis to irony detection or emoji prediction. Therefore, it is unclear what the current state of the art is, as there is\n",
        "no standardized evaluation protocol, neither a strong set of baselines trained on such domainspecific data. The propose of this dataset is presenting evaluation consisting of seven heterogeneous Twitter-specific classification tasks.</font>\n",
        "\n",
        "### <font color=\"Orange\" size=4> Content </font>\n",
        "\n",
        "<font color=\"blue\" size=3>\n",
        "This dattaset consists of seven heterogenous tasks in Twitter, all framed as multi-class tweet classification. Each dataset presented in the same format and with fixed training, validation and test splits.</font>\n",
        "\n",
        "### <font color=\"Orange\" size=4> Acknowledgements </font>\n",
        "\n",
        "<font color=\"blue\" size=3>\n",
        "Unified Benchmark and Comparative Evaluation for Tweet Classification:\n",
        "\n",
        "  - Francesco Barbieri♣ Jose Camacho-Collados†\n",
        "  - Leonardo Neves♣ Luis Espinosa-Anke† </font>\n",
        "\n",
        "### <font color=\"Orange\" size=4>Inspiration </font>\n",
        "\n",
        "<ul>\n",
        "<li><font color=\"Orange\">Emotion Recognition</font></li>\n",
        "<li><font color=\"Orange\">Emoji Prediction</font></li>\n",
        "<li><font color=\"Orange\">Irony Detection</font></li>\n",
        "<li><font color=\"Orange\">Hate Speech Detection</font></li>\n",
        "<li><font color=\"Orange\">Offensive Language Identification</font></li>\n",
        "<li><font color=\"Orange\">Sentiment Analysis</font></li>\n",
        "<li><font color=\"Orange\">Stance Detection</font></li>\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exMjbsUezr1I"
      },
      "source": [
        "## <font color=\"Blue\" size=5> For every particular NLP task given below, the most appropriate model that gives the best results has been chosen after the trial of many </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSwag5Eh0SgI"
      },
      "source": [
        "## <font color=\"Blue\" size=5> For every particular NLP task given below, the most appropriate evaluation metrics have been chosen </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1nEl3edx8a4"
      },
      "source": [
        "# **Emotion Recognition**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2BUVpQTW93N"
      },
      "source": [
        "<font color=\"Orange\" size=5> Using a BERT Pretrained model: 'bert-base-cased' </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_kyOh7AUBTk"
      },
      "source": [
        "##  Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7H8HJc-7x7pe",
        "outputId": "4b5f1fd6-c8fa-4de5-bda3-9f2958df423f"
      },
      "source": [
        "\n",
        " !pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.5.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.10.1)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24FLVBO-VHqn",
        "outputId": "720b35d4-eb8f-4eeb-95d6-ef85d6e50606"
      },
      "source": [
        "pip install pytorch_transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch_transformers in /usr/local/lib/python3.7/dist-packages (1.2.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (1.19.5)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (1.8.1+cu101)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (2.23.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (1.17.54)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (0.1.95)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (4.41.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (0.0.45)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.0->pytorch_transformers) (3.7.4.3)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_transformers) (2020.12.5)\n",
            "Requirement already satisfied: botocore<1.21.0,>=1.20.54 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch_transformers) (1.20.54)\n",
            "Requirement already satisfied: s3transfer<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch_transformers) (0.4.0)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch_transformers) (0.10.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch_transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch_transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch_transformers) (7.1.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.21.0,>=1.20.54->boto3->pytorch_transformers) (2.8.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ai9ELGpiWqs0"
      },
      "source": [
        "##  Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "wreo2QXGWtrs",
        "outputId": "c5803f01-5da2-4dac-d6e9-8bca42f777f8"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Transforming the mapping into a .csv file\n",
        "\n",
        "with open('./source/emotion/mapping.txt') as file:\n",
        "  matrix = []\n",
        "  for line in file:\n",
        "    splits = line.split('\\t')\n",
        "    row = {}\n",
        "    row['Code'] = splits[0]\n",
        "    row['Emotion'] = splits[1].rstrip()\n",
        "    matrix.append(row)\n",
        "  mapping = pd.DataFrame(matrix)\n",
        "\n",
        "mapping.to_csv('./source/emotion/mapping.csv', index=False)\n",
        "mapping"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Code</th>\n",
              "      <th>Emotion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>optimism</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Code   Emotion\n",
              "0    0     anger\n",
              "1    1       joy\n",
              "2    2  optimism\n",
              "3    3   sadness"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "v_KfUp5yXsTH",
        "outputId": "3c4a4c64-56d5-4249-9d7c-cc3060a00a9a"
      },
      "source": [
        "# Transforming the .txt files and creating the train dataset\n",
        "\n",
        "with open('./source/emotion/train_text.txt') as train_text, open('./source/emotion/train_labels.txt') as train_labels:\n",
        "  matrix = []\n",
        "  emotions = pd.read_csv('./source/emotion/mapping.csv')\n",
        "  for text, label in zip(train_text, train_labels):\n",
        "    emotion = emotions.loc[emotions['Code'] == int(label), 'Emotion'].item()\n",
        "    row = {}\n",
        "    row['text'] = text.rstrip()\n",
        "    row['emotion'] = int(label)\n",
        "    row['target'] = emotion\n",
        "    matrix.append(row)\n",
        "  train = pd.DataFrame(matrix)\n",
        "\n",
        "train.to_csv('./source/emotion/train.csv', index=False)\n",
        "train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>emotion</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>“Worry is a down payment on a problem you may ...</td>\n",
              "      <td>2</td>\n",
              "      <td>optimism</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>My roommate: it's okay that we can't spell bec...</td>\n",
              "      <td>0</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>No but that's so cute. Atsu was probably shy a...</td>\n",
              "      <td>1</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Rooneys fucking untouchable isn't he? Been fuc...</td>\n",
              "      <td>0</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>it's pretty depressing when u hit pan on ur fa...</td>\n",
              "      <td>3</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3252</th>\n",
              "      <td>I get discouraged because I try for 5 fucking ...</td>\n",
              "      <td>3</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3253</th>\n",
              "      <td>The @user are in contention and hosting @user ...</td>\n",
              "      <td>3</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3254</th>\n",
              "      <td>@user @user @user @user @user as a fellow UP g...</td>\n",
              "      <td>0</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3255</th>\n",
              "      <td>You have a #problem? Yes! Can you do #somethin...</td>\n",
              "      <td>0</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3256</th>\n",
              "      <td>@user @user i will fight this guy! Don't insul...</td>\n",
              "      <td>0</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3257 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text  emotion    target\n",
              "0     “Worry is a down payment on a problem you may ...        2  optimism\n",
              "1     My roommate: it's okay that we can't spell bec...        0     anger\n",
              "2     No but that's so cute. Atsu was probably shy a...        1       joy\n",
              "3     Rooneys fucking untouchable isn't he? Been fuc...        0     anger\n",
              "4     it's pretty depressing when u hit pan on ur fa...        3   sadness\n",
              "...                                                 ...      ...       ...\n",
              "3252  I get discouraged because I try for 5 fucking ...        3   sadness\n",
              "3253  The @user are in contention and hosting @user ...        3   sadness\n",
              "3254  @user @user @user @user @user as a fellow UP g...        0     anger\n",
              "3255  You have a #problem? Yes! Can you do #somethin...        0     anger\n",
              "3256  @user @user i will fight this guy! Don't insul...        0     anger\n",
              "\n",
              "[3257 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "gf_gHEr3YBtM",
        "outputId": "02b31506-0578-4dba-9260-3a59bb7e18ee"
      },
      "source": [
        "# Transforming the .txt files and creating the test dataset\n",
        "\n",
        "with open('./source/emotion/test_text.txt') as test_text, open('./source/emotion/test_labels.txt') as test_labels:\n",
        "  matrix = []\n",
        "  emotions = pd.read_csv('./source/emotion/mapping.csv')\n",
        "  for text, label in zip(test_text, test_labels):\n",
        "    emotion = emotions.loc[emotions['Code'] == int(label), 'Emotion'].item()\n",
        "    row = {}\n",
        "    row['text'] = text.rstrip()\n",
        "    row['emotion'] = int(label)\n",
        "    row['target'] = emotion\n",
        "    matrix.append(row)\n",
        "  test = pd.DataFrame(matrix)\n",
        "\n",
        "test.to_csv('./source/emotion/test.csv', index=False)\n",
        "test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>emotion</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>#Deppression is real. Partners w/ #depressed p...</td>\n",
              "      <td>3</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@user Interesting choice of words... Are you c...</td>\n",
              "      <td>0</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>My visit to hospital for care triggered #traum...</td>\n",
              "      <td>3</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@user Welcome to #MPSVT! We are delighted to h...</td>\n",
              "      <td>1</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What makes you feel #joyful?</td>\n",
              "      <td>1</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1416</th>\n",
              "      <td>I need a sparkling bodysuit . No occasion. Jus...</td>\n",
              "      <td>1</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1417</th>\n",
              "      <td>@user I've finished reading it; simply mind-bl...</td>\n",
              "      <td>3</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1418</th>\n",
              "      <td>shaft abrasions from panties merely shifted to...</td>\n",
              "      <td>0</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1419</th>\n",
              "      <td>All this fake outrage. Y'all need to stop 🤣</td>\n",
              "      <td>0</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1420</th>\n",
              "      <td>Would be ever so grateful if you could record ...</td>\n",
              "      <td>1</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1421 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text  emotion   target\n",
              "0     #Deppression is real. Partners w/ #depressed p...        3  sadness\n",
              "1     @user Interesting choice of words... Are you c...        0    anger\n",
              "2     My visit to hospital for care triggered #traum...        3  sadness\n",
              "3     @user Welcome to #MPSVT! We are delighted to h...        1      joy\n",
              "4                          What makes you feel #joyful?        1      joy\n",
              "...                                                 ...      ...      ...\n",
              "1416  I need a sparkling bodysuit . No occasion. Jus...        1      joy\n",
              "1417  @user I've finished reading it; simply mind-bl...        3  sadness\n",
              "1418  shaft abrasions from panties merely shifted to...        0    anger\n",
              "1419        All this fake outrage. Y'all need to stop 🤣        0    anger\n",
              "1420  Would be ever so grateful if you could record ...        1      joy\n",
              "\n",
              "[1421 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "TKfZ2bp-YGfG",
        "outputId": "703cba1e-edca-4454-e67b-8bc759959653"
      },
      "source": [
        "# Transforming the .txt files and creating the validation dataset\n",
        "\n",
        "with open('./source/emotion/val_text.txt') as val_text, open('./source/emotion/val_labels.txt') as val_labels:\n",
        "  matrix = []\n",
        "  emotions = pd.read_csv('./source/emotion/mapping.csv')\n",
        "  for text, label in zip(val_text, val_labels):\n",
        "    emotion = emotions.loc[emotions['Code'] == int(label), 'Emotion'].item()\n",
        "    row = {}\n",
        "    row['text'] = text.rstrip()\n",
        "    row['emotion'] = int(label)\n",
        "    row['target'] = emotion\n",
        "    matrix.append(row)\n",
        "  val = pd.DataFrame(matrix)\n",
        "\n",
        "val.to_csv('./source/emotion/val.csv', index=False)\n",
        "val"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>emotion</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@user @user Oh, hidden revenge and anger...I r...</td>\n",
              "      <td>0</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>if not then #teamchristine bc all tana has don...</td>\n",
              "      <td>0</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Hey @user #Fields in #skibbereen give your onl...</td>\n",
              "      <td>0</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Why have #Emmerdale had to rob #robron of havi...</td>\n",
              "      <td>0</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@user I would like to hear a podcast of you go...</td>\n",
              "      <td>0</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>369</th>\n",
              "      <td>@user @user If #trump #whitehouse aren't held ...</td>\n",
              "      <td>0</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>370</th>\n",
              "      <td>@user Which #chutiya #producer #invested in #c...</td>\n",
              "      <td>0</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>371</th>\n",
              "      <td>Russia story will infuriate Trump today. Media...</td>\n",
              "      <td>0</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>372</th>\n",
              "      <td>Shit getting me irritated 😠</td>\n",
              "      <td>0</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>373</th>\n",
              "      <td>@user @user If this didn't make me so angry, I...</td>\n",
              "      <td>0</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>374 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  text  emotion target\n",
              "0    @user @user Oh, hidden revenge and anger...I r...        0  anger\n",
              "1    if not then #teamchristine bc all tana has don...        0  anger\n",
              "2    Hey @user #Fields in #skibbereen give your onl...        0  anger\n",
              "3    Why have #Emmerdale had to rob #robron of havi...        0  anger\n",
              "4    @user I would like to hear a podcast of you go...        0  anger\n",
              "..                                                 ...      ...    ...\n",
              "369  @user @user If #trump #whitehouse aren't held ...        0  anger\n",
              "370  @user Which #chutiya #producer #invested in #c...        0  anger\n",
              "371  Russia story will infuriate Trump today. Media...        0  anger\n",
              "372                        Shit getting me irritated 😠        0  anger\n",
              "373  @user @user If this didn't make me so angry, I...        0  anger\n",
              "\n",
              "[374 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-decMxkVNYj"
      },
      "source": [
        "##  Loading Tokenizer and Encoding our Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94kyQ0B-VOPr"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "# Importing the tokenizer for the model\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\n",
        "    'bert-base-cased',\n",
        "    do_lower_case=True\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdhdZfYXZFxd",
        "outputId": "dde56d68-dd2b-42d9-d146-c87bacd0a50f"
      },
      "source": [
        "import torch\n",
        "\n",
        "# Encoding the data\n",
        "\n",
        "encoded_data_train = tokenizer.batch_encode_plus(\n",
        "    train.text.values,\n",
        "    add_special_tokens=True,\n",
        "    return_attention_mask=True,\n",
        "    pad_to_max_length=True,\n",
        "    max_length=256,\n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "encoded_data_val = tokenizer.batch_encode_plus(\n",
        "    val.text.values,\n",
        "    add_special_tokens=True,\n",
        "    return_attention_mask=True,\n",
        "    pad_to_max_length=True,\n",
        "    max_length=256,\n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "input_ids_train = encoded_data_train['input_ids']\n",
        "attention_masks_train = encoded_data_train['attention_mask']\n",
        "labels_train = torch.tensor(train.emotion.values)\n",
        "\n",
        "input_ids_val = encoded_data_val['input_ids']\n",
        "attention_masks_val = encoded_data_val['attention_mask']\n",
        "labels_val = torch.tensor(val.emotion.values)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wfNUWimZiJs",
        "outputId": "b1bf7812-fdba-4961-d8d7-1cdd29a8d773"
      },
      "source": [
        "# Creating the tensor datasets\n",
        "\n",
        "dataset_train = TensorDataset(input_ids_train, \n",
        "                              attention_masks_train,\n",
        "                              labels_train)\n",
        "\n",
        "dataset_val = TensorDataset(input_ids_val, \n",
        "                            attention_masks_val,\n",
        "                           labels_val)\n",
        "\n",
        "dataset_val.tensors"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[  101,   137,  4795,  ...,     0,     0,     0],\n",
              "         [  101,  1191,  1136,  ...,     0,     0,     0],\n",
              "         [  101, 23998,   137,  ...,     0,     0,     0],\n",
              "         ...,\n",
              "         [  101,   187, 13356,  ...,     0,     0,     0],\n",
              "         [  101,  4170,  2033,  ...,     0,     0,     0],\n",
              "         [  101,   137,  4795,  ...,     0,     0,     0]]),\n",
              " tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         ...,\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
              " tensor([0, 0, 0, 0, 0, 0, 3, 3, 0, 3, 1, 0, 0, 3, 3, 0, 0, 3, 3, 0, 3, 1, 2, 3,\n",
              "         3, 3, 0, 1, 0, 0, 0, 3, 0, 3, 2, 1, 1, 0, 2, 1, 1, 3, 1, 0, 1, 1, 3, 0,\n",
              "         0, 0, 2, 1, 1, 3, 0, 0, 0, 0, 1, 1, 3, 2, 3, 1, 3, 0, 0, 0, 3, 0, 0, 0,\n",
              "         1, 2, 1, 0, 1, 0, 1, 0, 3, 0, 0, 1, 0, 0, 3, 0, 3, 3, 0, 1, 3, 1, 0, 1,\n",
              "         3, 2, 0, 2, 2, 1, 1, 1, 3, 3, 0, 0, 1, 3, 1, 0, 1, 1, 3, 1, 1, 0, 1, 1,\n",
              "         0, 0, 0, 0, 0, 3, 1, 0, 0, 3, 0, 1, 0, 0, 0, 2, 0, 3, 3, 0, 1, 0, 0, 0,\n",
              "         0, 2, 3, 0, 1, 1, 1, 3, 0, 3, 2, 1, 0, 2, 3, 0, 0, 2, 0, 1, 1, 1, 3, 1,\n",
              "         1, 0, 3, 0, 1, 0, 0, 2, 0, 1, 1, 0, 0, 3, 0, 0, 2, 1, 1, 0, 0, 0, 1, 3,\n",
              "         3, 0, 3, 1, 2, 0, 1, 0, 0, 1, 0, 3, 0, 0, 1, 1, 0, 1, 0, 0, 3, 1, 2, 1,\n",
              "         3, 2, 2, 2, 0, 2, 3, 3, 1, 1, 0, 3, 0, 3, 0, 3, 0, 0, 0, 3, 0, 3, 0, 1,\n",
              "         1, 1, 3, 0, 3, 3, 3, 1, 1, 3, 1, 0, 3, 0, 1, 3, 3, 1, 1, 3, 1, 0, 2, 1,\n",
              "         0, 2, 1, 1, 0, 1, 0, 0, 1, 1, 0, 3, 1, 3, 0, 0, 1, 0, 3, 1, 1, 0, 0, 3,\n",
              "         3, 0, 0, 0, 0, 0, 0, 1, 3, 0, 3, 0, 0, 0, 1, 1, 0, 3, 3, 0, 0, 0, 2, 1,\n",
              "         3, 0, 0, 0, 0, 3, 1, 0, 3, 3, 0, 1, 0, 3, 0, 0, 3, 0, 0, 1, 0, 1, 1, 3,\n",
              "         3, 0, 0, 2, 3, 0, 0, 0, 0, 3, 3, 0, 3, 0, 3, 3, 0, 1, 0, 3, 2, 0, 0, 1,\n",
              "         1, 1, 0, 1, 3, 2, 0, 1, 3, 0, 0, 0, 0, 0]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AC-fYAW_ZmE7"
      },
      "source": [
        "##  Setting up BERT Pretrained Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9ca31smZovz"
      },
      "source": [
        "from transformers import BertForSequenceClassification"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcRxgSPYcqwG"
      },
      "source": [
        "# Creating a dictionary with the possible labels for input\n",
        "\n",
        "label_dict = {}\n",
        "possible_labels = mapping['Emotion'].unique()\n",
        "\n",
        "for index, possible_label in enumerate(possible_labels):\n",
        "    label_dict[possible_label] = index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bs8ijOMIdA9G",
        "outputId": "3f28290e-4be7-4f49-d620-471de0ee7c42"
      },
      "source": [
        "# Importing the model\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "                                      'bert-base-cased', \n",
        "                                      num_labels = len(label_dict),\n",
        "                                      output_attentions = False,\n",
        "                                      output_hidden_states = False\n",
        "                                     )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8fCzZKGda2H"
      },
      "source": [
        "## Creating Data Loaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtL6r7zcdc-0"
      },
      "source": [
        "batch_size = 5\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "dataloader_train = DataLoader(\n",
        "    dataset_train,\n",
        "    sampler=RandomSampler(dataset_train),\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "dataloader_val = DataLoader(\n",
        "    dataset_val,\n",
        "    sampler=RandomSampler(dataset_val),\n",
        "    batch_size=32\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ap2xGAtcdiY8"
      },
      "source": [
        "##  Setting Up Optimizer and Scheduler\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZqu1uVJdjpM"
      },
      "source": [
        "# Setting up the optimizer\n",
        "\n",
        "from transformers import AdamW\n",
        "optimizer = AdamW(\n",
        "    model.parameters(),\n",
        "    lr = 1e-5,\n",
        "    eps = 1e-8\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AF1KWjtbdlnk"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Setting up the scheduler\n",
        "\n",
        "epochs = 1\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps = len(dataloader_train)*epochs\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5O3wHFVdoRa"
      },
      "source": [
        "##  Defining Performance Metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8j3CCFldqqM"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYPhdxy5drvs"
      },
      "source": [
        "# Defining the f1 score metric\n",
        "\n",
        " def f1_score_func(preds, labels):\n",
        "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return f1_score(labels_flat, preds_flat, average = 'weighted')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WfSUwBvdweN"
      },
      "source": [
        "# Defining the accuracy per class metric\n",
        "\n",
        "def accuracy_per_class(preds, labels):\n",
        "    label_dict_inverse = {v: k for k, v in label_dict.items()}\n",
        "    \n",
        "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    \n",
        "    for label in np.unique(labels_flat):\n",
        "        y_preds = preds_flat[labels_flat==label]\n",
        "        y_true = labels_flat[labels_flat==label]\n",
        "        print(f'Class: {label_dict_inverse[label]}')\n",
        "        print(f'Accuracy:{len(y_preds[y_preds==label])}/{len(y_true)}\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErQuJFSWd0Ko"
      },
      "source": [
        "##  Creating our Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PeUyic76d1wx"
      },
      "source": [
        "import random\n",
        "\n",
        "# Setting up the environment\n",
        "\n",
        "seed_val = 17\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7r1_hj4sd2_s",
        "outputId": "64bb0c57-16a6-4a76-aeb0-36fe0335617e"
      },
      "source": [
        "# Setting up the device\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jK66AKw3d7J1"
      },
      "source": [
        "# Defining the evaluation function\n",
        "\n",
        "def evaluate(dataloader_val):\n",
        "\n",
        "    model.eval()\n",
        "    \n",
        "    loss_val_total = 0\n",
        "    predictions, true_vals = [], []\n",
        "    \n",
        "    for batch in tqdm(dataloader_val):\n",
        "        \n",
        "        batch = tuple(b.to(device) for b in batch)\n",
        "        \n",
        "        inputs = {'input_ids':      batch[0],\n",
        "                  'attention_mask': batch[1],\n",
        "                  'labels':         batch[2],\n",
        "                 }\n",
        "\n",
        "        with torch.no_grad():        \n",
        "            outputs = model(**inputs)\n",
        "            \n",
        "        loss = outputs[0]\n",
        "        logits = outputs[1]\n",
        "        loss_val_total += loss.item()\n",
        "\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = inputs['labels'].cpu().numpy()\n",
        "        predictions.append(logits)\n",
        "        true_vals.append(label_ids)\n",
        "    \n",
        "    loss_val_avg = loss_val_total/len(dataloader_val) \n",
        "    \n",
        "    predictions = np.concatenate(predictions, axis=0)\n",
        "    true_vals = np.concatenate(true_vals, axis=0)\n",
        "            \n",
        "    return loss_val_avg, predictions, true_vals"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1XkC4CBd9Fc"
      },
      "source": [
        "## Training the model, making the prediction and calculating the performance metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "d5j7CIipd-4M",
        "outputId": "5e124798-6cc0-4e72-9577-d0baee75b281"
      },
      "source": [
        "from tqdm.notebook import tqdm\n",
        "\n",
        "for epoch in tqdm(range(1, epochs+1)):\n",
        "    model.train()\n",
        "    loss_train_total = 0\n",
        "    \n",
        "    progress_bar = tqdm(dataloader_train, \n",
        "                        desc='Epoch {:1d}'.format(epoch), \n",
        "                        leave=False, \n",
        "                        disable=False)\n",
        "    \n",
        "    for batch in progress_bar:\n",
        "        model.zero_grad()\n",
        "        batch = tuple(b.to(device) for b in batch)\n",
        "        inputs = {\n",
        "            'input_ids': batch[0],\n",
        "            'attention_mask': batch[1],\n",
        "            'labels': batch[2]\n",
        "        }\n",
        "        \n",
        "        outputs = model(**inputs)\n",
        "        loss = outputs[0]\n",
        "        loss_train_total +=loss.item()\n",
        "        loss.backward()\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        \n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        \n",
        "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})     \n",
        "\n",
        "    \n",
        "    loss_train_avg = loss_train_total/len(dataloader_train)\n",
        "    tqdm.write(f'Training loss: {loss_train_avg}')\n",
        "    \n",
        "    val_loss, predictions, true_vals = evaluate(dataloader_val)\n",
        "    val_f1 = f1_score_func(predictions, true_vals)\n",
        "    print(f'Validation loss: {val_loss}')\n",
        "    print(f'F1 Score (weighted): {val_f1}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0e1ee671de9a4ac28fa7faaf49e659aa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "538404b5833e4d3b9a252c746e33b4c0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Epoch 1', max=652.0, style=ProgressStyle(description_widt…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\r\r\r\r\rTraining loss: 0.6816470446122205\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9d5d48a7dd524c10b130e5f8028b2483",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=12.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Validation loss: 0.6187465737263361\n",
            "F1 Score (weighted): 0.7856047237210736\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1JE9_DxeCx8"
      },
      "source": [
        "## Evaluating the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VWt2S20EeGFs",
        "outputId": "0e591b6d-b487-4b67-e2af-5feadb6873be"
      },
      "source": [
        "accuracy_per_class(predictions, true_vals)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class: anger\n",
            "Accuracy:145/160\n",
            "\n",
            "Class: joy\n",
            "Accuracy:70/97\n",
            "\n",
            "Class: optimism\n",
            "Accuracy:14/28\n",
            "\n",
            "Class: sadness\n",
            "Accuracy:66/89\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-8VM72V2jKG"
      },
      "source": [
        "# **Emoji Prediction**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d692ssCSgrjF"
      },
      "source": [
        "<font color=\"Orange\" size=5> Using a ROBERTA Pretrained model: 'roberta-large' </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZTKLSWfgxLF"
      },
      "source": [
        "##  Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0nQpmXJg02f",
        "outputId": "77f2fc80-88d5-4541-8312-324df53d513c"
      },
      "source": [
        " !pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.5.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.2)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.10.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zz99UwW7JLbZ",
        "outputId": "96bf4a0e-5795-4271-ad45-30efa4a69e93"
      },
      "source": [
        " pip install pytorch_transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch_transformers in /usr/local/lib/python3.7/dist-packages (1.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (1.19.5)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (0.0.45)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (1.17.56)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (4.41.1)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (1.8.1+cu101)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (0.1.95)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch_transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch_transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch_transformers) (7.1.2)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch_transformers) (0.10.0)\n",
            "Requirement already satisfied: botocore<1.21.0,>=1.20.56 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch_transformers) (1.20.56)\n",
            "Requirement already satisfied: s3transfer<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch_transformers) (0.4.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_transformers) (2020.12.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.0->pytorch_transformers) (3.7.4.3)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.21.0,>=1.20.56->boto3->pytorch_transformers) (2.8.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWlLkWbzKOag"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ek5hw78OKQqG",
        "outputId": "9cdba944-923e-4fd2-eb48-41e382083dfb"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Transforming the mapping into a .csv file\n",
        "\n",
        "with open('./source/emoji/mapping.txt') as file:\n",
        "  matrix = []\n",
        "  for line in file:\n",
        "    splits = line.split('\\t')\n",
        "    row = {}\n",
        "    row['Code'] = splits[0]\n",
        "    row['Emoji'] = splits[1].rstrip()\n",
        "    matrix.append(row)\n",
        "  mapping = pd.DataFrame(matrix)\n",
        "\n",
        "mapping.to_csv('./source/emoji/mapping.csv', index=False)\n",
        "mapping"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Code</th>\n",
              "      <th>Emoji</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>❤</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>😍</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>😂</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>💕</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>🔥</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>😊</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>😎</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>✨</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>💙</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>😘</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>10</td>\n",
              "      <td>📷</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>11</td>\n",
              "      <td>🇺🇸</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>12</td>\n",
              "      <td>☀</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>13</td>\n",
              "      <td>💜</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>14</td>\n",
              "      <td>😉</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>15</td>\n",
              "      <td>💯</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>16</td>\n",
              "      <td>😁</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>17</td>\n",
              "      <td>🎄</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>18</td>\n",
              "      <td>📸</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>19</td>\n",
              "      <td>😜</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Code Emoji\n",
              "0     0     ❤\n",
              "1     1     😍\n",
              "2     2     😂\n",
              "3     3     💕\n",
              "4     4     🔥\n",
              "5     5     😊\n",
              "6     6     😎\n",
              "7     7     ✨\n",
              "8     8     💙\n",
              "9     9     😘\n",
              "10   10     📷\n",
              "11   11    🇺🇸\n",
              "12   12     ☀\n",
              "13   13     💜\n",
              "14   14     😉\n",
              "15   15     💯\n",
              "16   16     😁\n",
              "17   17     🎄\n",
              "18   18     📸\n",
              "19   19     😜"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jtl6cRAgLajX",
        "outputId": "b0087e9c-0a89-47ca-dfb6-60dcc454517e"
      },
      "source": [
        "# Transforming the .txt files and creating the final dataset to work with\n",
        "\n",
        "with open('./source/emoji/train_text.txt') as train_text, open('./source/emoji/train_labels.txt') as train_labels, open('./source/emoji/test_text.txt') as test_text, open('./source/emoji/test_labels.txt') as test_labels, open('./source/emoji/val_text.txt') as val_text, open('./source/emoji/val_labels.txt') as val_labels:\n",
        "\n",
        "  matrix = []\n",
        "  emojis = pd.read_csv('./source/emoji/mapping.csv')\n",
        "\n",
        "  noZeros = 0\n",
        "\n",
        "  for text, label in zip(train_text, train_labels):\n",
        "    if noZeros == 10000 and int(label) == 0:\n",
        "      continue\n",
        "    if int(label) == 0:\n",
        "      noZeros = noZeros + 1\n",
        "\n",
        "    emoji = emojis.loc[emojis['Code'] == int(label), 'Emoji'].item()\n",
        "    row = {}\n",
        "    row['text'] = text.rstrip()\n",
        "    row['emoji'] = int(label)\n",
        "    row['target'] = emoji\n",
        "    matrix.append(row)\n",
        "  \n",
        "  for text, label in zip(test_text, test_labels):\n",
        "    if noZeros == 10000 and int(label) == 0:\n",
        "      continue\n",
        "    if int(label) == 0:\n",
        "      noZeros = noZeros + 1\n",
        "\n",
        "    emoji = emojis.loc[emojis['Code'] == int(label), 'Emoji'].item()\n",
        "    row = {}\n",
        "    row['text'] = text.rstrip()\n",
        "    row['emoji'] = int(label)\n",
        "    row['target'] = emoji\n",
        "    matrix.append(row)\n",
        "\n",
        "  for text, label in zip(val_text, val_labels):\n",
        "    if noZeros == 10000 and int(label) == 0:\n",
        "      continue\n",
        "    if int(label) == 0:\n",
        "      noZeros = noZeros + 1\n",
        "\n",
        "    emoji = emojis.loc[emojis['Code'] == int(label), 'Emoji'].item()\n",
        "    row = {}\n",
        "    row['text'] = text.rstrip()\n",
        "    row['emoji'] = int(label)\n",
        "    row['target'] = emoji\n",
        "    matrix.append(row)\n",
        "\n",
        "  dataset = pd.DataFrame(matrix)\n",
        "\n",
        "dataset.to_csv('./source/emoji/dataset.csv', index=False)\n",
        "dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>emoji</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sunday afternoon walking through Venice in the...</td>\n",
              "      <td>12</td>\n",
              "      <td>☀</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Time for some BBQ and whiskey libations. Chomp...</td>\n",
              "      <td>19</td>\n",
              "      <td>😜</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Love love love all these people ️ ️ ️ #friends...</td>\n",
              "      <td>0</td>\n",
              "      <td>❤</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>️ ️ ️ ️ @ Toys\"R\"Us</td>\n",
              "      <td>0</td>\n",
              "      <td>❤</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Man these are the funniest kids ever!! That fa...</td>\n",
              "      <td>2</td>\n",
              "      <td>😂</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88937</th>\n",
              "      <td>They're alright @ Da Vinci Banquet Halls</td>\n",
              "      <td>13</td>\n",
              "      <td>💜</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88938</th>\n",
              "      <td>Senior night with my little Bailey !! So proud...</td>\n",
              "      <td>3</td>\n",
              "      <td>💕</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88939</th>\n",
              "      <td>Real friends or labeled as family! #BrotherMan...</td>\n",
              "      <td>6</td>\n",
              "      <td>😎</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88940</th>\n",
              "      <td>It makes me so happy meet people wearing hats ...</td>\n",
              "      <td>3</td>\n",
              "      <td>💕</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88941</th>\n",
              "      <td>It's been 48 hours with her and she still hasn...</td>\n",
              "      <td>2</td>\n",
              "      <td>😂</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>88942 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    text  emoji target\n",
              "0      Sunday afternoon walking through Venice in the...     12      ☀\n",
              "1      Time for some BBQ and whiskey libations. Chomp...     19      😜\n",
              "2      Love love love all these people ️ ️ ️ #friends...      0      ❤\n",
              "3                                    ️ ️ ️ ️ @ Toys\"R\"Us      0      ❤\n",
              "4      Man these are the funniest kids ever!! That fa...      2      😂\n",
              "...                                                  ...    ...    ...\n",
              "88937           They're alright @ Da Vinci Banquet Halls     13      💜\n",
              "88938  Senior night with my little Bailey !! So proud...      3      💕\n",
              "88939  Real friends or labeled as family! #BrotherMan...      6      😎\n",
              "88940  It makes me so happy meet people wearing hats ...      3      💕\n",
              "88941  It's been 48 hours with her and she still hasn...      2      😂\n",
              "\n",
              "[88942 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3H4xYbmM4He"
      },
      "source": [
        "# Separating the dataset into train, test, validation set and stratifying it in order to get more balanced set of data to work with\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, val, y_train, y_val = train_test_split(dataset.index.values, \n",
        "                                                  dataset.emoji.values, \n",
        "                                                  test_size=0.15, \n",
        "                                                  random_state=42,\n",
        "                                                  stratify=dataset.emoji.values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6VINQp4qN4Kd",
        "outputId": "17259bde-8227-4ac7-9a62-9820837edef7"
      },
      "source": [
        "dataset['data_type'] = ['not_set']*dataset.shape[0]\n",
        "dataset.loc[train, 'data_type'] = 'train'\n",
        "dataset.loc[val, 'data_type'] = 'val'\n",
        "\n",
        "dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>emoji</th>\n",
              "      <th>target</th>\n",
              "      <th>data_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sunday afternoon walking through Venice in the...</td>\n",
              "      <td>12</td>\n",
              "      <td>☀</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Time for some BBQ and whiskey libations. Chomp...</td>\n",
              "      <td>19</td>\n",
              "      <td>😜</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Love love love all these people ️ ️ ️ #friends...</td>\n",
              "      <td>0</td>\n",
              "      <td>❤</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>️ ️ ️ ️ @ Toys\"R\"Us</td>\n",
              "      <td>0</td>\n",
              "      <td>❤</td>\n",
              "      <td>val</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Man these are the funniest kids ever!! That fa...</td>\n",
              "      <td>2</td>\n",
              "      <td>😂</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88937</th>\n",
              "      <td>They're alright @ Da Vinci Banquet Halls</td>\n",
              "      <td>13</td>\n",
              "      <td>💜</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88938</th>\n",
              "      <td>Senior night with my little Bailey !! So proud...</td>\n",
              "      <td>3</td>\n",
              "      <td>💕</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88939</th>\n",
              "      <td>Real friends or labeled as family! #BrotherMan...</td>\n",
              "      <td>6</td>\n",
              "      <td>😎</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88940</th>\n",
              "      <td>It makes me so happy meet people wearing hats ...</td>\n",
              "      <td>3</td>\n",
              "      <td>💕</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88941</th>\n",
              "      <td>It's been 48 hours with her and she still hasn...</td>\n",
              "      <td>2</td>\n",
              "      <td>😂</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>88942 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    text  ...  data_type\n",
              "0      Sunday afternoon walking through Venice in the...  ...      train\n",
              "1      Time for some BBQ and whiskey libations. Chomp...  ...      train\n",
              "2      Love love love all these people ️ ️ ️ #friends...  ...      train\n",
              "3                                    ️ ️ ️ ️ @ Toys\"R\"Us  ...        val\n",
              "4      Man these are the funniest kids ever!! That fa...  ...      train\n",
              "...                                                  ...  ...        ...\n",
              "88937           They're alright @ Da Vinci Banquet Halls  ...      train\n",
              "88938  Senior night with my little Bailey !! So proud...  ...      train\n",
              "88939  Real friends or labeled as family! #BrotherMan...  ...      train\n",
              "88940  It makes me so happy meet people wearing hats ...  ...      train\n",
              "88941  It's been 48 hours with her and she still hasn...  ...      train\n",
              "\n",
              "[88942 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8OtB-T14QUvX",
        "outputId": "e1179daa-c810-46fa-89ab-df70bfef5117"
      },
      "source": [
        "dataset.groupby(['emoji', 'data_type']).count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>emoji</th>\n",
              "      <th>data_type</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
              "      <th>train</th>\n",
              "      <td>8500</td>\n",
              "      <td>8500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>val</th>\n",
              "      <td>1500</td>\n",
              "      <td>1500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
              "      <th>train</th>\n",
              "      <td>8714</td>\n",
              "      <td>8714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>val</th>\n",
              "      <td>1538</td>\n",
              "      <td>1538</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
              "      <th>train</th>\n",
              "      <td>8288</td>\n",
              "      <td>8288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>val</th>\n",
              "      <td>1463</td>\n",
              "      <td>1463</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">3</th>\n",
              "      <th>train</th>\n",
              "      <td>4213</td>\n",
              "      <td>4213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>val</th>\n",
              "      <td>743</td>\n",
              "      <td>743</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">4</th>\n",
              "      <th>train</th>\n",
              "      <td>5189</td>\n",
              "      <td>5189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>val</th>\n",
              "      <td>916</td>\n",
              "      <td>916</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">5</th>\n",
              "      <th>train</th>\n",
              "      <td>3386</td>\n",
              "      <td>3386</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>val</th>\n",
              "      <td>597</td>\n",
              "      <td>597</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">6</th>\n",
              "      <th>train</th>\n",
              "      <td>3636</td>\n",
              "      <td>3636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>val</th>\n",
              "      <td>642</td>\n",
              "      <td>642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">7</th>\n",
              "      <th>train</th>\n",
              "      <td>4499</td>\n",
              "      <td>4499</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>val</th>\n",
              "      <td>794</td>\n",
              "      <td>794</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">8</th>\n",
              "      <th>train</th>\n",
              "      <td>2561</td>\n",
              "      <td>2561</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>val</th>\n",
              "      <td>452</td>\n",
              "      <td>452</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">9</th>\n",
              "      <th>train</th>\n",
              "      <td>2326</td>\n",
              "      <td>2326</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>val</th>\n",
              "      <td>411</td>\n",
              "      <td>411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">10</th>\n",
              "      <th>train</th>\n",
              "      <td>3037</td>\n",
              "      <td>3037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>val</th>\n",
              "      <td>536</td>\n",
              "      <td>536</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">11</th>\n",
              "      <th>train</th>\n",
              "      <td>2582</td>\n",
              "      <td>2582</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>val</th>\n",
              "      <td>456</td>\n",
              "      <td>456</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">12</th>\n",
              "      <th>train</th>\n",
              "      <td>2244</td>\n",
              "      <td>2244</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>val</th>\n",
              "      <td>396</td>\n",
              "      <td>396</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">13</th>\n",
              "      <th>train</th>\n",
              "      <td>1910</td>\n",
              "      <td>1910</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>val</th>\n",
              "      <td>337</td>\n",
              "      <td>337</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">14</th>\n",
              "      <th>train</th>\n",
              "      <td>2260</td>\n",
              "      <td>2260</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>val</th>\n",
              "      <td>399</td>\n",
              "      <td>399</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">15</th>\n",
              "      <th>train</th>\n",
              "      <td>1977</td>\n",
              "      <td>1977</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>val</th>\n",
              "      <td>349</td>\n",
              "      <td>349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">16</th>\n",
              "      <th>train</th>\n",
              "      <td>2244</td>\n",
              "      <td>2244</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>val</th>\n",
              "      <td>396</td>\n",
              "      <td>396</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">17</th>\n",
              "      <th>train</th>\n",
              "      <td>2604</td>\n",
              "      <td>2604</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>val</th>\n",
              "      <td>459</td>\n",
              "      <td>459</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">18</th>\n",
              "      <th>train</th>\n",
              "      <td>3448</td>\n",
              "      <td>3448</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>val</th>\n",
              "      <td>608</td>\n",
              "      <td>608</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">19</th>\n",
              "      <th>train</th>\n",
              "      <td>1982</td>\n",
              "      <td>1982</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>val</th>\n",
              "      <td>350</td>\n",
              "      <td>350</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 text  target\n",
              "emoji data_type              \n",
              "0     train      8500    8500\n",
              "      val        1500    1500\n",
              "1     train      8714    8714\n",
              "      val        1538    1538\n",
              "2     train      8288    8288\n",
              "      val        1463    1463\n",
              "3     train      4213    4213\n",
              "      val         743     743\n",
              "4     train      5189    5189\n",
              "      val         916     916\n",
              "5     train      3386    3386\n",
              "      val         597     597\n",
              "6     train      3636    3636\n",
              "      val         642     642\n",
              "7     train      4499    4499\n",
              "      val         794     794\n",
              "8     train      2561    2561\n",
              "      val         452     452\n",
              "9     train      2326    2326\n",
              "      val         411     411\n",
              "10    train      3037    3037\n",
              "      val         536     536\n",
              "11    train      2582    2582\n",
              "      val         456     456\n",
              "12    train      2244    2244\n",
              "      val         396     396\n",
              "13    train      1910    1910\n",
              "      val         337     337\n",
              "14    train      2260    2260\n",
              "      val         399     399\n",
              "15    train      1977    1977\n",
              "      val         349     349\n",
              "16    train      2244    2244\n",
              "      val         396     396\n",
              "17    train      2604    2604\n",
              "      val         459     459\n",
              "18    train      3448    3448\n",
              "      val         608     608\n",
              "19    train      1982    1982\n",
              "      val         350     350"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j13iiBXpJbRQ"
      },
      "source": [
        "##  Loading Tokenizer and Encoding the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEso1TcoJZU5"
      },
      "source": [
        "from transformers import RobertaTokenizer\n",
        "from torch.utils.data import TensorDataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYaVhXO_Ji1p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "f185c8c8a5a04d2f89e62097bfa2df8e",
            "84e59d0f34b64d919d9f77501126a5ed",
            "bdcafa65546d4ba4874001211444375c",
            "4ca01ce18c624c10817836c3428f6ad8",
            "acba8e00bcb34dbd9c2be7196c847ee3",
            "987542270ce94752bd6a5941a67d5bf9",
            "55c8ec4f0a3249e5863e43147345f7e1",
            "b09be2f9c1fa4cd4aa33c8b0364d6118",
            "4c75ed6cf56e4fdf9465457b16a5f74b",
            "9a32bfb7053a48e6a7ac80e6f0db2f3b",
            "5cea3a21f3a34f1d826aba5561f7c6e6",
            "996bfe27c147491ca33709cc75202b0c",
            "1e221cecf8c6401a833cfc46e7a90c40",
            "92f220f133324a9889b58e2a8b587767",
            "05c8629af3904ce49f680e7a5a9eacbc",
            "b1502be8c17a403690418b751c58e72b",
            "3ae1f5af37e44a608688d85c025e7269",
            "44f83a80734c42e995192ab1723a0891",
            "d18b3c33fbda4b90b6dcc13c9e6257b7",
            "ac83c700a1b94cb58bbdcc577d53f21f",
            "f55f5ac698c4418eb0854a70ee511666",
            "b60146833b014a8f8fcd821e0254e96b",
            "11dfb73cbf93465398672b914c221ef1",
            "fda51457ad354c3e8e2af81fd201e96d"
          ]
        },
        "outputId": "0755de71-8f0c-4e49-932e-2c0f1051699e"
      },
      "source": [
        "# Importing the tokenizer for the model\n",
        "\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\n",
        "    'roberta-large',\n",
        "    do_lower_case=True\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f185c8c8a5a04d2f89e62097bfa2df8e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=898823.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4c75ed6cf56e4fdf9465457b16a5f74b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3ae1f5af37e44a608688d85c025e7269",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1355863.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQlrsJlXJpd_",
        "outputId": "d862f2e3-28f5-4f68-db55-33b7d754cf92"
      },
      "source": [
        "import torch\n",
        "\n",
        "# Encoding the data\n",
        "\n",
        "encoded_data_train = tokenizer.batch_encode_plus(\n",
        "    dataset[dataset.data_type=='train'].text.values,\n",
        "    add_special_tokens=True,\n",
        "    return_attention_mask=True,\n",
        "    pad_to_max_length=True,\n",
        "    max_length=256,\n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "encoded_data_val = tokenizer.batch_encode_plus(\n",
        "    dataset[dataset.data_type=='val'].text.values,\n",
        "    add_special_tokens=True,\n",
        "    return_attention_mask=True,\n",
        "    pad_to_max_length=True,\n",
        "    max_length=256,\n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "input_ids_train = encoded_data_train['input_ids']\n",
        "attention_masks_train = encoded_data_train['attention_mask']\n",
        "labels_train = torch.tensor(dataset[dataset.data_type=='train'].emoji.values)\n",
        "\n",
        "input_ids_val = encoded_data_val['input_ids']\n",
        "attention_masks_val = encoded_data_val['attention_mask']\n",
        "labels_val = torch.tensor(dataset[dataset.data_type=='val'].emoji.values)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VzHtJDZuJ3jW",
        "outputId": "a1ff2e83-64a5-465b-e3fc-b27ee33f5d11"
      },
      "source": [
        "# Creating the tensor datasets\n",
        "\n",
        "dataset_train = TensorDataset(input_ids_train, \n",
        "                              attention_masks_train,\n",
        "                              labels_train)\n",
        "\n",
        "dataset_val = TensorDataset(input_ids_val, \n",
        "                            attention_masks_val,\n",
        "                           labels_val)\n",
        "\n",
        "dataset_val.tensors"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[    0, 12605, 33549,  ...,     1,     1,     1],\n",
              "         [    0, 10431, 39009,  ...,     1,     1,     1],\n",
              "         [    0, 18028, 24754,  ...,     1,     1,     1],\n",
              "         ...,\n",
              "         [    0,  2794, 18759,  ...,     1,     1,     1],\n",
              "         [    0,  4651,   881,  ...,     1,     1,     1],\n",
              "         [    0,  4528,    32,  ...,     1,     1,     1]]),\n",
              " tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         ...,\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
              " tensor([ 0, 11,  7,  ...,  3,  4,  1]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxWeqrlmJ-RN"
      },
      "source": [
        "##  Setting up RoBERTa Pretrained Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCuTGiwNJ_vY"
      },
      "source": [
        "from transformers import RobertaForSequenceClassification"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xM6D1kXVKEle"
      },
      "source": [
        "# Creating a dictionary with the possible labels for input\n",
        "\n",
        "label_dict = {}\n",
        "possible_labels = dataset['target'].unique()\n",
        "\n",
        "for index, possible_label in enumerate(possible_labels):\n",
        "    label_dict[possible_label] = index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220,
          "referenced_widgets": [
            "fbbbf2241b1a4d08af9bac7c67820061",
            "aa3e8e1e930e4a45b2dd56e974ceb180",
            "d0be76c18ec2478586a065ffccd083ce",
            "884c0ec6b37a4ef1ad40a03b5fd13a71",
            "a39b640e30ba47f8a51602fee2c47390",
            "c3243ebefe094b92aa4f787d14ad7243",
            "9b10037ad3dd455faba447c5f856522e",
            "f5cf6abd5e4746d493d46ca118c7d2b7",
            "4c8caeef507c49b19f28745ae735cba3",
            "b80118f1030945f6bced3a7b80adc59c",
            "d81fb0f4d6e044a197cf04d2f28cc230",
            "cf10b233005e42379f8b10f3eae16621",
            "71e5635daf614d37b4ceb7272256b907",
            "d6cd625203074a228783a50e2bd5d087",
            "74caa60d16ef4643ae9365575773acb4",
            "55c4c800234e4cedae10c023066db1d1"
          ]
        },
        "id": "kl5rVz2fKPan",
        "outputId": "95662b3a-aa4e-4b7c-ee44-3c73eeef01f1"
      },
      "source": [
        "# Importing the model\n",
        "\n",
        "model = RobertaForSequenceClassification.from_pretrained(\n",
        "                                      'roberta-large', \n",
        "                                      num_labels = len(label_dict),\n",
        "                                      output_attentions = False,\n",
        "                                      output_hidden_states = False\n",
        "                                     )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fbbbf2241b1a4d08af9bac7c67820061",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=482.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4c8caeef507c49b19f28745ae735cba3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1425941629.0, style=ProgressStyle(descr…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gLSNYQLKadw"
      },
      "source": [
        "##  Creating Data Loaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nvcj4Mi8KbiP"
      },
      "source": [
        "batch_size = 10\n",
        "\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "dataloader_train = DataLoader(\n",
        "    dataset_train,\n",
        "    sampler=RandomSampler(dataset_train),\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "dataloader_val = DataLoader(\n",
        "    dataset_val,\n",
        "    sampler=RandomSampler(dataset_val),\n",
        "    batch_size=40\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1QyVcEcHKoJa"
      },
      "source": [
        "##  Setting Up Optimizer and Scheduler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiFQ-EsMKpiY"
      },
      "source": [
        "from transformers import AdamW\n",
        "\n",
        "# Setting up the optimizer\n",
        "\n",
        "optimizer = AdamW(\n",
        "    model.parameters(),\n",
        "    lr = 1e-5,\n",
        "    eps = 1e-8\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4AKeiScLKmx"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Setting up the scheduler\n",
        "\n",
        "epochs = 1\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps = len(dataloader_train)*epochs\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8OSm-kILM_o"
      },
      "source": [
        "##  Defining the Performance Metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lz0Oq9YRLPQE"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WvRaTJZLRII"
      },
      "source": [
        "# Defining the f1 score metric\n",
        "\n",
        "def f1_score_func(preds, labels):\n",
        "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return f1_score(labels_flat, preds_flat, average = 'weighted')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bygp51QLTtQ"
      },
      "source": [
        "# Defining the accuracy per class metric\n",
        "\n",
        "def accuracy_per_class(preds, labels):\n",
        "    label_dict_inverse = {v: k for k, v in label_dict.items()}\n",
        "    \n",
        "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    \n",
        "    for label in np.unique(labels_flat):\n",
        "        y_preds = preds_flat[labels_flat==label]\n",
        "        y_true = labels_flat[labels_flat==label]\n",
        "        print(f'Class: {label_dict_inverse[label]}')\n",
        "        print(f'Accuracy:{len(y_preds[y_preds==label])}/{len(y_true)}\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tya-cB0ALWYz"
      },
      "source": [
        "##  Creating the Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xppQWfl3LXUu"
      },
      "source": [
        "import random\n",
        "\n",
        "# Setting up the environment\n",
        "\n",
        "seed_val = 17\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WB_0oxq5LZfK",
        "outputId": "30628937-59fe-49d7-a387-cc612ea3590b"
      },
      "source": [
        "# Setting up the device\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57weZevPLdLx"
      },
      "source": [
        "# Defining the evaluation function\n",
        "\n",
        "def evaluate(dataloader_val):\n",
        "\n",
        "    model.eval()\n",
        "    \n",
        "    loss_val_total = 0\n",
        "    predictions, true_vals = [], []\n",
        "    \n",
        "    for batch in tqdm(dataloader_val):\n",
        "        \n",
        "        batch = tuple(b.to(device) for b in batch)\n",
        "        \n",
        "        inputs = {'input_ids':      batch[0],\n",
        "                  'attention_mask': batch[1],\n",
        "                  'labels':         batch[2],\n",
        "                 }\n",
        "\n",
        "        with torch.no_grad():        \n",
        "            outputs = model(**inputs)\n",
        "            \n",
        "        loss = outputs[0]\n",
        "        logits = outputs[1]\n",
        "        loss_val_total += loss.item()\n",
        "\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = inputs['labels'].cpu().numpy()\n",
        "        predictions.append(logits)\n",
        "        true_vals.append(label_ids)\n",
        "    \n",
        "    loss_val_avg = loss_val_total/len(dataloader_val) \n",
        "    \n",
        "    predictions = np.concatenate(predictions, axis=0)\n",
        "    true_vals = np.concatenate(true_vals, axis=0)\n",
        "            \n",
        "    return loss_val_avg, predictions, true_vals"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixqJB3n7LhRQ"
      },
      "source": [
        "## Training the model, making the prediction and calculating the performance metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzivD6cAzfFT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166,
          "referenced_widgets": [
            "45b10068935e4d5ba16d976293280912",
            "e53c0c747d6b400792482f44dca7fa78",
            "ef7bed9506f0461a9b37e905a95da7c2",
            "49fdac4886ca466293ae6aa7b82f95b4",
            "52360d705cbf4eabbf1b7e84ca8eb227",
            "ed9eba1d0a494b84b13148c9df4a4f79",
            "31cd5abf7e324f23ad5a38a8be26e466",
            "9d800e2864a543799e02ec203c58820f",
            "f8dab7ab0a3e4b24a94f5e17d32fe6b6",
            "93bcb4fcca704ab98f3d0d1aa2cfa18d",
            "b699e240811944a4a50173a5f5a7a55b",
            "a816b669176d4221be430792385ce629",
            "c0433edf6d1d40868b3d87138e02550a",
            "310258bd358b43a2857e5d13524b9035",
            "77692829f0ce4e8382d57b68135ad5f8",
            "5c00917228a249e897dcd0cbba9e810c",
            "42c7363e0bb1469b9dfdc983080cc1b9",
            "f1a9095b789c48978a25c68bbb8e259d",
            "f382c70ca8a14717884eabe2b02026c5",
            "ee96c6e1d50040928ba604f0f5e9ae6a",
            "d6d29a939a6547c88154a8fbdff609b8",
            "5a366921b9a549d2a783968baa53f701",
            "eb00cccdbb6a4fe1bb932ad0adfcb015",
            "58a6c3962b5446d3b1ecb99547908466"
          ]
        },
        "outputId": "a4ceec99-994f-48c9-f5a5-1b22689c95df"
      },
      "source": [
        "from tqdm.notebook import tqdm\n",
        "\n",
        "for epoch in tqdm(range(1, epochs+1)):\n",
        "    model.train()\n",
        "    loss_train_total = 0\n",
        "    \n",
        "    progress_bar = tqdm(dataloader_train, \n",
        "                        desc='Epoch {:1d}'.format(epoch), \n",
        "                        leave=False, \n",
        "                        disable=False)\n",
        "    \n",
        "    for batch in progress_bar:\n",
        "        model.zero_grad()\n",
        "        batch = tuple(b.to(device) for b in batch)\n",
        "        inputs = {\n",
        "            'input_ids': batch[0],\n",
        "            'attention_mask': batch[1],\n",
        "            'labels': batch[2]\n",
        "        }\n",
        "        \n",
        "        outputs = model(**inputs)\n",
        "        loss = outputs[0]\n",
        "        loss_train_total +=loss.item()\n",
        "        loss.backward()\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        \n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        \n",
        "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})     \n",
        "    \n",
        "    #torch.save(model.state_dict(), f'Models/BERT_ft_Epoch{epoch}.model')\n",
        "    \n",
        "\n",
        "    \n",
        "    loss_train_avg = loss_train_total/len(dataloader_train)\n",
        "    tqdm.write(f'Training loss: {loss_train_avg}')\n",
        "    \n",
        "    val_loss, predictions, true_vals = evaluate(dataloader_val)\n",
        "    val_f1 = f1_score_func(predictions, true_vals)\n",
        "    print(f'Validation loss: {val_loss}')\n",
        "    print(f'F1 Score (weighted): {val_f1}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "45b10068935e4d5ba16d976293280912",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f8dab7ab0a3e4b24a94f5e17d32fe6b6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Epoch 1', max=7560.0, style=ProgressStyle(description_wid…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\rTraining loss: 1.9830986277885223\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "42c7363e0bb1469b9dfdc983080cc1b9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=334.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Validation loss: 1.8143948634227594\n",
            "F1 Score (weighted): 0.4203684579628441\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffYP7EOMLsUA"
      },
      "source": [
        "##  Evaluating the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eY3ee66cLtQc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6cf92ce-e4ca-427b-c5a5-3bfae0193a9a"
      },
      "source": [
        "accuracy_per_class(predictions, true_vals) # One best model prediction"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class: ☀\n",
            "Accuracy:1202/1500\n",
            "\n",
            "Class: 😜\n",
            "Accuracy:733/1538\n",
            "\n",
            "Class: ❤\n",
            "Accuracy:1018/1463\n",
            "\n",
            "Class: 😂\n",
            "Accuracy:201/743\n",
            "\n",
            "Class: 🇺🇸\n",
            "Accuracy:510/916\n",
            "\n",
            "Class: ✨\n",
            "Accuracy:94/597\n",
            "\n",
            "Class: 😍\n",
            "Accuracy:172/642\n",
            "\n",
            "Class: 😘\n",
            "Accuracy:325/794\n",
            "\n",
            "Class: 🔥\n",
            "Accuracy:81/452\n",
            "\n",
            "Class: 💙\n",
            "Accuracy:115/411\n",
            "\n",
            "Class: 😊\n",
            "Accuracy:14/536\n",
            "\n",
            "Class: 📷\n",
            "Accuracy:296/456\n",
            "\n",
            "Class: 😉\n",
            "Accuracy:275/396\n",
            "\n",
            "Class: 😁\n",
            "Accuracy:0/337\n",
            "\n",
            "Class: 📸\n",
            "Accuracy:11/399\n",
            "\n",
            "Class: 😎\n",
            "Accuracy:52/349\n",
            "\n",
            "Class: 💜\n",
            "Accuracy:5/396\n",
            "\n",
            "Class: 💕\n",
            "Accuracy:385/459\n",
            "\n",
            "Class: 💯\n",
            "Accuracy:478/608\n",
            "\n",
            "Class: 🎄\n",
            "Accuracy:3/350\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_q98hAjmNM1Z",
        "outputId": "60235cd5-74dc-4d04-9f4d-0581acde7ab6"
      },
      "source": [
        "accuracy_per_class(predictions, true_vals) # Second best model prediction"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class: ☀\n",
            "Accuracy:1195/1500\n",
            "\n",
            "Class: 😜\n",
            "Accuracy:838/1538\n",
            "\n",
            "Class: ❤\n",
            "Accuracy:978/1463\n",
            "\n",
            "Class: 😂\n",
            "Accuracy:199/743\n",
            "\n",
            "Class: 🇺🇸\n",
            "Accuracy:540/916\n",
            "\n",
            "Class: ✨\n",
            "Accuracy:118/597\n",
            "\n",
            "Class: 😍\n",
            "Accuracy:148/642\n",
            "\n",
            "Class: 😘\n",
            "Accuracy:313/794\n",
            "\n",
            "Class: 🔥\n",
            "Accuracy:40/452\n",
            "\n",
            "Class: 💙\n",
            "Accuracy:88/411\n",
            "\n",
            "Class: 😊\n",
            "Accuracy:279/536\n",
            "\n",
            "Class: 📷\n",
            "Accuracy:293/456\n",
            "\n",
            "Class: 😉\n",
            "Accuracy:272/396\n",
            "\n",
            "Class: 😁\n",
            "Accuracy:0/337\n",
            "\n",
            "Class: 📸\n",
            "Accuracy:6/399\n",
            "\n",
            "Class: 😎\n",
            "Accuracy:68/349\n",
            "\n",
            "Class: 💜\n",
            "Accuracy:4/396\n",
            "\n",
            "Class: 💕\n",
            "Accuracy:376/459\n",
            "\n",
            "Class: 💯\n",
            "Accuracy:204/608\n",
            "\n",
            "Class: 🎄\n",
            "Accuracy:0/350\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezeIMHk72uxe"
      },
      "source": [
        "# **Hate Speech Detection**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CgbThoaNqm4s"
      },
      "source": [
        "<font color=\"Orange\" size=5> Using a ROBERTA Pretrained model: 'roberta-large' </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBFKAhM1jUXD"
      },
      "source": [
        "##  Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLptF9_cjWSO",
        "outputId": "999f4be9-eadb-4158-c17b-0f2166ac9dfe"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.5.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.10.1)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Se02J_HZjbPC",
        "outputId": "a03686f9-7bd5-460c-955c-1f902b80617a"
      },
      "source": [
        " pip install pytorch_transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch_transformers in /usr/local/lib/python3.7/dist-packages (1.2.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (0.0.45)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (2.23.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (1.17.54)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (4.41.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (0.1.95)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (1.8.1+cu101)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch_transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch_transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch_transformers) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_transformers) (2020.12.5)\n",
            "Requirement already satisfied: botocore<1.21.0,>=1.20.54 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch_transformers) (1.20.54)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch_transformers) (0.10.0)\n",
            "Requirement already satisfied: s3transfer<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch_transformers) (0.4.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.0->pytorch_transformers) (3.7.4.3)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.21.0,>=1.20.54->boto3->pytorch_transformers) (2.8.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46o3edJ7jYz7"
      },
      "source": [
        "##   Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VBgkKbN2zft",
        "outputId": "554ddfda-ca1f-43c8-f115-5e7178faff33"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Transforming the mapping into a .csv file\n",
        "\n",
        "with open('./source/hate/mapping.txt') as file:\n",
        "  matrix = []\n",
        "  for line in file:\n",
        "    splits = line.split('\\t')\n",
        "    row = {}\n",
        "    row['Code'] = splits[0]\n",
        "    row['Hate'] = splits[1].rstrip()\n",
        "    matrix.append(row)\n",
        "  mapping = pd.DataFrame(matrix)\n",
        "\n",
        "mapping.to_csv('./source/hate/mapping.csv', index=False)\n",
        "mapping"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Code</th>\n",
              "      <th>Hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>not-hate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>hate</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Code      Hate\n",
              "0    0  not-hate\n",
              "1    1      hate"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebHBeRqFkCi0",
        "outputId": "0220bace-56e5-4c64-c89c-a441dfe9e097"
      },
      "source": [
        "# Transforming the .txt files and creating the train dataset\n",
        "\n",
        "with open('./source/hate/train_text.txt') as train_text, open('./source/hate/train_labels.txt') as train_labels:\n",
        "  matrix = []\n",
        "  hates = pd.read_csv('./source/hate/mapping.csv')\n",
        "  for text, label in zip(train_text, train_labels):\n",
        "    hate = hates.loc[hates['Code'] == int(label), 'Hate'].item()\n",
        "    row = {}\n",
        "    row['text'] = text.rstrip()\n",
        "    row['hate'] = int(label)\n",
        "    row['target'] = hate\n",
        "    matrix.append(row)\n",
        "  train = pd.DataFrame(matrix)\n",
        "\n",
        "train.to_csv('./source/hate/train.csv', index=False)\n",
        "train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>hate</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@user nice new signage. Are you not concerned ...</td>\n",
              "      <td>0</td>\n",
              "      <td>not-hate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A woman who you fucked multiple times saying y...</td>\n",
              "      <td>1</td>\n",
              "      <td>hate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@user @user real talk do you have eyes or were...</td>\n",
              "      <td>1</td>\n",
              "      <td>hate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>your girlfriend lookin at me like a groupie in...</td>\n",
              "      <td>1</td>\n",
              "      <td>hate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Hysterical woman like @user</td>\n",
              "      <td>0</td>\n",
              "      <td>not-hate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8995</th>\n",
              "      <td>Oooohhhh bitch didn't even listen to the dead ...</td>\n",
              "      <td>0</td>\n",
              "      <td>not-hate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8996</th>\n",
              "      <td>@user Good Luck @user More Americans #WalkAway...</td>\n",
              "      <td>0</td>\n",
              "      <td>not-hate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8997</th>\n",
              "      <td>Bitch you can't keep up so stop trying</td>\n",
              "      <td>1</td>\n",
              "      <td>hate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8998</th>\n",
              "      <td>@user @user @user @user @user @user Japan is a...</td>\n",
              "      <td>0</td>\n",
              "      <td>not-hate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8999</th>\n",
              "      <td>@user hi Best l see someone fucking girl comme...</td>\n",
              "      <td>1</td>\n",
              "      <td>hate</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9000 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text  hate    target\n",
              "0     @user nice new signage. Are you not concerned ...     0  not-hate\n",
              "1     A woman who you fucked multiple times saying y...     1      hate\n",
              "2     @user @user real talk do you have eyes or were...     1      hate\n",
              "3     your girlfriend lookin at me like a groupie in...     1      hate\n",
              "4                           Hysterical woman like @user     0  not-hate\n",
              "...                                                 ...   ...       ...\n",
              "8995  Oooohhhh bitch didn't even listen to the dead ...     0  not-hate\n",
              "8996  @user Good Luck @user More Americans #WalkAway...     0  not-hate\n",
              "8997             Bitch you can't keep up so stop trying     1      hate\n",
              "8998  @user @user @user @user @user @user Japan is a...     0  not-hate\n",
              "8999  @user hi Best l see someone fucking girl comme...     1      hate\n",
              "\n",
              "[9000 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGCVvNOykWlk",
        "outputId": "72a57ad9-b122-4b13-a06e-86ff2f395810"
      },
      "source": [
        "# Transforming the .txt files and creating the test dataset\n",
        "\n",
        "with open('./source/hate/test_text.txt') as test_text, open('./source/hate/test_labels.txt') as test_labels:\n",
        "  matrix = []\n",
        "  hates = pd.read_csv('./source/hate/mapping.csv')\n",
        "  for text, label in zip(test_text, test_labels):\n",
        "    hate = hates.loc[hates['Code'] == int(label), 'Hate'].item()\n",
        "    row = {}\n",
        "    row['text'] = text.rstrip()\n",
        "    row['hate'] = int(label)\n",
        "    row['target'] = hate\n",
        "    matrix.append(row)\n",
        "  test = pd.DataFrame(matrix)\n",
        "\n",
        "test.to_csv('./source/hate/test.csv', index=False)\n",
        "test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>hate</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@user , you are correct that Reid certainly is...</td>\n",
              "      <td>0</td>\n",
              "      <td>not-hate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Whoever just unfollowed me you a bitch</td>\n",
              "      <td>1</td>\n",
              "      <td>hate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@user @user Those People Invaded Us!!! They DO...</td>\n",
              "      <td>1</td>\n",
              "      <td>hate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>stop JUDGING bitches by there cover, jus cuz s...</td>\n",
              "      <td>1</td>\n",
              "      <td>hate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>how about i knock heads off and send them gift...</td>\n",
              "      <td>1</td>\n",
              "      <td>hate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2965</th>\n",
              "      <td>@user Calling them #IllegalAliens is heartless...</td>\n",
              "      <td>0</td>\n",
              "      <td>not-hate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2966</th>\n",
              "      <td>Silly Killary WANNABE !! And @user numbers JUS...</td>\n",
              "      <td>0</td>\n",
              "      <td>not-hate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2967</th>\n",
              "      <td>@user @user @user @user @user @user @user @use...</td>\n",
              "      <td>0</td>\n",
              "      <td>not-hate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2968</th>\n",
              "      <td>@user StopImmigration</td>\n",
              "      <td>1</td>\n",
              "      <td>hate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2969</th>\n",
              "      <td>That bitch on the spoiled whore list   Thought...</td>\n",
              "      <td>1</td>\n",
              "      <td>hate</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2970 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text  hate    target\n",
              "0     @user , you are correct that Reid certainly is...     0  not-hate\n",
              "1                Whoever just unfollowed me you a bitch     1      hate\n",
              "2     @user @user Those People Invaded Us!!! They DO...     1      hate\n",
              "3     stop JUDGING bitches by there cover, jus cuz s...     1      hate\n",
              "4     how about i knock heads off and send them gift...     1      hate\n",
              "...                                                 ...   ...       ...\n",
              "2965  @user Calling them #IllegalAliens is heartless...     0  not-hate\n",
              "2966  Silly Killary WANNABE !! And @user numbers JUS...     0  not-hate\n",
              "2967  @user @user @user @user @user @user @user @use...     0  not-hate\n",
              "2968                              @user StopImmigration     1      hate\n",
              "2969  That bitch on the spoiled whore list   Thought...     1      hate\n",
              "\n",
              "[2970 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvGhp6YBkjjy",
        "outputId": "ba0c5134-5ec6-4880-e0af-ef8c29893b9e"
      },
      "source": [
        "# Transforming the .txt files and creating the validation dataset\n",
        "\n",
        "with open('./source/hate/val_text.txt') as val_text, open('./source/hate/val_labels.txt') as val_labels:\n",
        "  matrix = []\n",
        "  hates = pd.read_csv('./source/hate/mapping.csv')\n",
        "  for text, label in zip(val_text, val_labels):\n",
        "    hate = hates.loc[hates['Code'] == int(label), 'Hate'].item()\n",
        "    row = {}\n",
        "    row['text'] = text.rstrip()\n",
        "    row['hate'] = int(label)\n",
        "    row['target'] = hate\n",
        "    matrix.append(row)\n",
        "  val = pd.DataFrame(matrix)\n",
        "\n",
        "val.to_csv('./source/hate/val.csv', index=False)\n",
        "val"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>hate</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@user @user If book Claire wanted to \"stay in ...</td>\n",
              "      <td>0</td>\n",
              "      <td>not-hate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>After arriving in the EU refugees make protest...</td>\n",
              "      <td>0</td>\n",
              "      <td>not-hate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>😳👇</td>\n",
              "      <td>0</td>\n",
              "      <td>not-hate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@user Worst thing is if they are that stupid t...</td>\n",
              "      <td>1</td>\n",
              "      <td>hate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@user Say's the HYSTERICAL woman. It is woman ...</td>\n",
              "      <td>0</td>\n",
              "      <td>not-hate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>Pass #MeritBased Immigration. Kill #ChainMigra...</td>\n",
              "      <td>1</td>\n",
              "      <td>hate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>imagine chaeyoung cutting some cooked meat for...</td>\n",
              "      <td>0</td>\n",
              "      <td>not-hate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>I usually dont hate people but I actually hate...</td>\n",
              "      <td>1</td>\n",
              "      <td>hate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>Cameron stopped immigrants voting on the EU in...</td>\n",
              "      <td>1</td>\n",
              "      <td>hate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>Large scale migration of illegal migrants to D...</td>\n",
              "      <td>0</td>\n",
              "      <td>not-hate</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  text  hate    target\n",
              "0    @user @user If book Claire wanted to \"stay in ...     0  not-hate\n",
              "1    After arriving in the EU refugees make protest...     0  not-hate\n",
              "2                                                   😳👇     0  not-hate\n",
              "3    @user Worst thing is if they are that stupid t...     1      hate\n",
              "4    @user Say's the HYSTERICAL woman. It is woman ...     0  not-hate\n",
              "..                                                 ...   ...       ...\n",
              "995  Pass #MeritBased Immigration. Kill #ChainMigra...     1      hate\n",
              "996  imagine chaeyoung cutting some cooked meat for...     0  not-hate\n",
              "997  I usually dont hate people but I actually hate...     1      hate\n",
              "998  Cameron stopped immigrants voting on the EU in...     1      hate\n",
              "999  Large scale migration of illegal migrants to D...     0  not-hate\n",
              "\n",
              "[1000 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYzYCln1k0eC"
      },
      "source": [
        "##  Loading Tokenizer and Encoding the Data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQgJbMw8k9ca"
      },
      "source": [
        "from transformers import RobertaTokenizer\n",
        "from torch.utils.data import TensorDataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        },
        "id": "Wg68nKoPlA8y",
        "outputId": "727155d5-9f2d-49e4-bf1b-6ce9ec0bf74a"
      },
      "source": [
        "# Importing the tokenizer for the model\n",
        "\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\n",
        "    'roberta-large',\n",
        "    do_lower_case=True\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3e7a13dac9e348148cdb5c8beb6bc2b0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=898823.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ca781bb6592e476eac247d7facc9d0ec",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kmtpa_KElLVC",
        "outputId": "78136aa6-dcc2-4601-96d9-56c83bcec1af"
      },
      "source": [
        "import torch\n",
        "\n",
        "# Encoding the data\n",
        "\n",
        "encoded_data_train = tokenizer.batch_encode_plus(\n",
        "    train.text.values,\n",
        "    add_special_tokens=True,\n",
        "    return_attention_mask=True,\n",
        "    pad_to_max_length=True,\n",
        "    max_length=256,\n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "encoded_data_val = tokenizer.batch_encode_plus(\n",
        "    val.text.values,\n",
        "    add_special_tokens=True,\n",
        "    return_attention_mask=True,\n",
        "    pad_to_max_length=True,\n",
        "    max_length=256,\n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "input_ids_train = encoded_data_train['input_ids']\n",
        "attention_masks_train = encoded_data_train['attention_mask']\n",
        "labels_train = torch.tensor(train.hate.values)\n",
        "\n",
        "input_ids_val = encoded_data_val['input_ids']\n",
        "attention_masks_val = encoded_data_val['attention_mask']\n",
        "labels_val = torch.tensor(val.hate.values)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGc_AIc1lVQJ",
        "outputId": "fd9df619-ca5d-4b5c-fc1a-3e76a73441e8"
      },
      "source": [
        "# Creating the tensor datasets\n",
        "\n",
        "dataset_train = TensorDataset(input_ids_train, \n",
        "                              attention_masks_train,\n",
        "                              labels_train)\n",
        "\n",
        "dataset_val = TensorDataset(input_ids_val, \n",
        "                            attention_masks_val,\n",
        "                           labels_val)\n",
        "\n",
        "dataset_val.tensors"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[    0,  1039, 12105,  ...,     1,     1,     1],\n",
              "         [    0,  4993,  7789,  ...,     1,     1,     1],\n",
              "         [    0, 18636, 15264,  ...,     1,     1,     1],\n",
              "         ...,\n",
              "         [    0,   100,  2333,  ...,     1,     1,     1],\n",
              "         [    0,   347, 35953,  ...,     1,     1,     1],\n",
              "         [    0, 39012,  3189,  ...,     1,     1,     1]]),\n",
              " tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         ...,\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
              " tensor([0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
              "         1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1,\n",
              "         0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
              "         1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1,\n",
              "         1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
              "         1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1,\n",
              "         1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1,\n",
              "         0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1,\n",
              "         1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0,\n",
              "         0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1,\n",
              "         1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
              "         1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
              "         0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
              "         0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1,\n",
              "         0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0,\n",
              "         0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0,\n",
              "         1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0,\n",
              "         0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0,\n",
              "         1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1,\n",
              "         0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
              "         0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1,\n",
              "         1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0,\n",
              "         0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
              "         0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1,\n",
              "         0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0,\n",
              "         1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n",
              "         1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0,\n",
              "         1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1,\n",
              "         0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1,\n",
              "         1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCmUjkJGlcCf"
      },
      "source": [
        "## Setting up ROBERTA Pretrained Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8XW66_ulZbz"
      },
      "source": [
        "from transformers import RobertaForSequenceClassification"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIVrG8Y5lhEV"
      },
      "source": [
        "# Creating a dictionary with the possible labels for input\n",
        "\n",
        "label_dict = {}\n",
        "possible_labels = mapping['Hate'].unique()\n",
        "\n",
        "for index, possible_label in enumerate(possible_labels):\n",
        "    label_dict[possible_label] = index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        },
        "id": "9WZB6Z65lnjD",
        "outputId": "ec4c9ff8-573a-4ae3-a759-bd2f955a2b19"
      },
      "source": [
        "# Importing the model\n",
        "\n",
        "model = RobertaForSequenceClassification.from_pretrained(\n",
        "                                      'roberta-large', \n",
        "                                      num_labels = len(label_dict),\n",
        "                                      output_attentions = False,\n",
        "                                      output_hidden_states = False\n",
        "                                     )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6158e8a3a8bf4dffa854380621b04076",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=482.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "db9ba626dc634512bf5a69c526dd3ac1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1425941629.0, style=ProgressStyle(descr…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rGaE5Xslr_C"
      },
      "source": [
        "## Creating Data Loaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLNcNzOVlqGS"
      },
      "source": [
        "batch_size = 4\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "dataloader_train = DataLoader(\n",
        "    dataset_train,\n",
        "    sampler=RandomSampler(dataset_train),\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "dataloader_val = DataLoader(\n",
        "    dataset_val,\n",
        "    sampler=RandomSampler(dataset_val),\n",
        "    batch_size=32\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSlZkHvvlu9t"
      },
      "source": [
        "##  Setting Up Optimizer and Scheduler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afb35dI3lwrB"
      },
      "source": [
        "from transformers import AdamW\n",
        "\n",
        "# Setting up the optimizer\n",
        "\n",
        "optimizer = AdamW(\n",
        "    model.parameters(),\n",
        "    lr = 1e-5,\n",
        "    eps = 1e-8\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ES4YvCyQl4T6"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Setting up the scheduler\n",
        "\n",
        "epochs = 1\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps = len(dataloader_train)*epochs\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAX-HJz0l6TM"
      },
      "source": [
        "##  Defining the Performance Metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Me1aNoq6l8Xh"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KK4O3ePil-Sh"
      },
      "source": [
        "# Defining the f1 score metric\n",
        "\n",
        "def f1_score_func(preds, labels):\n",
        "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return f1_score(labels_flat, preds_flat, average = 'weighted')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmoh_ZBamAbK"
      },
      "source": [
        "# Defining the accuracy per class metric\n",
        "\n",
        "def accuracy_per_class(preds, labels):\n",
        "    label_dict_inverse = {v: k for k, v in label_dict.items()}\n",
        "    \n",
        "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    \n",
        "    for label in np.unique(labels_flat):\n",
        "        y_preds = preds_flat[labels_flat==label]\n",
        "        y_true = labels_flat[labels_flat==label]\n",
        "        print(f'Class: {label_dict_inverse[label]}')\n",
        "        print(f'Accuracy:{len(y_preds[y_preds==label])}/{len(y_true)}\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJ_RrFNpmCTS"
      },
      "source": [
        "##  Creating the Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpZPBMVumEky"
      },
      "source": [
        "import random\n",
        "\n",
        "# Setting up the environment\n",
        "\n",
        "seed_val = 17\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKeEK7j3mGMS",
        "outputId": "9a14e333-b421-46b5-a7bb-6fa7fadea3f8"
      },
      "source": [
        "# Setting up the device\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjnnVpRhmL0k"
      },
      "source": [
        " # Defining the evaluation function\n",
        " \n",
        " def evaluate(dataloader_val):\n",
        "\n",
        "    model.eval()\n",
        "    \n",
        "    loss_val_total = 0\n",
        "    predictions, true_vals = [], []\n",
        "    \n",
        "    for batch in tqdm(dataloader_val):\n",
        "        \n",
        "        batch = tuple(b.to(device) for b in batch)\n",
        "        \n",
        "        inputs = {'input_ids':      batch[0],\n",
        "                  'attention_mask': batch[1],\n",
        "                  'labels':         batch[2],\n",
        "                 }\n",
        "\n",
        "        with torch.no_grad():        \n",
        "            outputs = model(**inputs)\n",
        "            \n",
        "        loss = outputs[0]\n",
        "        logits = outputs[1]\n",
        "        loss_val_total += loss.item()\n",
        "\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = inputs['labels'].cpu().numpy()\n",
        "        predictions.append(logits)\n",
        "        true_vals.append(label_ids)\n",
        "    \n",
        "    loss_val_avg = loss_val_total/len(dataloader_val) \n",
        "    \n",
        "    predictions = np.concatenate(predictions, axis=0)\n",
        "    true_vals = np.concatenate(true_vals, axis=0)\n",
        "            \n",
        "    return loss_val_avg, predictions, true_vals"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7oMAhaNmQW8"
      },
      "source": [
        "## Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "O94wExL3mR3q",
        "outputId": "b3b7fdd3-61fc-49fb-bf38-ce11d5845c7c"
      },
      "source": [
        "from tqdm.notebook import tqdm\n",
        "\n",
        "for epoch in tqdm(range(1, epochs+1)):\n",
        "    model.train()\n",
        "    loss_train_total = 0\n",
        "    \n",
        "    progress_bar = tqdm(dataloader_train, \n",
        "                        desc='Epoch {:1d}'.format(epoch), \n",
        "                        leave=False, \n",
        "                        disable=False)\n",
        "    \n",
        "    for batch in progress_bar:\n",
        "        model.zero_grad()\n",
        "        batch = tuple(b.to(device) for b in batch)\n",
        "        inputs = {\n",
        "            'input_ids': batch[0],\n",
        "            'attention_mask': batch[1],\n",
        "            'labels': batch[2]\n",
        "        }\n",
        "        \n",
        "        outputs = model(**inputs)\n",
        "        loss = outputs[0]\n",
        "        loss_train_total +=loss.item()\n",
        "        loss.backward()\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        \n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        \n",
        "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})     \n",
        "    \n",
        "    #torch.save(model.state_dict(), f'Models/BERT_ft_Epoch{epoch}.model')\n",
        "    \n",
        "\n",
        "    \n",
        "    loss_train_avg = loss_train_total/len(dataloader_train)\n",
        "    tqdm.write(f'Training loss: {loss_train_avg}')\n",
        "    \n",
        "    val_loss, predictions, true_vals = evaluate(dataloader_val)\n",
        "    val_f1 = f1_score_func(predictions, true_vals)\n",
        "    print(f'Validation loss: {val_loss}')\n",
        "    print(f'F1 Score (weighted): {val_f1}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "04f5b99f183f4a34b098c373d135d8ed",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3e97ee3239bf401188ded9aa27c7a104",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Epoch 1', max=2250.0, style=ProgressStyle(description_wid…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\r\r\r\r\r\r\r\r\rTraining loss: 0.5841976440191372\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "48254d76660247e8833f3bfd8afd7ecb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=32.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Validation loss: 0.7236271155998111\n",
            "F1 Score (weighted): 0.7970300671620828\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzqMVclMmYry"
      },
      "source": [
        "## Evaluation of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1PBNZXrmaia",
        "outputId": "46667c01-b99f-437b-b54a-1a5160497d69"
      },
      "source": [
        " accuracy_per_class(predictions, true_vals)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class: not-hate\n",
            "Accuracy:471/573\n",
            "\n",
            "Class: hate\n",
            "Accuracy:326/427\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0TB9jlC2z70"
      },
      "source": [
        "# **Irony Detection**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KktUuDFcHXta"
      },
      "source": [
        "<font color=\"Orange\" size=5> Using a DistilBERT Pretrained model: 'distilbert-base-uncased-distilled-squad' </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fGeH8qR4ftY"
      },
      "source": [
        "##  Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UATxYhcX23v8",
        "outputId": "8f3c97c7-9da4-45fb-99d9-a50ca6640f4a"
      },
      "source": [
        "pip install pytorch_transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch_transformers in /usr/local/lib/python3.7/dist-packages (1.2.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (0.1.95)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (1.17.55)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (1.8.1+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (4.41.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (0.0.45)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch_transformers) (0.10.0)\n",
            "Requirement already satisfied: botocore<1.21.0,>=1.20.55 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch_transformers) (1.20.55)\n",
            "Requirement already satisfied: s3transfer<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch_transformers) (0.4.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.0->pytorch_transformers) (3.7.4.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_transformers) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_transformers) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch_transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch_transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch_transformers) (1.0.1)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.21.0,>=1.20.55->boto3->pytorch_transformers) (2.8.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwB0Hz5Z4m5I",
        "outputId": "897d86db-9001-4795-9bbc-fbb00d36202e"
      },
      "source": [
        " !pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.5.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.10.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J19u8yXY4o95"
      },
      "source": [
        "##  Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_HDuJnq4sHm",
        "outputId": "b60d92bc-0207-4e1b-bd50-513512bc54a5"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Transforming the mapping into a .csv file\n",
        "\n",
        "with open('./source/irony/mapping.txt') as file:\n",
        "  matrix = []\n",
        "  for line in file:\n",
        "    splits = line.split('\\t')\n",
        "    row = {}\n",
        "    row['Code'] = splits[0]\n",
        "    row['Irony'] = splits[1].rstrip()\n",
        "    matrix.append(row)\n",
        "  mapping = pd.DataFrame(matrix)\n",
        "\n",
        "mapping.to_csv('./source/irony/mapping.csv', index=False)\n",
        "mapping"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Code</th>\n",
              "      <th>Irony</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>non_irony</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>irony</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Code      Irony\n",
              "0    0  non_irony\n",
              "1    1      irony"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 439
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9NHkIrbp5XYR",
        "outputId": "6e3af51a-1bca-4ce7-c577-b3ae78f091cd"
      },
      "source": [
        "# Transforming the .txt files and creating the train dataset\n",
        "\n",
        "with open('./source/irony/train_text.txt') as train_text, open('./source/irony/train_labels.txt') as train_labels:\n",
        "  matrix = []\n",
        "  ironies = pd.read_csv('./source/irony/mapping.csv')\n",
        "  for text, label in zip(train_text, train_labels):\n",
        "    irony = ironies.loc[ironies['Code'] == int(label), 'Irony'].item()\n",
        "    row = {}\n",
        "    row['text'] = text.rstrip()\n",
        "    row['irony'] = int(label)\n",
        "    row['target'] = irony\n",
        "    matrix.append(row)\n",
        "  train = pd.DataFrame(matrix)\n",
        "\n",
        "train.to_csv('./source/irony/train.csv', index=False)\n",
        "train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>irony</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>seeing ppl walking w/ crutches makes me really...</td>\n",
              "      <td>1</td>\n",
              "      <td>irony</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>look for the girl with the broken smile, ask h...</td>\n",
              "      <td>0</td>\n",
              "      <td>non_irony</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Now I remember why I buy books online @user #s...</td>\n",
              "      <td>1</td>\n",
              "      <td>irony</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@user @user So is he banded from wearing the c...</td>\n",
              "      <td>1</td>\n",
              "      <td>irony</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Just found out there are Etch A Sketch apps.  ...</td>\n",
              "      <td>1</td>\n",
              "      <td>irony</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2857</th>\n",
              "      <td>I don't have to respect your beliefs.||I only ...</td>\n",
              "      <td>0</td>\n",
              "      <td>non_irony</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2858</th>\n",
              "      <td>Women getting hit on by married managers at @u...</td>\n",
              "      <td>1</td>\n",
              "      <td>irony</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2859</th>\n",
              "      <td>@user no but i followed you and i saw you post...</td>\n",
              "      <td>0</td>\n",
              "      <td>non_irony</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2860</th>\n",
              "      <td>@user I dont know what it is but I'm in love y...</td>\n",
              "      <td>0</td>\n",
              "      <td>non_irony</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2861</th>\n",
              "      <td>@user @user @user For having union representat...</td>\n",
              "      <td>1</td>\n",
              "      <td>irony</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2862 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text  irony     target\n",
              "0     seeing ppl walking w/ crutches makes me really...      1      irony\n",
              "1     look for the girl with the broken smile, ask h...      0  non_irony\n",
              "2     Now I remember why I buy books online @user #s...      1      irony\n",
              "3     @user @user So is he banded from wearing the c...      1      irony\n",
              "4     Just found out there are Etch A Sketch apps.  ...      1      irony\n",
              "...                                                 ...    ...        ...\n",
              "2857  I don't have to respect your beliefs.||I only ...      0  non_irony\n",
              "2858  Women getting hit on by married managers at @u...      1      irony\n",
              "2859  @user no but i followed you and i saw you post...      0  non_irony\n",
              "2860  @user I dont know what it is but I'm in love y...      0  non_irony\n",
              "2861  @user @user @user For having union representat...      1      irony\n",
              "\n",
              "[2862 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 440
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17K3-eq25wkz",
        "outputId": "da91b3ab-3cfe-438c-d6c2-5d08cd6650c8"
      },
      "source": [
        "# Transforming the .txt files and creating the test dataset\n",
        "\n",
        "with open('./source/irony/test_text.txt') as test_text, open('./source/irony/test_labels.txt') as test_labels:\n",
        "  matrix = []\n",
        "  ironies = pd.read_csv('./source/irony/mapping.csv')\n",
        "  for text, label in zip(test_text, test_labels):\n",
        "    irony = ironies.loc[ironies['Code'] == int(label), 'Irony'].item()\n",
        "    row = {}\n",
        "    row['text'] = text.rstrip()\n",
        "    row['irony'] = int(label)\n",
        "    row['target'] = irony\n",
        "    matrix.append(row)\n",
        "  test = pd.DataFrame(matrix)\n",
        "\n",
        "test.to_csv('./source/irony/test.csv', index=False)\n",
        "test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>irony</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@user Can U Help?||More conservatives needed o...</td>\n",
              "      <td>0</td>\n",
              "      <td>non_irony</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Just walked in to #Starbucks and asked for a \"...</td>\n",
              "      <td>1</td>\n",
              "      <td>irony</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>#NOT GONNA WIN</td>\n",
              "      <td>0</td>\n",
              "      <td>non_irony</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@user He is exactly that sort of person. Weirdo!</td>\n",
              "      <td>0</td>\n",
              "      <td>non_irony</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>So much #sarcasm at work mate 10/10 #boring 10...</td>\n",
              "      <td>1</td>\n",
              "      <td>irony</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>779</th>\n",
              "      <td>If you drag yesterday into today, your tomorro...</td>\n",
              "      <td>0</td>\n",
              "      <td>non_irony</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>780</th>\n",
              "      <td>Congrats to my fav @user &amp; her team &amp; my birth...</td>\n",
              "      <td>0</td>\n",
              "      <td>non_irony</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>781</th>\n",
              "      <td>@user Jessica sheds tears at her fan signing e...</td>\n",
              "      <td>0</td>\n",
              "      <td>non_irony</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>782</th>\n",
              "      <td>#Irony: al jazeera is pro Anti - #GamerGate be...</td>\n",
              "      <td>1</td>\n",
              "      <td>irony</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>783</th>\n",
              "      <td>#NOT ALL 👌 There good &amp; bad in every occupatio...</td>\n",
              "      <td>0</td>\n",
              "      <td>non_irony</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>784 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  text  irony     target\n",
              "0    @user Can U Help?||More conservatives needed o...      0  non_irony\n",
              "1    Just walked in to #Starbucks and asked for a \"...      1      irony\n",
              "2                                       #NOT GONNA WIN      0  non_irony\n",
              "3     @user He is exactly that sort of person. Weirdo!      0  non_irony\n",
              "4    So much #sarcasm at work mate 10/10 #boring 10...      1      irony\n",
              "..                                                 ...    ...        ...\n",
              "779  If you drag yesterday into today, your tomorro...      0  non_irony\n",
              "780  Congrats to my fav @user & her team & my birth...      0  non_irony\n",
              "781  @user Jessica sheds tears at her fan signing e...      0  non_irony\n",
              "782  #Irony: al jazeera is pro Anti - #GamerGate be...      1      irony\n",
              "783  #NOT ALL 👌 There good & bad in every occupatio...      0  non_irony\n",
              "\n",
              "[784 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 441
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6k0Oe-E58DA",
        "outputId": "329364b8-15a8-4474-d9b0-d88483d95ae7"
      },
      "source": [
        "# Transforming the .txt files and creating the validation dataset\n",
        "\n",
        "with open('./source/irony/val_text.txt') as val_text, open('./source/irony/val_labels.txt') as val_labels:\n",
        "  matrix = []\n",
        "  ironies = pd.read_csv('./source/irony/mapping.csv')\n",
        "  for text, label in zip(val_text, val_labels):\n",
        "    irony = ironies.loc[ironies['Code'] == int(label), 'Irony'].item()\n",
        "    row = {}\n",
        "    row['text'] = text.rstrip()\n",
        "    row['irony'] = int(label)\n",
        "    row['target'] = irony\n",
        "    matrix.append(row)\n",
        "  val = pd.DataFrame(matrix)\n",
        "\n",
        "val.to_csv('./source/irony/val.csv', index=False)\n",
        "val"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>irony</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>#NBA players #NY support protests of #police k...</td>\n",
              "      <td>1</td>\n",
              "      <td>irony</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A new year about to start|So many people came ...</td>\n",
              "      <td>0</td>\n",
              "      <td>non_irony</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Obama's $1,176,120.90 in Taxpayer Funded Cost...</td>\n",
              "      <td>1</td>\n",
              "      <td>irony</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Can't wait to work with the dream team again t...</td>\n",
              "      <td>1</td>\n",
              "      <td>irony</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>!!! RT @user Of all the places to get stuck in...</td>\n",
              "      <td>1</td>\n",
              "      <td>irony</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>950</th>\n",
              "      <td>Abraham was actually from modern day Iraq (Ur ...</td>\n",
              "      <td>0</td>\n",
              "      <td>non_irony</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>951</th>\n",
              "      <td>@user which one is more disturbing dan? Tickli...</td>\n",
              "      <td>1</td>\n",
              "      <td>irony</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>952</th>\n",
              "      <td>@user @user haha that's cool! I had a feeling ...</td>\n",
              "      <td>0</td>\n",
              "      <td>non_irony</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>953</th>\n",
              "      <td>@user @user Let the Western bastards bank acco...</td>\n",
              "      <td>1</td>\n",
              "      <td>irony</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>954</th>\n",
              "      <td>FALSE, slavery was based on economics, @user @...</td>\n",
              "      <td>0</td>\n",
              "      <td>non_irony</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>955 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  text  irony     target\n",
              "0    #NBA players #NY support protests of #police k...      1      irony\n",
              "1    A new year about to start|So many people came ...      0  non_irony\n",
              "2     Obama's $1,176,120.90 in Taxpayer Funded Cost...      1      irony\n",
              "3    Can't wait to work with the dream team again t...      1      irony\n",
              "4    !!! RT @user Of all the places to get stuck in...      1      irony\n",
              "..                                                 ...    ...        ...\n",
              "950  Abraham was actually from modern day Iraq (Ur ...      0  non_irony\n",
              "951  @user which one is more disturbing dan? Tickli...      1      irony\n",
              "952  @user @user haha that's cool! I had a feeling ...      0  non_irony\n",
              "953  @user @user Let the Western bastards bank acco...      1      irony\n",
              "954  FALSE, slavery was based on economics, @user @...      0  non_irony\n",
              "\n",
              "[955 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 442
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xxyWp_VJ1v0",
        "outputId": "432b3efc-129d-490f-a442-736cb11a9684"
      },
      "source": [
        "train.groupby(['irony']).count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>irony</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1417</td>\n",
              "      <td>1417</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1445</td>\n",
              "      <td>1445</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       text  target\n",
              "irony              \n",
              "0      1417    1417\n",
              "1      1445    1445"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 443
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUQGTNTs4sg_"
      },
      "source": [
        "##  Loading Tokenizer and Encoding our Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGoDx8i94vT3"
      },
      "source": [
        "from transformers import DistilBertTokenizer\n",
        "from torch.utils.data import TensorDataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkpXn8_F6aJ0"
      },
      "source": [
        "# Importing the tokenizer for the model\n",
        "\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased-distilled-squad\", use_fast=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZPGqXRD6fwf",
        "outputId": "667a35fc-ca14-438b-a1b6-3016e51c6827"
      },
      "source": [
        "import torch\n",
        "\n",
        "# Encoding the data\n",
        "\n",
        "encoded_data_train = tokenizer.batch_encode_plus(\n",
        "    train.text.values,\n",
        "    add_special_tokens=True,\n",
        "    return_attention_mask=True,\n",
        "    pad_to_max_length=True,\n",
        "    max_length=256,\n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "encoded_data_val = tokenizer.batch_encode_plus(\n",
        "    val.text.values,\n",
        "    add_special_tokens=True,\n",
        "    return_attention_mask=True,\n",
        "    pad_to_max_length=True,\n",
        "    max_length=256,\n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "input_ids_train = encoded_data_train['input_ids']\n",
        "attention_masks_train = encoded_data_train['attention_mask']\n",
        "labels_train = torch.tensor(train.irony.values)\n",
        "\n",
        "input_ids_val = encoded_data_val['input_ids']\n",
        "attention_masks_val = encoded_data_val['attention_mask']\n",
        "labels_val = torch.tensor(val.irony.values)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNbeJWBq6oUQ",
        "outputId": "dc2ab973-1830-43c8-aec9-55e05c22d26e"
      },
      "source": [
        "# Creating the tensor datasets\n",
        "\n",
        "dataset_train = TensorDataset(input_ids_train, \n",
        "                              attention_masks_train,\n",
        "                              labels_train)\n",
        "\n",
        "dataset_val = TensorDataset(input_ids_val, \n",
        "                            attention_masks_val,\n",
        "                           labels_val)\n",
        "\n",
        "dataset_val.tensors"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 101, 1001, 6452,  ...,    0,    0,    0],\n",
              "         [ 101, 1037, 2047,  ...,    0,    0,    0],\n",
              "         [ 101, 8112, 1005,  ...,    0,    0,    0],\n",
              "         ...,\n",
              "         [ 101, 1030, 5310,  ...,    0,    0,    0],\n",
              "         [ 101, 1030, 5310,  ...,    0,    0,    0],\n",
              "         [ 101, 6270, 1010,  ...,    0,    0,    0]]),\n",
              " tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         ...,\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
              " tensor([1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0,\n",
              "         1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1,\n",
              "         1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1,\n",
              "         1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1,\n",
              "         0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0,\n",
              "         0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
              "         1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0,\n",
              "         1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
              "         0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1,\n",
              "         0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1,\n",
              "         0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
              "         1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1,\n",
              "         0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
              "         0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1,\n",
              "         1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1,\n",
              "         1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1,\n",
              "         1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0,\n",
              "         0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1,\n",
              "         1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0,\n",
              "         0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1,\n",
              "         1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
              "         0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1,\n",
              "         0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0,\n",
              "         0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
              "         1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0,\n",
              "         1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1,\n",
              "         0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
              "         1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1,\n",
              "         1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0,\n",
              "         0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1,\n",
              "         1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1,\n",
              "         1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0,\n",
              "         1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 447
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amIERp164v2J"
      },
      "source": [
        " ## Setting up DistilBERT Pretrained Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09yiaKQr6v_v"
      },
      "source": [
        "from transformers import DistilBertForSequenceClassification"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFooKjbp6zf_"
      },
      "source": [
        "# Creating a dictionary with the possible labels for input\n",
        "\n",
        "label_dict = {}\n",
        "possible_labels = mapping['Irony'].unique()\n",
        "\n",
        "for index, possible_label in enumerate(possible_labels):\n",
        "    label_dict[possible_label] = index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1dJwdN7614n",
        "outputId": "9333d717-2fef-4250-88db-a804342aa085"
      },
      "source": [
        "# Importing the model\n",
        "\n",
        "model = DistilBertForSequenceClassification.from_pretrained(\n",
        "                                      'distilbert-base-uncased-distilled-squad', \n",
        "                                      num_labels = len(label_dict),\n",
        "                                      output_attentions = False,\n",
        "                                      output_hidden_states = False\n",
        "                                     )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased-distilled-squad were not used when initializing DistilBertForSequenceClassification: ['qa_outputs.weight', 'qa_outputs.bias']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased-distilled-squad and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWROiXO767wx"
      },
      "source": [
        "##  Creating Data Loaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fixAwO_9699P"
      },
      "source": [
        "batch_size = 3\n",
        "\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "dataloader_train = DataLoader(\n",
        "    dataset_train,\n",
        "    sampler=RandomSampler(dataset_train),\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "dataloader_val = DataLoader(\n",
        "    dataset_val,\n",
        "    sampler=RandomSampler(dataset_val),\n",
        "    batch_size=5\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdvDi22-7DcR"
      },
      "source": [
        "##  Setting Up Optimizer and Scheduler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUoD-2Nl7FgU"
      },
      "source": [
        "from transformers import AdamW\n",
        "\n",
        "# Setting up the optimizer\n",
        "\n",
        "optimizer = AdamW(\n",
        "    model.parameters(),\n",
        "    lr = 1e-5,\n",
        "    eps = 1e-8\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNsjw3iV7MTI"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Setting up the scheduler\n",
        "\n",
        "epochs = 3\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps = len(dataloader_train)*epochs\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fb-GWEcJ7PwN"
      },
      "source": [
        "## Defining the Performance Metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLiLaW137X1I"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oCQCRM17ZZf"
      },
      "source": [
        "# Defining the f1 score metric\n",
        "\n",
        "def f1_score_func(preds, labels):\n",
        "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return f1_score(labels_flat, preds_flat, average = 'weighted')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQbSIWNt7bPf"
      },
      "source": [
        "# Defining the accuracy per class metric\n",
        "\n",
        "def accuracy_per_class(preds, labels):\n",
        "    label_dict_inverse = {v: k for k, v in label_dict.items()}\n",
        "    \n",
        "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    \n",
        "    for label in np.unique(labels_flat):\n",
        "        y_preds = preds_flat[labels_flat==label]\n",
        "        y_true = labels_flat[labels_flat==label]\n",
        "        print(f'Class: {label_dict_inverse[label]}')\n",
        "        print(f'Accuracy:{len(y_preds[y_preds==label])}/{len(y_true)}\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcPPG4Eg7d5n"
      },
      "source": [
        "##  Creating the Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAJbrozK7ewf"
      },
      "source": [
        "# Setting up the environment\n",
        "\n",
        "import random\n",
        "\n",
        "seed_val = 17\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hn6fEvE-7gx_",
        "outputId": "cc2b4ae6-bca7-4c59-da08-dd56b5856786"
      },
      "source": [
        "# Setting up the device\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iqxEMOo7ja7"
      },
      "source": [
        "# Defining the evaluation function\n",
        "\n",
        "def evaluate(dataloader_val):\n",
        "\n",
        "    model.eval()\n",
        "    \n",
        "    loss_val_total = 0\n",
        "    predictions, true_vals = [], []\n",
        "    \n",
        "    for batch in tqdm(dataloader_val):\n",
        "        \n",
        "        batch = tuple(b.to(device) for b in batch)\n",
        "        \n",
        "        inputs = {'input_ids':      batch[0],\n",
        "                  'attention_mask': batch[1],\n",
        "                  'labels':         batch[2],\n",
        "                 }\n",
        "\n",
        "        with torch.no_grad():        \n",
        "            outputs = model(**inputs)\n",
        "            \n",
        "        loss = outputs[0]\n",
        "        logits = outputs[1]\n",
        "        loss_val_total += loss.item()\n",
        "\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = inputs['labels'].cpu().numpy()\n",
        "        predictions.append(logits)\n",
        "        true_vals.append(label_ids)\n",
        "    \n",
        "    loss_val_avg = loss_val_total/len(dataloader_val) \n",
        "    \n",
        "    predictions = np.concatenate(predictions, axis=0)\n",
        "    true_vals = np.concatenate(true_vals, axis=0)\n",
        "            \n",
        "    return loss_val_avg, predictions, true_vals"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLZEC7Q17oMA"
      },
      "source": [
        "## Training the model, making the prediction and calculating the performance metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "id": "_mOPCNPI7pxv",
        "outputId": "661c0a3c-9e58-4fcd-c013-adf41e53e5e2"
      },
      "source": [
        "from tqdm.notebook import tqdm\n",
        "\n",
        "for epoch in tqdm(range(1, epochs+1)):\n",
        "    model.train()\n",
        "    loss_train_total = 0\n",
        "    \n",
        "    progress_bar = tqdm(dataloader_train, \n",
        "                        desc='Epoch {:1d}'.format(epoch), \n",
        "                        leave=False, \n",
        "                        disable=False)\n",
        "    \n",
        "    for batch in progress_bar:\n",
        "        model.zero_grad()\n",
        "        batch = tuple(b.to(device) for b in batch)\n",
        "        inputs = {\n",
        "            'input_ids': batch[0],\n",
        "            'attention_mask': batch[1],\n",
        "            'labels': batch[2]\n",
        "        }\n",
        "        \n",
        "        outputs = model(**inputs)\n",
        "        loss = outputs[0]\n",
        "        loss_train_total +=loss.item()\n",
        "        loss.backward()\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        \n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        \n",
        "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})     \n",
        "    \n",
        "    #torch.save(model.state_dict(), f'Models/BERT_ft_Epoch{epoch}.model')\n",
        "    \n",
        "\n",
        "    \n",
        "    loss_train_avg = loss_train_total/len(dataloader_train)\n",
        "    tqdm.write(f'Training loss: {loss_train_avg}')\n",
        "    \n",
        "    val_loss, predictions, true_vals = evaluate(dataloader_val)\n",
        "    val_f1 = f1_score_func(predictions, true_vals)\n",
        "    print(f'Validation loss: {val_loss}')\n",
        "    print(f'F1 Score (weighted): {val_f1}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fd2604469ba1488eac29c6f0e18aff12",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3dd4d71bf6664b388c775d1c9c2ee1b9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Epoch 1', max=954.0, style=ProgressStyle(description_widt…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\r\r\r\r\r\r\r\r\r\r\r\r\r\r\r\r\r\r\r\r\r\r\r\r\r\rTraining loss: 0.6527713685759209\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d5c7275a5c944fc88a7c03cdb14d922d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=191.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Validation loss: 0.6197772813249008\n",
            "F1 Score (weighted): 0.6605352188355637\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "849e7acc06af4770a1969cc1600ad96e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Epoch 2', max=954.0, style=ProgressStyle(description_widt…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\r\r\r\r\r\r\r\r\r\r\r\r\r\r\r\r\r\r\r\r\r\r\r\r\r\rTraining loss: 0.5388618419903567\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c3ee7d9b0811409098adb349a6505e46",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=191.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Validation loss: 0.8309663156564323\n",
            "F1 Score (weighted): 0.662558035938622\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f0c0258facb4433391a850020022f621",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Epoch 3', max=954.0, style=ProgressStyle(description_widt…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\r\r\r\r\r\r\r\r\r\r\r\r\r\r\r\r\r\r\r\r\r\r\r\r\r\rTraining loss: 0.4476918964061019\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5a6edfeb4801455c8e63fac4bea65432",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=191.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Validation loss: 1.1137144400650412\n",
            "F1 Score (weighted): 0.6712474503294743\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dzIlycq7uPt"
      },
      "source": [
        "##  Evaluating the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKt_sZAr7wDh",
        "outputId": "a52cf405-0c1d-46de-914a-3cbd494fe76e"
      },
      "source": [
        "accuracy_per_class(predictions, true_vals)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class: non_irony\n",
            "Accuracy:322/499\n",
            "\n",
            "Class: irony\n",
            "Accuracy:319/456\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpgPcWXF25Fm"
      },
      "source": [
        "# **Offensive Language Identification**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SZl6BgUR__h"
      },
      "source": [
        "<font color=\"Orange\" size=5> Using an ALBERT Pretrained model: 'albert-base-v2' </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LfTxhjaOfVL"
      },
      "source": [
        "##  Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Asz-POuQOxXx",
        "outputId": "e610461d-ed0e-41de-e5e7-c59c0bb0c3bd"
      },
      "source": [
        " pip install pytorch_transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch_transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/b7/d3d18008a67e0b968d1ab93ad444fc05699403fa662f634b2f2c318a508b/pytorch_transformers-1.2.0-py3-none-any.whl (176kB)\n",
            "\r\u001b[K     |█▉                              | 10kB 14.3MB/s eta 0:00:01\r\u001b[K     |███▊                            | 20kB 18.9MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 30kB 17.2MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 40kB 12.5MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 51kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 61kB 13.8MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 71kB 12.9MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 81kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 92kB 10.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 102kB 10.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 112kB 10.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 122kB 10.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 133kB 10.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 143kB 10.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 153kB 10.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 163kB 10.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 174kB 10.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 184kB 10.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (2019.12.20)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 11.6MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 37.7MB/s \n",
            "\u001b[?25hCollecting boto3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/f2/52bf45246ad421cdd8c80a5c0f3e8f082e818d0467cde6aa8294258d1b4a/boto3-1.17.55-py2.py3-none-any.whl (131kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 39.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (2.23.0)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (1.8.1+cu101)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (4.41.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch_transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch_transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch_transformers) (1.0.1)\n",
            "Collecting botocore<1.21.0,>=1.20.55\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c5/b0/d382d472989ce23bee0a36f8bd0c326d4694496611a7fe41fae51d71bf46/botocore-1.20.55-py2.py3-none-any.whl (7.4MB)\n",
            "\u001b[K     |████████████████████████████████| 7.4MB 39.3MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Collecting s3transfer<0.5.0,>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/95/91a1b99e4ef46bb915167b04aa26aec74dad5356d13d487a90f7d22994ee/s3transfer-0.4.1-py2.py3-none-any.whl (79kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 7.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_transformers) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_transformers) (2.10)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.0->pytorch_transformers) (3.7.4.3)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.21.0,>=1.20.55->boto3->pytorch_transformers) (2.8.1)\n",
            "\u001b[31mERROR: botocore 1.20.55 has requirement urllib3<1.27,>=1.25.4, but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: sentencepiece, sacremoses, jmespath, botocore, s3transfer, boto3, pytorch-transformers\n",
            "Successfully installed boto3-1.17.55 botocore-1.20.55 jmespath-0.10.0 pytorch-transformers-1.2.0 s3transfer-0.4.1 sacremoses-0.0.45 sentencepiece-0.1.95\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmEVzYu128u1",
        "outputId": "14155830-b2bf-452b-f4a2-01b0369093d5"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/b2/57495b5309f09fa501866e225c84532d1fd89536ea62406b2181933fb418/transformers-4.5.1-py3-none-any.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 11.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 36.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.10.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Installing collected packages: tokenizers, transformers\n",
            "Successfully installed tokenizers-0.10.2 transformers-4.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3O0y5qmO1Gz"
      },
      "source": [
        "##  Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bW_YsH_O3Zn",
        "outputId": "12d1a538-039c-4dab-ac97-63b81cb0f396"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Transforming the mapping into a .csv file\n",
        "\n",
        "with open('./source/offensive/mapping.txt') as file:\n",
        "  matrix = []\n",
        "  for line in file:\n",
        "    splits = line.split('\\t')\n",
        "    row = {}\n",
        "    row['Code'] = splits[0]\n",
        "    row['Offensive'] = splits[1].rstrip()\n",
        "    matrix.append(row)\n",
        "  mapping = pd.DataFrame(matrix)\n",
        "\n",
        "mapping.to_csv('./source/offensive/mapping.csv', index=False)\n",
        "mapping"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Code</th>\n",
              "      <th>Offensive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>not-offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>offensive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Code      Offensive\n",
              "0    0  not-offensive\n",
              "1    1      offensive"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-LYDnGpiO9tE",
        "outputId": "1cd41190-cbeb-4606-a747-b03f8441c3fe"
      },
      "source": [
        "# Transforming the .txt files and creating the train dataset\n",
        "\n",
        "with open('./source/offensive/train_text.txt') as train_text, open('./source/offensive/train_labels.txt') as train_labels:\n",
        "  matrix = []\n",
        "  off_languages = pd.read_csv('./source/offensive/mapping.csv')\n",
        "  for text, label in zip(train_text, train_labels):\n",
        "    offensive = off_languages.loc[off_languages['Code'] == int(label), 'Offensive'].item()\n",
        "    row = {}\n",
        "    row['text'] = text.rstrip()\n",
        "    row['offensive'] = int(label)\n",
        "    row['target'] = offensive\n",
        "    matrix.append(row)\n",
        "  train = pd.DataFrame(matrix)\n",
        "\n",
        "train.to_csv('./source/offensive/train.csv', index=False)\n",
        "train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>offensive</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@user Bono... who cares. Soon people will unde...</td>\n",
              "      <td>0</td>\n",
              "      <td>not-offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@user Eight years the republicans denied obama...</td>\n",
              "      <td>1</td>\n",
              "      <td>offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@user Get him some line help. He is gonna be j...</td>\n",
              "      <td>0</td>\n",
              "      <td>not-offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@user @user She is great. Hi Fiona!</td>\n",
              "      <td>0</td>\n",
              "      <td>not-offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@user She has become a parody unto herself? Sh...</td>\n",
              "      <td>1</td>\n",
              "      <td>offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11911</th>\n",
              "      <td>@user I wonder if they are sex traffic victims?</td>\n",
              "      <td>1</td>\n",
              "      <td>offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11912</th>\n",
              "      <td>@user Do we dare say he is... better than Nyjer?</td>\n",
              "      <td>0</td>\n",
              "      <td>not-offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11913</th>\n",
              "      <td>@user No idea who he is. Sorry</td>\n",
              "      <td>0</td>\n",
              "      <td>not-offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11914</th>\n",
              "      <td>#Professor Who Shot Self Over Trump Says Gun C...</td>\n",
              "      <td>0</td>\n",
              "      <td>not-offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11915</th>\n",
              "      <td>@user @user @user Here your proof!  Our Africa...</td>\n",
              "      <td>1</td>\n",
              "      <td>offensive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11916 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    text  ...         target\n",
              "0      @user Bono... who cares. Soon people will unde...  ...  not-offensive\n",
              "1      @user Eight years the republicans denied obama...  ...      offensive\n",
              "2      @user Get him some line help. He is gonna be j...  ...  not-offensive\n",
              "3                    @user @user She is great. Hi Fiona!  ...  not-offensive\n",
              "4      @user She has become a parody unto herself? Sh...  ...      offensive\n",
              "...                                                  ...  ...            ...\n",
              "11911    @user I wonder if they are sex traffic victims?  ...      offensive\n",
              "11912   @user Do we dare say he is... better than Nyjer?  ...  not-offensive\n",
              "11913                     @user No idea who he is. Sorry  ...  not-offensive\n",
              "11914  #Professor Who Shot Self Over Trump Says Gun C...  ...  not-offensive\n",
              "11915  @user @user @user Here your proof!  Our Africa...  ...      offensive\n",
              "\n",
              "[11916 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhFe8cg9PRom",
        "outputId": "ff689ac2-6c9f-42ee-9a1a-648790eb9fa0"
      },
      "source": [
        "# Transforming the .txt files and creating the test dataset\n",
        "\n",
        "with open('./source/offensive/test_text.txt') as test_text, open('./source/offensive/test_labels.txt') as test_labels:\n",
        "  matrix = []\n",
        "  off_languages = pd.read_csv('./source/offensive/mapping.csv')\n",
        "  for text, label in zip(test_text, test_labels):\n",
        "    offensive = off_languages.loc[off_languages['Code'] == int(label), 'Offensive'].item()\n",
        "    row = {}\n",
        "    row['text'] = text.rstrip()\n",
        "    row['offensive'] = int(label)\n",
        "    row['target'] = offensive\n",
        "    matrix.append(row)\n",
        "  test = pd.DataFrame(matrix)\n",
        "\n",
        "test.to_csv('./source/offensive/test.csv', index=False)\n",
        "test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>offensive</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>#ibelieveblaseyford is liar she is fat ugly li...</td>\n",
              "      <td>1</td>\n",
              "      <td>offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@user @user @user I got in a pretty deep debat...</td>\n",
              "      <td>0</td>\n",
              "      <td>not-offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>...if you want more shootings and more death, ...</td>\n",
              "      <td>0</td>\n",
              "      <td>not-offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Angels now have 6 runs. Five of them have come...</td>\n",
              "      <td>0</td>\n",
              "      <td>not-offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>#Travel #Movies and Unix #Fortune combined  Vi...</td>\n",
              "      <td>0</td>\n",
              "      <td>not-offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>855</th>\n",
              "      <td>#CNN irrationally argues 4 legalising #abortio...</td>\n",
              "      <td>0</td>\n",
              "      <td>not-offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>856</th>\n",
              "      <td>@user @user @user @user @user @user @user @use...</td>\n",
              "      <td>0</td>\n",
              "      <td>not-offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>857</th>\n",
              "      <td>#Conservatives don’t care what you post..it’s ...</td>\n",
              "      <td>1</td>\n",
              "      <td>offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>858</th>\n",
              "      <td>#antifa #Resist.. Trump is trying to bring wor...</td>\n",
              "      <td>0</td>\n",
              "      <td>not-offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>859</th>\n",
              "      <td>#Maine you need to face facts @user doesn’t re...</td>\n",
              "      <td>0</td>\n",
              "      <td>not-offensive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>860 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  text  ...         target\n",
              "0    #ibelieveblaseyford is liar she is fat ugly li...  ...      offensive\n",
              "1    @user @user @user I got in a pretty deep debat...  ...  not-offensive\n",
              "2    ...if you want more shootings and more death, ...  ...  not-offensive\n",
              "3    Angels now have 6 runs. Five of them have come...  ...  not-offensive\n",
              "4    #Travel #Movies and Unix #Fortune combined  Vi...  ...  not-offensive\n",
              "..                                                 ...  ...            ...\n",
              "855  #CNN irrationally argues 4 legalising #abortio...  ...  not-offensive\n",
              "856  @user @user @user @user @user @user @user @use...  ...  not-offensive\n",
              "857  #Conservatives don’t care what you post..it’s ...  ...      offensive\n",
              "858  #antifa #Resist.. Trump is trying to bring wor...  ...  not-offensive\n",
              "859  #Maine you need to face facts @user doesn’t re...  ...  not-offensive\n",
              "\n",
              "[860 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UUyQ-zvPSZB",
        "outputId": "80128b4e-0c60-4ca8-a18b-6fec34d90b00"
      },
      "source": [
        "# Transforming the .txt files and creating the validation dataset\n",
        "\n",
        "with open('./source/offensive/val_text.txt') as val_text, open('./source/offensive/val_labels.txt') as val_labels:\n",
        "  matrix = []\n",
        "  off_languages = pd.read_csv('./source/offensive/mapping.csv')\n",
        "  for text, label in zip(val_text, val_labels):\n",
        "    offensive = off_languages.loc[off_languages['Code'] == int(label), 'Offensive'].item()\n",
        "    row = {}\n",
        "    row['text'] = text.rstrip()\n",
        "    row['offensive'] = int(label)\n",
        "    row['target'] = offensive\n",
        "    matrix.append(row)\n",
        "  val = pd.DataFrame(matrix)\n",
        "\n",
        "val.to_csv('./source/offensive/val.csv', index=False)\n",
        "val"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>offensive</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@user @user WiiU is not even a real console.</td>\n",
              "      <td>0</td>\n",
              "      <td>not-offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@user @user @user If he is from AZ I would put...</td>\n",
              "      <td>1</td>\n",
              "      <td>offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@user I thought Canada had strict gun control....</td>\n",
              "      <td>0</td>\n",
              "      <td>not-offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@user @user @user @user @user @user @user @use...</td>\n",
              "      <td>0</td>\n",
              "      <td>not-offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1 Minute of Truth: Gun Control via @user</td>\n",
              "      <td>0</td>\n",
              "      <td>not-offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1319</th>\n",
              "      <td>@user @user Whose twitter interest start with ...</td>\n",
              "      <td>0</td>\n",
              "      <td>not-offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1320</th>\n",
              "      <td>@user @user How did the press\"\" get the letter...</td>\n",
              "      <td>0</td>\n",
              "      <td>not-offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1321</th>\n",
              "      <td>@user @user @user @user @user @user Sorry abou...</td>\n",
              "      <td>0</td>\n",
              "      <td>not-offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1322</th>\n",
              "      <td>@user Fuck Alan I’m sorry</td>\n",
              "      <td>1</td>\n",
              "      <td>offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1323</th>\n",
              "      <td>#Tories #Labour #GE2017 #Conservatives Conserv...</td>\n",
              "      <td>0</td>\n",
              "      <td>not-offensive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1324 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text  ...         target\n",
              "0          @user @user WiiU is not even a real console.  ...  not-offensive\n",
              "1     @user @user @user If he is from AZ I would put...  ...      offensive\n",
              "2     @user I thought Canada had strict gun control....  ...  not-offensive\n",
              "3     @user @user @user @user @user @user @user @use...  ...  not-offensive\n",
              "4              1 Minute of Truth: Gun Control via @user  ...  not-offensive\n",
              "...                                                 ...  ...            ...\n",
              "1319  @user @user Whose twitter interest start with ...  ...  not-offensive\n",
              "1320  @user @user How did the press\"\" get the letter...  ...  not-offensive\n",
              "1321  @user @user @user @user @user @user Sorry abou...  ...  not-offensive\n",
              "1322                          @user Fuck Alan I’m sorry  ...      offensive\n",
              "1323  #Tories #Labour #GE2017 #Conservatives Conserv...  ...  not-offensive\n",
              "\n",
              "[1324 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6IKc_w0OQUVQ"
      },
      "source": [
        "##  Loading Tokenizer and Encoding the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFpD4fAmQXNR"
      },
      "source": [
        "from transformers import AlbertTokenizer\n",
        "from torch.utils.data import TensorDataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        },
        "id": "HssZejcXQl_a",
        "outputId": "70c4e6a7-fe7d-4218-a56a-2695d7c91c2a"
      },
      "source": [
        "# Importing the tokenizer for the model\n",
        "\n",
        "tokenizer = AlbertTokenizer.from_pretrained(\n",
        "    'albert-base-v2',\n",
        "    do_lower_case=True\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e26fe16d13f641758169e4efaf155ee4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=760289.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6a15d2f9da794326aca6d1cde932fa51",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1312669.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBTwzogxQq0y",
        "outputId": "3a5774aa-05bc-419c-8e66-264700d6ebcc"
      },
      "source": [
        "import torch\n",
        "\n",
        "# Encoding the data\n",
        "\n",
        "encoded_data_train = tokenizer.batch_encode_plus(\n",
        "    train.text.values,\n",
        "    add_special_tokens=True,\n",
        "    return_attention_mask=True,\n",
        "    pad_to_max_length=True,\n",
        "    max_length=256,\n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "encoded_data_val = tokenizer.batch_encode_plus(\n",
        "    val.text.values,\n",
        "    add_special_tokens=True,\n",
        "    return_attention_mask=True,\n",
        "    pad_to_max_length=True,\n",
        "    max_length=256,\n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "input_ids_train = encoded_data_train['input_ids']\n",
        "attention_masks_train = encoded_data_train['attention_mask']\n",
        "labels_train = torch.tensor(train.offensive.values)\n",
        "\n",
        "input_ids_val = encoded_data_val['input_ids']\n",
        "attention_masks_val = encoded_data_val['attention_mask']\n",
        "labels_val = torch.tensor(val.offensive.values)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58FQHAQgQ4Jy",
        "outputId": "0db2b9a0-b762-4ea6-d04b-ed81b775bba5"
      },
      "source": [
        "# Creating the tensor datasets\n",
        "\n",
        "dataset_train = TensorDataset(input_ids_train, \n",
        "                              attention_masks_train,\n",
        "                              labels_train)\n",
        "\n",
        "dataset_val = TensorDataset(input_ids_val, \n",
        "                            attention_masks_val,\n",
        "                           labels_val)\n",
        "\n",
        "dataset_val.tensors"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[   2,   13,    1,  ...,    0,    0,    0],\n",
              "         [   2,   13,    1,  ...,    0,    0,    0],\n",
              "         [   2,   13,    1,  ...,    0,    0,    0],\n",
              "         ...,\n",
              "         [   2,   13,    1,  ...,    0,    0,    0],\n",
              "         [   2,   13,    1,  ...,    0,    0,    0],\n",
              "         [   2, 6926,  262,  ...,    0,    0,    0]]),\n",
              " tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         ...,\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
              " tensor([0, 1, 0,  ..., 0, 1, 0]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPKq_lPaQ6vR"
      },
      "source": [
        "##  Setting up ALBERT Pretrained Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOb1mnokQ9kx"
      },
      "source": [
        "from transformers import AlbertForSequenceClassification"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZuYsEPwRBWy"
      },
      "source": [
        "# Creating a dictionary with the possible labels for input\n",
        "\n",
        "label_dict = {}\n",
        "possible_labels = mapping['Offensive'].unique()\n",
        "\n",
        "for index, possible_label in enumerate(possible_labels):\n",
        "    label_dict[possible_label] = index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZutzmstRHPR",
        "outputId": "31eb35e3-6340-456a-df8d-737079047d51"
      },
      "source": [
        "# Importing the model\n",
        "\n",
        "model = AlbertForSequenceClassification.from_pretrained(\n",
        "                                      'albert-base-v2', \n",
        "                                      num_labels = len(label_dict),\n",
        "                                      output_attentions = False,\n",
        "                                      output_hidden_states = False\n",
        "                                     )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "801e0413a5a24cfc9b97204c61c085be",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=684.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "68519d7a4f2b4b5da6ced0bf76a0a51e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=47376696.0, style=ProgressStyle(descrip…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at albert-base-v2 were not used when initializing AlbertForSequenceClassification: ['predictions.bias', 'predictions.LayerNorm.weight', 'predictions.LayerNorm.bias', 'predictions.dense.weight', 'predictions.dense.bias', 'predictions.decoder.weight', 'predictions.decoder.bias']\n",
            "- This IS expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-base-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i90A5mgfRMSD"
      },
      "source": [
        "##  Creating Data Loaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-ek1vkVRN1m"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "batch_size = 20\n",
        "\n",
        "dataloader_train = DataLoader(\n",
        "    dataset_train,\n",
        "    sampler=RandomSampler(dataset_train),\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "dataloader_val = DataLoader(\n",
        "    dataset_val,\n",
        "    sampler=RandomSampler(dataset_val),\n",
        "    batch_size=32\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFgEdNDBRVxD"
      },
      "source": [
        "##  Setting Up Optimizer and Scheduler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8yDvZ3QRaCV"
      },
      "source": [
        "from transformers import AdamW\n",
        "\n",
        "# Setting up the optimizer\n",
        "\n",
        "optimizer = AdamW(\n",
        "    model.parameters(),\n",
        "    lr = 1e-5,\n",
        "    eps = 1e-8\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whJ17xKQRcL6"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Setting up the scheduler\n",
        "\n",
        "epochs = 1\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps = len(dataloader_train)*epochs\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmAtwXIbRf9x"
      },
      "source": [
        "## Defining the Performance Metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABc3QGuJRjA5"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iv7YAzD_Rjy6"
      },
      "source": [
        "# Defining the f1 score metric\n",
        "\n",
        "def f1_score_func(preds, labels):\n",
        "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return f1_score(labels_flat, preds_flat, average = 'weighted')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufkZRax2Rl9J"
      },
      "source": [
        "# Defining the accuracy per class metric\n",
        "\n",
        "def accuracy_per_class(preds, labels):\n",
        "    label_dict_inverse = {v: k for k, v in label_dict.items()}\n",
        "    \n",
        "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    \n",
        "    for label in np.unique(labels_flat):\n",
        "        y_preds = preds_flat[labels_flat==label]\n",
        "        y_true = labels_flat[labels_flat==label]\n",
        "        print(f'Class: {label_dict_inverse[label]}')\n",
        "        print(f'Accuracy:{len(y_preds[y_preds==label])}/{len(y_true)}\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ry_IorLNRnbi"
      },
      "source": [
        "##  Creating the Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puQ_mAsgRpib"
      },
      "source": [
        "import random\n",
        "\n",
        "# Setting up the environment\n",
        "\n",
        "seed_val = 17\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UImF2RiZRq0p",
        "outputId": "1ab79ad1-d7b1-4b50-b044-ed55005d5967"
      },
      "source": [
        "# Setting up the device\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "torch.cuda.empty_cache() \n",
        "\n",
        "model.to(device)\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gh5gPVpfRtD5"
      },
      "source": [
        "# Defining the evaluation function\n",
        "\n",
        "def evaluate(dataloader_val):\n",
        "\n",
        "    model.eval()\n",
        "    \n",
        "    loss_val_total = 0\n",
        "    predictions, true_vals = [], []\n",
        "    \n",
        "    for batch in tqdm(dataloader_val):\n",
        "        \n",
        "        batch = tuple(b.to(device) for b in batch)\n",
        "        \n",
        "        inputs = {'input_ids':      batch[0],\n",
        "                  'attention_mask': batch[1],\n",
        "                  'labels':         batch[2],\n",
        "                 }\n",
        "\n",
        "        with torch.no_grad():        \n",
        "            outputs = model(**inputs)\n",
        "            \n",
        "        loss = outputs[0]\n",
        "        logits = outputs[1]\n",
        "        loss_val_total += loss.item()\n",
        "\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = inputs['labels'].cpu().numpy()\n",
        "        predictions.append(logits)\n",
        "        true_vals.append(label_ids)\n",
        "    \n",
        "    loss_val_avg = loss_val_total/len(dataloader_val) \n",
        "    \n",
        "    predictions = np.concatenate(predictions, axis=0)\n",
        "    true_vals = np.concatenate(true_vals, axis=0)\n",
        "            \n",
        "    return loss_val_avg, predictions, true_vals"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhvrzsWjR4Bn"
      },
      "source": [
        "## Training the model, making the prediction and calculating the performance metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "ceoCtHGPRvdM",
        "outputId": "18baa0de-2d99-44dd-af5b-f4bb45c06a49"
      },
      "source": [
        "from tqdm.notebook import tqdm\n",
        "\n",
        "for epoch in tqdm(range(1, epochs+1)):\n",
        "    model.train()\n",
        "    loss_train_total = 0\n",
        "    \n",
        "    progress_bar = tqdm(dataloader_train, \n",
        "                        desc='Epoch {:1d}'.format(epoch), \n",
        "                        leave=False, \n",
        "                        disable=False)\n",
        "    \n",
        "    for batch in progress_bar:\n",
        "        model.zero_grad()\n",
        "        batch = tuple(b.to(device) for b in batch)\n",
        "        inputs = {\n",
        "            'input_ids': batch[0],\n",
        "            'attention_mask': batch[1],\n",
        "            'labels': batch[2]\n",
        "        }\n",
        "        \n",
        "        outputs = model(**inputs)\n",
        "        loss = outputs[0]\n",
        "        loss_train_total +=loss.item()\n",
        "        loss.backward()\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        \n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        \n",
        "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})     \n",
        "    \n",
        "    #torch.save(model.state_dict(), f'Models/BERT_ft_Epoch{epoch}.model')\n",
        "    \n",
        "\n",
        "    \n",
        "    loss_train_avg = loss_train_total/len(dataloader_train)\n",
        "    tqdm.write(f'Training loss: {loss_train_avg}')\n",
        "    \n",
        "    val_loss, predictions, true_vals = evaluate(dataloader_val)\n",
        "    val_f1 = f1_score_func(predictions, true_vals)\n",
        "    print(f'Validation loss: {val_loss}')\n",
        "    print(f'F1 Score (weighted): {val_f1}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cc135547a7bb495296400b187f871ee6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ef388281a8b64a0b9ec731e64704caa5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Epoch 1', max=596.0, style=ProgressStyle(description_widt…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\rTraining loss: 0.4844311217233639\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7d21ec5893f7418ab4eb082c415c4493",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=42.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Validation loss: 0.42420835775278865\n",
            "F1 Score (weighted): 0.7987578944874906\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bk8ZTQqaRyfr"
      },
      "source": [
        "##  Evaluating the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7tJXTB0Rz7I",
        "outputId": "e9663cb1-a622-4976-feb0-e0c5c2705cbf"
      },
      "source": [
        "accuracy_per_class(predictions, true_vals)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class: not-offensive\n",
            "Accuracy:756/865\n",
            "\n",
            "Class: offensive\n",
            "Accuracy:305/459\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZpYUuLN29vk"
      },
      "source": [
        "# **Sentiment Analysis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mESOjafmIR2P"
      },
      "source": [
        "<font color=\"Orange\"> </font>\n",
        "<font color=\"Orange\" size=5> Using a BERT Pretrained model: 'bert-large-uncased'</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTQNqhl4xjOj"
      },
      "source": [
        "##  Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yoDnTguI6FLC",
        "outputId": "922b993d-3580-48bd-e9ae-bbc83fe8d007"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/b2/57495b5309f09fa501866e225c84532d1fd89536ea62406b2181933fb418/transformers-4.5.1-py3-none-any.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 8.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 47.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 51.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.10.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Installing collected packages: sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.45 tokenizers-0.10.2 transformers-4.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDLrhehB3Asl",
        "outputId": "66f0ee8f-2b7f-4a86-a58b-e0f8e074d197"
      },
      "source": [
        "pip install pytorch_transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch_transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/b7/d3d18008a67e0b968d1ab93ad444fc05699403fa662f634b2f2c318a508b/pytorch_transformers-1.2.0-py3-none-any.whl (176kB)\n",
            "\r\u001b[K     |█▉                              | 10kB 20.5MB/s eta 0:00:01\r\u001b[K     |███▊                            | 20kB 19.7MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 30kB 11.5MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 40kB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 51kB 7.5MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 61kB 7.4MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 71kB 8.4MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 81kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 92kB 7.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 102kB 8.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 112kB 8.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 122kB 8.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 133kB 8.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 143kB 8.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 153kB 8.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 163kB 8.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 174kB 8.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 184kB 8.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (4.41.1)\n",
            "Collecting boto3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/f2/52bf45246ad421cdd8c80a5c0f3e8f082e818d0467cde6aa8294258d1b4a/boto3-1.17.55-py2.py3-none-any.whl (131kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 8.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (0.0.45)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (1.19.5)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 11.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (1.8.1+cu101)\n",
            "Collecting botocore<1.21.0,>=1.20.55\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c5/b0/d382d472989ce23bee0a36f8bd0c326d4694496611a7fe41fae51d71bf46/botocore-1.20.55-py2.py3-none-any.whl (7.4MB)\n",
            "\u001b[K     |████████████████████████████████| 7.4MB 23.5MB/s \n",
            "\u001b[?25hCollecting s3transfer<0.5.0,>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/95/91a1b99e4ef46bb915167b04aa26aec74dad5356d13d487a90f7d22994ee/s3transfer-0.4.1-py2.py3-none-any.whl (79kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 11.8MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch_transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch_transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch_transformers) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_transformers) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_transformers) (1.24.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.0->pytorch_transformers) (3.7.4.3)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.21.0,>=1.20.55->boto3->pytorch_transformers) (2.8.1)\n",
            "\u001b[31mERROR: botocore 1.20.55 has requirement urllib3<1.27,>=1.25.4, but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: jmespath, botocore, s3transfer, boto3, sentencepiece, pytorch-transformers\n",
            "Successfully installed boto3-1.17.55 botocore-1.20.55 jmespath-0.10.0 pytorch-transformers-1.2.0 s3transfer-0.4.1 sentencepiece-0.1.95\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYl4AWPcxnOS"
      },
      "source": [
        "##  Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SLoFyweZxplK",
        "outputId": "318da43d-a982-40f2-ccd9-95d656671ad3"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Transforming the mapping into a .csv file\n",
        "\n",
        "with open('./source/sentiment/mapping.txt') as file:\n",
        "  matrix = []\n",
        "  for line in file:\n",
        "    splits = line.split('\\t')\n",
        "    row = {}\n",
        "    row['Code'] = splits[0]\n",
        "    row['Sentiment'] = splits[1].rstrip()\n",
        "    matrix.append(row)\n",
        "  mapping = pd.DataFrame(matrix)\n",
        "\n",
        "mapping.to_csv('./source/sentiment/mapping.csv', index=False)\n",
        "mapping"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Code</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Code Sentiment\n",
              "0    0  negative\n",
              "1    1   neutral\n",
              "2    2  positive"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hjdfcDP2KhC",
        "outputId": "31b3916e-79c8-4b33-c46b-bcf416577fb0"
      },
      "source": [
        "# Transforming the .txt files and creating the train dataset\n",
        "\n",
        "with open('./source/sentiment/train_text.txt') as train_text, open('./source/sentiment/train_labels.txt') as train_labels:\n",
        "  matrix = []\n",
        "  sentiments = pd.read_csv('./source/sentiment/mapping.csv')\n",
        "  for text, label in zip(train_text, train_labels):\n",
        "    sentiment = sentiments.loc[sentiments['Code'] == int(label), 'Sentiment'].item()\n",
        "    row = {}\n",
        "    row['text'] = text.rstrip()\n",
        "    row['sentiment'] = int(label)\n",
        "    row['target'] = sentiment\n",
        "    matrix.append(row)\n",
        "  train = pd.DataFrame(matrix)\n",
        "\n",
        "train.to_csv('./source/sentiment/train.txt', index=False)\n",
        "train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Broncineers! Remember that tomorrow we have th...</td>\n",
              "      <td>1</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Not to be outdone by the neighbours, Erdogan i...</td>\n",
              "      <td>1</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Katy Perry - \"You just gotta ignite the light,...</td>\n",
              "      <td>1</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Who\\u2019s going to Concords football game thi...</td>\n",
              "      <td>1</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Do you own a business in Bolder? Then you may ...</td>\n",
              "      <td>1</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45384</th>\n",
              "      <td>Looking forward to the new Jersey Shore starti...</td>\n",
              "      <td>2</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45385</th>\n",
              "      <td>Dreamed I was @user and I spent the night maki...</td>\n",
              "      <td>2</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45386</th>\n",
              "      <td>Kyle is going out for the first time tomorrow ...</td>\n",
              "      <td>2</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45387</th>\n",
              "      <td>Hey happy Friday!!! Today T&amp;amp;P will be givi...</td>\n",
              "      <td>2</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45388</th>\n",
              "      <td>Did anybody notice Jurassic World is currently...</td>\n",
              "      <td>2</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>45389 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    text  sentiment    target\n",
              "0      Broncineers! Remember that tomorrow we have th...          1   neutral\n",
              "1      Not to be outdone by the neighbours, Erdogan i...          1   neutral\n",
              "2      Katy Perry - \"You just gotta ignite the light,...          1   neutral\n",
              "3      Who\\u2019s going to Concords football game thi...          1   neutral\n",
              "4      Do you own a business in Bolder? Then you may ...          1   neutral\n",
              "...                                                  ...        ...       ...\n",
              "45384  Looking forward to the new Jersey Shore starti...          2  positive\n",
              "45385  Dreamed I was @user and I spent the night maki...          2  positive\n",
              "45386  Kyle is going out for the first time tomorrow ...          2  positive\n",
              "45387  Hey happy Friday!!! Today T&amp;P will be givi...          2  positive\n",
              "45388  Did anybody notice Jurassic World is currently...          2  positive\n",
              "\n",
              "[45389 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-27i4OL3H10",
        "outputId": "50ece9ac-c663-4f57-d092-4998cf485950"
      },
      "source": [
        "# Transforming the .txt files and creating the test dataset\n",
        "\n",
        "with open('./source/sentiment/test_text.txt') as test_text, open('./source/sentiment/test_labels.txt') as test_labels:\n",
        "  matrix = []\n",
        "  sentiments = pd.read_csv('./source/sentiment/mapping.csv')\n",
        "  for text, label in zip(test_text, test_labels):\n",
        "    sentiment = sentiments.loc[sentiments['Code'] == int(label), 'Sentiment'].item()\n",
        "    row = {}\n",
        "    row['text'] = text.rstrip()\n",
        "    row['sentiment'] = int(label)\n",
        "    row['target'] = sentiment\n",
        "    matrix.append(row)\n",
        "  test = pd.DataFrame(matrix)\n",
        "\n",
        "test.to_csv('./source/sentiment/test.txt', index=False)\n",
        "test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>#ArianaGrande Ari By Ariana Grande 80% Full #S...</td>\n",
              "      <td>1</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ariana Grande KIIS FM Yours Truly CD listening...</td>\n",
              "      <td>2</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ariana Grande White House Easter Egg Roll in W...</td>\n",
              "      <td>2</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>#CD #Musics Ariana Grande Sweet Like Candy 3.4...</td>\n",
              "      <td>2</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>SIDE TO SIDE 😘 @user #sidetoside #arianagrande...</td>\n",
              "      <td>1</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11901</th>\n",
              "      <td>@user update: Zac Efron kissing a puppy</td>\n",
              "      <td>2</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11902</th>\n",
              "      <td>#zac efron sex pic skins michelle sex</td>\n",
              "      <td>1</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11903</th>\n",
              "      <td>First Look at Neighbors 2 with Zac Efron Shirt...</td>\n",
              "      <td>1</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11904</th>\n",
              "      <td>zac efron poses nude #lovely libra porn</td>\n",
              "      <td>1</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11905</th>\n",
              "      <td>#Fashion #Style The Paperboy (NEW Blu-ray Disc...</td>\n",
              "      <td>1</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11906 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    text  sentiment    target\n",
              "0      #ArianaGrande Ari By Ariana Grande 80% Full #S...          1   neutral\n",
              "1      Ariana Grande KIIS FM Yours Truly CD listening...          2  positive\n",
              "2      Ariana Grande White House Easter Egg Roll in W...          2  positive\n",
              "3      #CD #Musics Ariana Grande Sweet Like Candy 3.4...          2  positive\n",
              "4      SIDE TO SIDE 😘 @user #sidetoside #arianagrande...          1   neutral\n",
              "...                                                  ...        ...       ...\n",
              "11901            @user update: Zac Efron kissing a puppy          2  positive\n",
              "11902              #zac efron sex pic skins michelle sex          1   neutral\n",
              "11903  First Look at Neighbors 2 with Zac Efron Shirt...          1   neutral\n",
              "11904            zac efron poses nude #lovely libra porn          1   neutral\n",
              "11905  #Fashion #Style The Paperboy (NEW Blu-ray Disc...          1   neutral\n",
              "\n",
              "[11906 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfx7FOB83_Es",
        "outputId": "bb54acf4-334a-49c0-edcd-5d85cfdbdf3c"
      },
      "source": [
        "# Transforming the .txt files and creating the validation dataset\n",
        "\n",
        "with open('./source/sentiment/val_text.txt') as val_text, open('./source/sentiment/val_labels.txt') as val_labels:\n",
        "  matrix = []\n",
        "  sentiments = pd.read_csv('./source/sentiment/mapping.csv')\n",
        "  for text, label in zip(val_text, val_labels):\n",
        "    sentiment = sentiments.loc[sentiments['Code'] == int(label), 'Sentiment'].item()\n",
        "    row = {}\n",
        "    row['text'] = text.rstrip()\n",
        "    row['sentiment'] = int(label)\n",
        "    row['target'] = sentiment\n",
        "    matrix.append(row)\n",
        "  val = pd.DataFrame(matrix)\n",
        "\n",
        "val.to_csv('./source/sentiment/val.csv', index=False)\n",
        "val"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>man I'm about to see Janet Jackson in October ...</td>\n",
              "      <td>1</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@user what do you think about the reaction is ...</td>\n",
              "      <td>1</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Conor McGregor's reaction to swirling Jose Ald...</td>\n",
              "      <td>1</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>To all the people who will buy Go Set a Watchm...</td>\n",
              "      <td>0</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>How about a Day of Action and Meetups on Sat O...</td>\n",
              "      <td>2</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1995</th>\n",
              "      <td>It's good to see that Dave managed to get back...</td>\n",
              "      <td>2</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996</th>\n",
              "      <td>Hope everyone is out having fun at the 2012 Ro...</td>\n",
              "      <td>2</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1997</th>\n",
              "      <td>Watching full 1st season of The Finder on Hulu...</td>\n",
              "      <td>2</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998</th>\n",
              "      <td>#cricket Pakistan hopeful of Bangladesh visit:...</td>\n",
              "      <td>2</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999</th>\n",
              "      <td>RT @user - it's Boston Red Sox - NY Yankees to...</td>\n",
              "      <td>2</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2000 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text  sentiment    target\n",
              "0     man I'm about to see Janet Jackson in October ...          1   neutral\n",
              "1     @user what do you think about the reaction is ...          1   neutral\n",
              "2     Conor McGregor's reaction to swirling Jose Ald...          1   neutral\n",
              "3     To all the people who will buy Go Set a Watchm...          0  negative\n",
              "4     How about a Day of Action and Meetups on Sat O...          2  positive\n",
              "...                                                 ...        ...       ...\n",
              "1995  It's good to see that Dave managed to get back...          2  positive\n",
              "1996  Hope everyone is out having fun at the 2012 Ro...          2  positive\n",
              "1997  Watching full 1st season of The Finder on Hulu...          2  positive\n",
              "1998  #cricket Pakistan hopeful of Bangladesh visit:...          2  positive\n",
              "1999  RT @user - it's Boston Red Sox - NY Yankees to...          2  positive\n",
              "\n",
              "[2000 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpVwEyd55c2U"
      },
      "source": [
        "##  Loading Tokenizer and Encoding our Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6DlaBtU5gMb",
        "outputId": "f58bcd1d-5a31-4302-8176-15864c735ff4"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "# Importing the tokenizer for the model\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\n",
        "    'bert-large-uncased',\n",
        "    do_lower_case=True\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "33b35c1de5c5435cae59a9cf7c4f532b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6bceed27a8914a47ab77e6cfbf058bd3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a1e93267abbf4c0e999b017dbd174429",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JV1scSp6U-s",
        "outputId": "17d2fd93-a7bb-40c5-8acf-d6206da1e51e"
      },
      "source": [
        "# Encoding the data\n",
        "\n",
        "import torch\n",
        "\n",
        "encoded_data_train = tokenizer.batch_encode_plus(\n",
        "    train.text.values,\n",
        "    add_special_tokens=True,\n",
        "    return_attention_mask=True,\n",
        "    pad_to_max_length=True,\n",
        "    max_length=256,\n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "encoded_data_val = tokenizer.batch_encode_plus(\n",
        "    val.text.values,\n",
        "    add_special_tokens=True,\n",
        "    return_attention_mask=True,\n",
        "    pad_to_max_length=True,\n",
        "    max_length=256,\n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "input_ids_train = encoded_data_train['input_ids']\n",
        "attention_masks_train = encoded_data_train['attention_mask']\n",
        "labels_train = torch.tensor(train.sentiment.values)\n",
        "\n",
        "input_ids_val = encoded_data_val['input_ids']\n",
        "attention_masks_val = encoded_data_val['attention_mask']\n",
        "labels_val = torch.tensor(val.sentiment.values)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdI3EpqA7if6",
        "outputId": "de852fe6-98ef-411a-b228-c80eaa9b8114"
      },
      "source": [
        "# Creating the tensor datasets\n",
        "\n",
        "dataset_train = TensorDataset(input_ids_train, \n",
        "                              attention_masks_train,\n",
        "                              labels_train)\n",
        "\n",
        "dataset_val = TensorDataset(input_ids_val, \n",
        "                            attention_masks_val,\n",
        "                           labels_val)\n",
        "\n",
        "\n",
        "dataset_val.tensors"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[  101,  2158,  1045,  ...,     0,     0,     0],\n",
              "         [  101,  1030,  5310,  ...,     0,     0,     0],\n",
              "         [  101, 20545, 23023,  ...,     0,     0,     0],\n",
              "         ...,\n",
              "         [  101,  3666,  2440,  ...,     0,     0,     0],\n",
              "         [  101,  1001,  4533,  ...,     0,     0,     0],\n",
              "         [  101, 19387,  1030,  ...,     0,     0,     0]]),\n",
              " tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         ...,\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
              " tensor([1, 1, 1,  ..., 2, 2, 2]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nu-E4yaO9YjO"
      },
      "source": [
        "##  Setting up BERT Pretrained Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55G_CgT59aBL"
      },
      "source": [
        "from transformers import BertForSequenceClassification"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naokSnSk9dFC"
      },
      "source": [
        "# Creating a dictionary with the possible labels for input\n",
        "\n",
        "label_dict = {}\n",
        "possible_labels = mapping['Sentiment'].unique()\n",
        "\n",
        "for index, possible_label in enumerate(possible_labels):\n",
        "    label_dict[possible_label] = index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "1d526a163c69452492577e06480510b4",
            "efe301a5d4564cb8b87a5b181ce37fcd"
          ]
        },
        "id": "BopCXeVC9gDk",
        "outputId": "5d2b1cf7-eeea-472e-cf16-31fdd8380baa"
      },
      "source": [
        "# Importing the model\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "                                      'bert-large-uncased', \n",
        "                                      num_labels = len(label_dict),\n",
        "                                      output_attentions = False,\n",
        "                                      output_hidden_states = False\n",
        "                                     )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1d526a163c69452492577e06480510b4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=434.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "efe301a5d4564cb8b87a5b181ce37fcd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1344997306.0, style=ProgressStyle(descr…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqD0_91o-CWt"
      },
      "source": [
        "##  Creating Data Loaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ww0KzsSy-FCd"
      },
      "source": [
        "batch_size = 6\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "dataloader_train = DataLoader(\n",
        "    dataset_train,\n",
        "    sampler=RandomSampler(dataset_train),\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "dataloader_val = DataLoader(\n",
        "    dataset_val,\n",
        "    sampler=RandomSampler(dataset_val),\n",
        "    batch_size=20\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVfeL4QF-OAD"
      },
      "source": [
        "##  Setting up Optimizer and Scheduler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ahhd4Xai-O79"
      },
      "source": [
        "from transformers import AdamW\n",
        "\n",
        "# Setting up the optimizer\n",
        "\n",
        "optimizer = AdamW(\n",
        "    model.parameters(),\n",
        "    lr = 1e-5,\n",
        "    eps = 1e-8\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48-3XsHu-Ry_"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Setting up the scheduler\n",
        "\n",
        "epochs = 1\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps = len(dataloader_train)*epochs\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWPQd9UJ-Tvv"
      },
      "source": [
        "##  Defining the Performance Metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMTvUjEU-VrD"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTNZcnyU-Z0q"
      },
      "source": [
        "# Defining the f1 score metric\n",
        " \n",
        "def f1_score_func(preds, labels):\n",
        "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return f1_score(labels_flat, preds_flat, average = 'weighted')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5oAOJENx-bhK"
      },
      "source": [
        "# Defining the accuracy per class metric\n",
        "\n",
        "def accuracy_per_class(preds, labels):\n",
        "    label_dict_inverse = {v: k for k, v in label_dict.items()}\n",
        "    \n",
        "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    \n",
        "    for label in np.unique(labels_flat):\n",
        "        y_preds = preds_flat[labels_flat==label]\n",
        "        y_true = labels_flat[labels_flat==label]\n",
        "        print(f'Class: {label_dict_inverse[label]}')\n",
        "        print(f'Accuracy:{len(y_preds[y_preds==label])}/{len(y_true)}\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vbFAL6s-ecD"
      },
      "source": [
        "##  Creating the Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNZcASGX-fdb"
      },
      "source": [
        "import random\n",
        "\n",
        "# Setting up the environment\n",
        "\n",
        "seed_val = 17\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5WILvCO-jOa",
        "outputId": "9e655233-f9a6-4f76-db23-44521bf4109f"
      },
      "source": [
        "# Setting up the device\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s90EFWZi-me9"
      },
      "source": [
        "# Defining the evaluation function\n",
        "\n",
        "def evaluate(dataloader_val):\n",
        "\n",
        "    model.eval()\n",
        "    \n",
        "    loss_val_total = 0\n",
        "    predictions, true_vals = [], []\n",
        "    \n",
        "    for batch in tqdm(dataloader_val):\n",
        "        \n",
        "        batch = tuple(b.to(device) for b in batch)\n",
        "        \n",
        "        inputs = {'input_ids':      batch[0],\n",
        "                  'attention_mask': batch[1],\n",
        "                  'labels':         batch[2],\n",
        "                 }\n",
        "\n",
        "        with torch.no_grad():        \n",
        "            outputs = model(**inputs)\n",
        "            \n",
        "        loss = outputs[0]\n",
        "        logits = outputs[1]\n",
        "        loss_val_total += loss.item()\n",
        "\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = inputs['labels'].cpu().numpy()\n",
        "        predictions.append(logits)\n",
        "        true_vals.append(label_ids)\n",
        "    \n",
        "    loss_val_avg = loss_val_total/len(dataloader_val) \n",
        "    \n",
        "    predictions = np.concatenate(predictions, axis=0)\n",
        "    true_vals = np.concatenate(true_vals, axis=0)\n",
        "            \n",
        "    return loss_val_avg, predictions, true_vals"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3C8d5-V8eOx8"
      },
      "source": [
        "## Training the model, making the prediction and calculating the performance metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "ML5h5EEW-uSM",
        "outputId": "5c65ea4c-6f0b-43b1-c1ac-80fee8568460"
      },
      "source": [
        "from tqdm.notebook import tqdm\n",
        "\n",
        "for epoch in tqdm(range(1, epochs+1)):\n",
        "    model.train()\n",
        "    loss_train_total = 0\n",
        "    \n",
        "    progress_bar = tqdm(dataloader_train, \n",
        "                        desc='Epoch {:1d}'.format(epoch), \n",
        "                        leave=False, \n",
        "                        disable=False)\n",
        "    \n",
        "    for batch in progress_bar:\n",
        "        model.zero_grad()\n",
        "        batch = tuple(b.to(device) for b in batch)\n",
        "        inputs = {\n",
        "            'input_ids': batch[0],\n",
        "            'attention_mask': batch[1],\n",
        "            'labels': batch[2]\n",
        "        }\n",
        "        \n",
        "        outputs = model(**inputs)\n",
        "        loss = outputs[0]\n",
        "        loss_train_total +=loss.item()\n",
        "        loss.backward()\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        \n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        \n",
        "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})     \n",
        "    \n",
        "    #torch.save(model.state_dict(), f'Models/BERT_ft_Epoch{epoch}.model')\n",
        "    \n",
        "\n",
        "    \n",
        "    loss_train_avg = loss_train_total/len(dataloader_train)\n",
        "    tqdm.write(f'Training loss: {loss_train_avg}')\n",
        "    \n",
        "    val_loss, predictions, true_vals = evaluate(dataloader_val)\n",
        "    val_f1 = f1_score_func(predictions, true_vals)\n",
        "    print(f'Validation loss: {val_loss}')\n",
        "    print(f'F1 Score (weighted): {val_f1}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7942e0b8e74c4161b8a1fe9dfcdd5ef7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ab321751fd944159828b06d9ec557d26",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Epoch 1', max=7565.0, style=ProgressStyle(description_wid…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\rTraining loss: 0.6556394049665113\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d4c1cae0070946a1b242915e16790029",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Validation loss: 0.5883392065763473\n",
            "F1 Score (weighted): 0.7450052407878486\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRV0Dxv9-6Zv"
      },
      "source": [
        "## Evaluating the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0OMwg7zv-8ps",
        "outputId": "dc868dfa-b577-49b7-f25d-0d7f5b4cc60d"
      },
      "source": [
        "accuracy_per_class(predictions, true_vals)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class: negative\n",
            "Accuracy:187/301\n",
            "\n",
            "Class: neutral\n",
            "Accuracy:658/896\n",
            "\n",
            "Class: positive\n",
            "Accuracy:647/803\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6MckM5k3CCd"
      },
      "source": [
        "# **Stance Detection**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-LM_WJpe7fm"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "LG2sn6vo3Gec",
        "outputId": "7685e873-4ca2-4673-d855-ba77981313cd"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Transforming the mapping for all stance categories into a .csv file\n",
        "\n",
        "with open('./source/stance/mapping.txt') as file:\n",
        "  matrix = []\n",
        "  for line in file:\n",
        "    splits = line.split('\\t')\n",
        "    row = {}\n",
        "    row['Code'] = splits[0]\n",
        "    row['Stance'] = splits[1].rstrip()\n",
        "    matrix.append(row)\n",
        "  mapping = pd.DataFrame(matrix)\n",
        "\n",
        "mapping.to_csv('./source/stance/mapping.csv', index=False)\n",
        "mapping"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Code</th>\n",
              "      <th>Stance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>none</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>against</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>favor</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Code   Stance\n",
              "0    0     none\n",
              "1    1  against\n",
              "2    2    favor"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K72hhK1L3EJ1",
        "outputId": "bf99c5b7-a814-4437-d529-c178a4ed857d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0JCRa5mqeUh",
        "outputId": "30a45b50-2bda-42ca-e7d5-81115fea4e1d"
      },
      "source": [
        "pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b0/9e/5b80becd952d5f7250eaf8fc64b957077b12ccfe73e9c03d37146ab29712/transformers-4.6.0-py3-none-any.whl (2.3MB)\n",
            "\r\u001b[K     |▏                               | 10kB 20.2MB/s eta 0:00:01\r\u001b[K     |▎                               | 20kB 27.5MB/s eta 0:00:01\r\u001b[K     |▍                               | 30kB 24.8MB/s eta 0:00:01\r\u001b[K     |▋                               | 40kB 27.5MB/s eta 0:00:01\r\u001b[K     |▊                               | 51kB 29.6MB/s eta 0:00:01\r\u001b[K     |▉                               | 61kB 31.5MB/s eta 0:00:01\r\u001b[K     |█                               | 71kB 25.5MB/s eta 0:00:01\r\u001b[K     |█▏                              | 81kB 26.5MB/s eta 0:00:01\r\u001b[K     |█▎                              | 92kB 27.9MB/s eta 0:00:01\r\u001b[K     |█▍                              | 102kB 29.4MB/s eta 0:00:01\r\u001b[K     |█▌                              | 112kB 29.4MB/s eta 0:00:01\r\u001b[K     |█▊                              | 122kB 29.4MB/s eta 0:00:01\r\u001b[K     |█▉                              | 133kB 29.4MB/s eta 0:00:01\r\u001b[K     |██                              | 143kB 29.4MB/s eta 0:00:01\r\u001b[K     |██                              | 153kB 29.4MB/s eta 0:00:01\r\u001b[K     |██▎                             | 163kB 29.4MB/s eta 0:00:01\r\u001b[K     |██▍                             | 174kB 29.4MB/s eta 0:00:01\r\u001b[K     |██▌                             | 184kB 29.4MB/s eta 0:00:01\r\u001b[K     |██▋                             | 194kB 29.4MB/s eta 0:00:01\r\u001b[K     |██▉                             | 204kB 29.4MB/s eta 0:00:01\r\u001b[K     |███                             | 215kB 29.4MB/s eta 0:00:01\r\u001b[K     |███                             | 225kB 29.4MB/s eta 0:00:01\r\u001b[K     |███▎                            | 235kB 29.4MB/s eta 0:00:01\r\u001b[K     |███▍                            | 245kB 29.4MB/s eta 0:00:01\r\u001b[K     |███▌                            | 256kB 29.4MB/s eta 0:00:01\r\u001b[K     |███▋                            | 266kB 29.4MB/s eta 0:00:01\r\u001b[K     |███▉                            | 276kB 29.4MB/s eta 0:00:01\r\u001b[K     |████                            | 286kB 29.4MB/s eta 0:00:01\r\u001b[K     |████                            | 296kB 29.4MB/s eta 0:00:01\r\u001b[K     |████▏                           | 307kB 29.4MB/s eta 0:00:01\r\u001b[K     |████▍                           | 317kB 29.4MB/s eta 0:00:01\r\u001b[K     |████▌                           | 327kB 29.4MB/s eta 0:00:01\r\u001b[K     |████▋                           | 337kB 29.4MB/s eta 0:00:01\r\u001b[K     |████▊                           | 348kB 29.4MB/s eta 0:00:01\r\u001b[K     |█████                           | 358kB 29.4MB/s eta 0:00:01\r\u001b[K     |█████                           | 368kB 29.4MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 378kB 29.4MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 389kB 29.4MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 399kB 29.4MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 409kB 29.4MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 419kB 29.4MB/s eta 0:00:01\r\u001b[K     |██████                          | 430kB 29.4MB/s eta 0:00:01\r\u001b[K     |██████                          | 440kB 29.4MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 450kB 29.4MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 460kB 29.4MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 471kB 29.4MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 481kB 29.4MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 491kB 29.4MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 501kB 29.4MB/s eta 0:00:01\r\u001b[K     |███████                         | 512kB 29.4MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 522kB 29.4MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 532kB 29.4MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 542kB 29.4MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 552kB 29.4MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 563kB 29.4MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 573kB 29.4MB/s eta 0:00:01\r\u001b[K     |████████                        | 583kB 29.4MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 593kB 29.4MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 604kB 29.4MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 614kB 29.4MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 624kB 29.4MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 634kB 29.4MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 645kB 29.4MB/s eta 0:00:01\r\u001b[K     |█████████                       | 655kB 29.4MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 665kB 29.4MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 675kB 29.4MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 686kB 29.4MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 696kB 29.4MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 706kB 29.4MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 716kB 29.4MB/s eta 0:00:01\r\u001b[K     |██████████                      | 727kB 29.4MB/s eta 0:00:01\r\u001b[K     |██████████                      | 737kB 29.4MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 747kB 29.4MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 757kB 29.4MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 768kB 29.4MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 778kB 29.4MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 788kB 29.4MB/s eta 0:00:01\r\u001b[K     |███████████                     | 798kB 29.4MB/s eta 0:00:01\r\u001b[K     |███████████                     | 808kB 29.4MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 819kB 29.4MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 829kB 29.4MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 839kB 29.4MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 849kB 29.4MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 860kB 29.4MB/s eta 0:00:01\r\u001b[K     |████████████                    | 870kB 29.4MB/s eta 0:00:01\r\u001b[K     |████████████                    | 880kB 29.4MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 890kB 29.4MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 901kB 29.4MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 911kB 29.4MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 921kB 29.4MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 931kB 29.4MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 942kB 29.4MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 952kB 29.4MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 962kB 29.4MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 972kB 29.4MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 983kB 29.4MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 993kB 29.4MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 1.0MB 29.4MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 1.0MB 29.4MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 1.0MB 29.4MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 1.0MB 29.4MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 1.0MB 29.4MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 1.1MB 29.4MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 1.1MB 29.4MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 1.1MB 29.4MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 1.1MB 29.4MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 1.1MB 29.4MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 1.1MB 29.4MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 1.1MB 29.4MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 1.1MB 29.4MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 1.1MB 29.4MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 1.1MB 29.4MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 1.2MB 29.4MB/s eta 0:00:01\r\u001b[K     |████████████████                | 1.2MB 29.4MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 1.2MB 29.4MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 1.2MB 29.4MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 1.2MB 29.4MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 1.2MB 29.4MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 1.2MB 29.4MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 1.2MB 29.4MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 1.2MB 29.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 1.2MB 29.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 1.3MB 29.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 1.3MB 29.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 1.3MB 29.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 1.3MB 29.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 1.3MB 29.4MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 1.3MB 29.4MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 1.3MB 29.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 1.3MB 29.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 1.3MB 29.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 1.4MB 29.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 1.4MB 29.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 1.4MB 29.4MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.4MB 29.4MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.4MB 29.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 1.4MB 29.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 1.4MB 29.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 1.4MB 29.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 1.4MB 29.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 1.4MB 29.4MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.5MB 29.4MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.5MB 29.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 1.5MB 29.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 1.5MB 29.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 1.5MB 29.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 1.5MB 29.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 1.5MB 29.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.5MB 29.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.5MB 29.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 1.5MB 29.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 1.6MB 29.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 1.6MB 29.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 1.6MB 29.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 1.6MB 29.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 1.6MB 29.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.6MB 29.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 1.6MB 29.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 1.6MB 29.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 1.6MB 29.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 1.6MB 29.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 1.7MB 29.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 1.7MB 29.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.7MB 29.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 1.7MB 29.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 1.7MB 29.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 1.7MB 29.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 1.7MB 29.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.7MB 29.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 1.7MB 29.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.8MB 29.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 1.8MB 29.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.8MB 29.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 1.8MB 29.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.8MB 29.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.8MB 29.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 1.8MB 29.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.8MB 29.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.8MB 29.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 1.8MB 29.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 1.9MB 29.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.9MB 29.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.9MB 29.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 1.9MB 29.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.9MB 29.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.9MB 29.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 1.9MB 29.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.9MB 29.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.9MB 29.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.9MB 29.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 2.0MB 29.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 2.0MB 29.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 2.0MB 29.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 2.0MB 29.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 2.0MB 29.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 2.0MB 29.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 2.0MB 29.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 2.0MB 29.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 2.0MB 29.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 2.0MB 29.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 2.1MB 29.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 2.1MB 29.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 2.1MB 29.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 2.1MB 29.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 2.1MB 29.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 2.1MB 29.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 2.1MB 29.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 2.1MB 29.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 2.1MB 29.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 2.2MB 29.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 2.2MB 29.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 2.2MB 29.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 2.2MB 29.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 2.2MB 29.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 2.2MB 29.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 2.2MB 29.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 2.2MB 29.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 2.2MB 29.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 2.2MB 29.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 2.3MB 29.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 2.3MB 29.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 2.3MB 29.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 2.3MB 29.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 2.3MB 29.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 2.3MB 29.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 2.3MB 29.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 2.3MB 29.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 2.3MB 29.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 2.3MB 29.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Collecting huggingface-hub==0.0.8\n",
            "  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 56.1MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 54.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (8.0.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Installing collected packages: huggingface-hub, tokenizers, sacremoses, transformers\n",
            "Successfully installed huggingface-hub-0.0.8 sacremoses-0.0.45 tokenizers-0.10.2 transformers-4.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iW9ZVeWYH9P"
      },
      "source": [
        "## Abortion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDYVmZtDgCu9"
      },
      "source": [
        "# Transforming the .txt files and creating the train dataset\n",
        "\n",
        "with open('./source/stance/abortion/train_text.txt') as train_text, open('./source/stance/abortion/train_labels.txt') as train_labels:\n",
        "  matrix = []\n",
        "  stances = pd.read_csv('./source/stance/mapping.csv')\n",
        "  for text, label in zip(train_text, train_labels):\n",
        "    stance = stances.loc[stances['Code'] == int(label), 'Stance'].item()\n",
        "    row = {}\n",
        "    row['text'] = text.rstrip()\n",
        "    row['stance'] = int(label)\n",
        "    row['target'] = stance\n",
        "    matrix.append(row)\n",
        "  train = pd.DataFrame(matrix)\n",
        "\n",
        "train.to_csv('./source/stance/abortion/train.txt', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBFY93swkk8p"
      },
      "source": [
        "# Transforming the .txt files and creating the test dataset\n",
        "\n",
        "with open('./source/stance/abortion/test_text.txt') as test_text, open('./source/stance/abortion/test_labels.txt') as test_labels:\n",
        "  matrix = []\n",
        "  stances = pd.read_csv('./source/stance/mapping.csv')\n",
        "  for text, label in zip(test_text, test_labels):\n",
        "    stance = stances.loc[stances['Code'] == int(label), 'Stance'].item()\n",
        "    row = {}\n",
        "    row['text'] = text.rstrip()\n",
        "    row['stance'] = int(label)\n",
        "    row['target'] = stance\n",
        "    matrix.append(row)\n",
        "  test = pd.DataFrame(matrix)\n",
        "\n",
        "test.to_csv('./source/stance/abortion/test.txt', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3eVJ6hqmqQT"
      },
      "source": [
        "# Transforming the .txt files and creating the val dataset\n",
        "\n",
        "with open('./source/stance/abortion/val_text.txt') as val_text, open('./source/stance/abortion/val_labels.txt') as val_labels:\n",
        "  matrix = []\n",
        "  stances = pd.read_csv('./source/stance/mapping.csv')\n",
        "  for text, label in zip(val_text, val_labels):\n",
        "    stance = stances.loc[stances['Code'] == int(label), 'Stance'].item()\n",
        "    row = {}\n",
        "    row['text'] = text.rstrip()\n",
        "    row['stance'] = int(label)\n",
        "    row['target'] = stance\n",
        "    matrix.append(row)\n",
        "  val = pd.DataFrame(matrix)\n",
        "\n",
        "val.to_csv('./source/stance/abortion/val.txt', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3CBOs7n55Ba"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "from torch.utils.data import TensorDataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e47xvag17tUa"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\n",
        "    'bert-large-cased-whole-word-masking-finetuned-squad',\n",
        "    do_lower_case = True\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VeL_i-KD8kAO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6220ba38-928e-4037-d195-007bdf82b5d5"
      },
      "source": [
        "import torch\n",
        "encoded_data_train = tokenizer.batch_encode_plus(\n",
        "    train.text.values,\n",
        "    add_special_tokens=True,\n",
        "    return_attention_mask=True,\n",
        "    pad_to_max_length=True,\n",
        "    max_length=256,\n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "encoded_data_val = tokenizer.batch_encode_plus(\n",
        "    val.text.values,\n",
        "    add_special_tokens=True,\n",
        "    return_attention_mask=True,\n",
        "    pad_to_max_length=True,\n",
        "    max_length=256,\n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "input_ids_train = encoded_data_train['input_ids']\n",
        "attention_masks_train = encoded_data_train['attention_mask']\n",
        "labels_train = torch.tensor(train.stance.values)\n",
        "\n",
        "input_ids_val = encoded_data_val['input_ids']\n",
        "attention_masks_val = encoded_data_val['attention_mask']\n",
        "labels_val = torch.tensor(val.stance.values)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQ-Vu-qcD9Xg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be88932c-2c5b-4908-cd3f-05ebe118be32"
      },
      "source": [
        "# Creating the tensor datasets\n",
        "\n",
        "dataset_train = TensorDataset(input_ids_train, \n",
        "                              attention_masks_train,\n",
        "                              labels_train)\n",
        "\n",
        "dataset_val = TensorDataset(input_ids_val, \n",
        "                            attention_masks_val,\n",
        "                            labels_val)\n",
        "\n",
        "\n",
        "dataset_val.tensors"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 101, 2052,  117,  ...,    0,    0,    0],\n",
              "         [ 101, 1175,  112,  ...,    0,    0,    0],\n",
              "         [ 101, 1191, 1128,  ...,    0,    0,    0],\n",
              "         ...,\n",
              "         [ 101,  137, 4795,  ...,    0,    0,    0],\n",
              "         [ 101, 1139, 1404,  ...,    0,    0,    0],\n",
              "         [ 101, 6243, 1128,  ...,    0,    0,    0]]),\n",
              " tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         ...,\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
              " tensor([0, 1, 1, 0, 1, 2, 1, 0, 1, 2, 1, 2, 1, 0, 2, 0, 2, 2, 1, 0, 2, 1, 1, 1,\n",
              "         1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 2, 2, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1,\n",
              "         1, 1, 1, 2, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 2, 1, 2, 0]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNHBcydTFnIr"
      },
      "source": [
        "from transformers import BertForSequenceClassification "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7xhqyywHO1t"
      },
      "source": [
        "label_dict = {}\n",
        "possible_labels = train.stance.unique()\n",
        "\n",
        "for index, possible_label in enumerate(possible_labels):\n",
        "  label_dict[possible_label] = index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W99IFNenHESz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a004a64c-7987-4678-c40a-2d56800d7e5a"
      },
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\n",
        "                                      'bert-large-cased-whole-word-masking-finetuned-squad', \n",
        "                                      num_labels = len(label_dict),\n",
        "                                      output_attentions = False,\n",
        "                                      output_hidden_states = False\n",
        "                                     )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-large-cased-whole-word-masking-finetuned-squad were not used when initializing BertForSequenceClassification: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-cased-whole-word-masking-finetuned-squad and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHcSL3gDI_O-"
      },
      "source": [
        "batch_size = 5\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "dataloader_train = DataLoader(\n",
        "    dataset_train,\n",
        "    sampler=RandomSampler(dataset_train),\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "dataloader_val = DataLoader(\n",
        "    dataset_val,\n",
        "    sampler=RandomSampler(dataset_val),\n",
        "    batch_size=5\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCfLNCYcJAOn"
      },
      "source": [
        "from transformers import AdamW\n",
        "optimizer = AdamW(\n",
        "    model.parameters(),\n",
        "    lr = 2e-5,\n",
        "    eps = 1e-8\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5LLCQ8dJDl-"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "epochs = 1\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps = len(dataloader_train)*epochs\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uj7hC9yuJMTG"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0R5HMcxJOlO"
      },
      "source": [
        "def f1_score_func(preds, labels):\n",
        "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return f1_score(labels_flat, preds_flat, average = 'weighted')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kt-LdZN-JRly"
      },
      "source": [
        "def accuracy_per_class(preds, labels):\n",
        "    label_dict_inverse = {v: k for k, v in label_dict.items()}\n",
        "    \n",
        "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    \n",
        "    for label in np.unique(labels_flat):\n",
        "        y_preds = preds_flat[labels_flat==label]\n",
        "        y_true = labels_flat[labels_flat==label]\n",
        "        print(f'Class: {label_dict_inverse[label]}')\n",
        "        print(f'Accuracy:{len(y_preds[y_preds==label])}/{len(y_true)}\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SiPUKqF4JYJz"
      },
      "source": [
        "import random\n",
        "\n",
        "seed_val = 15\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WR2KbDNeJZtE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce893f88-99b8-41c6-da94-b5b5efc7a6de"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWjvbt8yJcrE"
      },
      "source": [
        "def evaluate(dataloader_val):\n",
        "\n",
        "    model.eval()\n",
        "    \n",
        "    loss_val_total = 0\n",
        "    predictions, true_vals = [], []\n",
        "    \n",
        "    for batch in tqdm(dataloader_val):\n",
        "        \n",
        "        batch = tuple(b.to(device) for b in batch)\n",
        "        \n",
        "        inputs = {'input_ids':      batch[0],\n",
        "                  'attention_mask': batch[1],\n",
        "                  'labels':         batch[2],\n",
        "                 }\n",
        "\n",
        "        with torch.no_grad():        \n",
        "            outputs = model(**inputs)\n",
        "            \n",
        "        loss = outputs[0]\n",
        "        logits = outputs[1]\n",
        "        loss_val_total += loss.item()\n",
        "\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = inputs['labels'].cpu().numpy()\n",
        "        predictions.append(logits)\n",
        "        true_vals.append(label_ids)\n",
        "    \n",
        "    loss_val_avg = loss_val_total/len(dataloader_val) \n",
        "    \n",
        "    predictions = np.concatenate(predictions, axis=0)\n",
        "    true_vals = np.concatenate(true_vals, axis=0)\n",
        "            \n",
        "    return loss_val_avg, predictions, true_vals"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHsFM69eJf9z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165,
          "referenced_widgets": [
            "c0250209c9d54031ad5fd8137e5d9863",
            "a9a82b78555d47f88b3a818cc361f7a8",
            "a556d3c9f2c14a66b528cea51bce6b3b",
            "6068edf664034ba6b002e8d100e6b7aa",
            "803bfa6d1af6460884d9687754f524a6",
            "ceaa0ba785c24cf58bd2c58509eccfff",
            "e601ef539b6741ab8d446855a91a3216",
            "6f3be56fc2f34df7acd75a375eb26f34",
            "1e0e2dab779b43e9848c43026b48d310",
            "358ae3fb9d584188a230c0db0f164201",
            "0070774d7664459098511b1706f7d2d9",
            "709a0f850e4c46429dfa332a6a3d0f7d",
            "8f3c9e447e6642f09add4b7b6ff4595c",
            "146c21820c1e4ed8a1da1883f780d3c6",
            "ae4568ea8d564984aaa1d86812234bc0",
            "9c9cff45ac544232910193cf4874a534",
            "a12181f7a9e4449a889b9c363257810f",
            "833909ccb5664a9a9709514a0c0394a0",
            "f945723be45d456695ff4346ed8e8abb",
            "9a38b17085264218a033af8a47883e8e",
            "23bb9f8cc156471983b0ab4ca8dfda3e",
            "dc2303856b094ef88966f95f9cdb83ae",
            "e2170b3a36d54783a4088bb211a3d54b",
            "6320576ad6e64f9187d4963b26776ff6"
          ]
        },
        "outputId": "710ef53c-3e3c-4183-ae57-250a0eb189e3"
      },
      "source": [
        "from tqdm.notebook import tqdm\n",
        "\n",
        "for epoch in tqdm(range(1, 2)):\n",
        "    model.train()\n",
        "    loss_train_total = 0\n",
        "    \n",
        "    progress_bar = tqdm(dataloader_train, \n",
        "                        desc='Epoch {:1d}'.format(epoch), \n",
        "                        leave=False, \n",
        "                        disable=False)\n",
        "    \n",
        "    for batch in progress_bar:\n",
        "        model.zero_grad()\n",
        "        batch = tuple(b.to(device) for b in batch)\n",
        "        inputs = {\n",
        "            'input_ids': batch[0],\n",
        "            'attention_mask': batch[1],\n",
        "            'labels': batch[2]\n",
        "        }\n",
        "        \n",
        "        outputs = model(**inputs)\n",
        "        loss = outputs[0]\n",
        "        loss_train_total +=loss.item()\n",
        "        loss.backward()\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        \n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        \n",
        "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})     \n",
        "    \n",
        "    \n",
        "    loss_train_avg = loss_train_total/len(dataloader_train)\n",
        "    tqdm.write(f'Training loss: {loss_train_avg}')\n",
        "    \n",
        "    val_loss, predictions, true_vals = evaluate(dataloader_val)\n",
        "    val_f1 = f1_score_func(predictions, true_vals)\n",
        "    print(f'Validation loss: {val_loss}')\n",
        "    print(f'F1 Score (weighted): {val_f1}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c0250209c9d54031ad5fd8137e5d9863",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1e0e2dab779b43e9848c43026b48d310",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Epoch 1', max=118.0, style=ProgressStyle(description_widt…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\r\r\rTraining loss: 0.5396141222030935\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a12181f7a9e4449a889b9c363257810f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=14.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Validation loss: 0.8177774372909751\n",
            "F1 Score (weighted): 0.803030303030303\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVAZhGOjrWzb",
        "outputId": "fe9cb8d3-4296-40df-bb0e-ababf3239178"
      },
      "source": [
        "accuracy_per_class(predictions, true_vals)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class: 1\n",
            "Accuracy:15/18\n",
            "\n",
            "Class: 0\n",
            "Accuracy:31/36\n",
            "\n",
            "Class: 2\n",
            "Accuracy:7/12\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJrhkNBpYV7d"
      },
      "source": [
        "## Atheism"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4daDg3DQYgT-"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "with open('./source/stance/atheism/train_text.txt') as train_text, open('./source/stance/atheism/train_labels.txt') as train_labels:\n",
        "  matrix = []\n",
        "  stances = pd.read_csv('./source/stance/mapping.csv')\n",
        "  for text, label in zip(train_text, train_labels):\n",
        "    stance = stances.loc[stances['Code'] == int(label), 'Stance'].item()\n",
        "    row = {}\n",
        "    row['text'] = text.rstrip()\n",
        "    row['stance'] = int(label)\n",
        "    row['target'] = stance\n",
        "    matrix.append(row)\n",
        "  train = pd.DataFrame(matrix)\n",
        "\n",
        "train.to_csv('./source/stance/atheism/train.txt', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zd7hWkwuvvbW"
      },
      "source": [
        "# Transforming the .txt files and creating the test dataset\n",
        "\n",
        "with open('./source/stance/atheism/test_text.txt') as test_text, open('./source/stance/atheism/test_labels.txt') as test_labels:\n",
        "  matrix = []\n",
        "  stances = pd.read_csv('./source/stance/mapping.csv')\n",
        "  for text, label in zip(test_text, test_labels):\n",
        "    stance = stances.loc[stances['Code'] == int(label), 'Stance'].item()\n",
        "    row = {}\n",
        "    row['text'] = text.rstrip()\n",
        "    row['stance'] = int(label)\n",
        "    row['target'] = stance\n",
        "    matrix.append(row)\n",
        "  test = pd.DataFrame(matrix)\n",
        "\n",
        "test.to_csv('./source/stance/atheism/test.txt', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMW76p9RwLXm"
      },
      "source": [
        "# Transforming the .txt files and creating the val dataset\n",
        "\n",
        "with open('./source/stance/atheism/val_text.txt') as val_text, open('./source/stance/atheism/val_labels.txt') as val_labels:\n",
        "  matrix = []\n",
        "  stances = pd.read_csv('./source/stance/mapping.csv')\n",
        "  for text, label in zip(val_text, val_labels):\n",
        "    stance = stances.loc[stances['Code'] == int(label), 'Stance'].item()\n",
        "    row = {}\n",
        "    row['text'] = text.rstrip()\n",
        "    row['stance'] = int(label)\n",
        "    row['target'] = stance\n",
        "    matrix.append(row)\n",
        "  val = pd.DataFrame(matrix)\n",
        "\n",
        "val.to_csv('./source/stance/atheism/val.txt', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6QcrIR6Qsqn"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "from torch.utils.data import TensorDataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofkez9eFWMkR"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\n",
        "    'bert-large-cased-whole-word-masking-finetuned-squad',\n",
        "    do_lower_case = False\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVy6UzygWMkV",
        "outputId": "77932858-8dd3-4a86-b45e-66d292cf8ef1"
      },
      "source": [
        "import torch\n",
        "encoded_data_train = tokenizer.batch_encode_plus(\n",
        "    train.text.values,\n",
        "    add_special_tokens=True,\n",
        "    return_attention_mask=True,\n",
        "    pad_to_max_length=True,\n",
        "    max_length=256,\n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "encoded_data_val = tokenizer.batch_encode_plus(\n",
        "    val.text.values,\n",
        "    add_special_tokens=True,\n",
        "    return_attention_mask=True,\n",
        "    pad_to_max_length=True,\n",
        "    max_length=256,\n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "input_ids_train = encoded_data_train['input_ids']\n",
        "attention_masks_train = encoded_data_train['attention_mask']\n",
        "labels_train = torch.tensor(train.stance.values)\n",
        "\n",
        "input_ids_val = encoded_data_val['input_ids']\n",
        "attention_masks_val = encoded_data_val['attention_mask']\n",
        "labels_val = torch.tensor(val.stance.values)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRQ-R9iiWMkV",
        "outputId": "2fd6dfcc-b34b-4d68-ae6c-7a8b3449cc29"
      },
      "source": [
        "# Creating the tensor datasets\n",
        "\n",
        "dataset_train = TensorDataset(input_ids_train, \n",
        "                              attention_masks_train,\n",
        "                              labels_train)\n",
        "\n",
        "dataset_val = TensorDataset(input_ids_val, \n",
        "                            attention_masks_val,\n",
        "                            labels_val)\n",
        "\n",
        "\n",
        "dataset_val.tensors"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[  101,  1192,  1169,  ...,     0,     0,     0],\n",
              "         [  101, 23451,  1406,  ...,     0,     0,     0],\n",
              "         [  101,  1109,  1178,  ...,     0,     0,     0],\n",
              "         ...,\n",
              "         [  101,  6424,  7215,  ...,     0,     0,     0],\n",
              "         [  101,   146,   112,  ...,     0,     0,     0],\n",
              "         [  101,  1109,  4997,  ...,     0,     0,     0]]),\n",
              " tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         ...,\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
              " tensor([1, 1, 1, 1, 1, 2, 2, 2, 0, 1, 1, 2, 1, 2, 1, 2, 1, 1, 1, 0, 1, 1, 1, 2,\n",
              "         0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 2, 1, 1, 1, 1, 1, 0, 1, 1, 2,\n",
              "         1, 0, 1, 0]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1950
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDqhCQaLWMkW"
      },
      "source": [
        "from transformers import BertForSequenceClassification "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47mawojEWMkW"
      },
      "source": [
        "label_dict = {}\n",
        "possible_labels = train.stance.unique()\n",
        "\n",
        "for index, possible_label in enumerate(possible_labels):\n",
        "  label_dict[possible_label] = index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83pgcePfWMkX",
        "outputId": "93af92d0-d301-4418-f926-059ad070d51d"
      },
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\n",
        "                                      'bert-large-cased-whole-word-masking-finetuned-squad', \n",
        "                                      num_labels = len(label_dict),\n",
        "                                      output_attentions = False,\n",
        "                                      output_hidden_states = False\n",
        "                                     )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-large-cased-whole-word-masking-finetuned-squad were not used when initializing BertForSequenceClassification: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-cased-whole-word-masking-finetuned-squad and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UctzyGwZWMkX"
      },
      "source": [
        "batch_size = 5\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "dataloader_train = DataLoader(\n",
        "    dataset_train,\n",
        "    sampler=RandomSampler(dataset_train),\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "dataloader_val = DataLoader(\n",
        "    dataset_val,\n",
        "    sampler=RandomSampler(dataset_val),\n",
        "    batch_size=5\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rh6cTD7sWMkX"
      },
      "source": [
        "from transformers import AdamW\n",
        "optimizer = AdamW(\n",
        "    model.parameters(),\n",
        "    lr = 4e-5,\n",
        "    eps = 7e-8\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjULXnO0WMkY"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "epochs = 1\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps = len(dataloader_train)*epochs\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjtmTGhSWMkY"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzw9H5NKWMkY"
      },
      "source": [
        "def f1_score_func(preds, labels):\n",
        "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return f1_score(labels_flat, preds_flat, average = 'weighted')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCg8FX5OWMkY"
      },
      "source": [
        "def accuracy_per_class(preds, labels):\n",
        "    label_dict_inverse = {v: k for k, v in label_dict.items()}\n",
        "    \n",
        "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    \n",
        "    for label in np.unique(labels_flat):\n",
        "        y_preds = preds_flat[labels_flat==label]\n",
        "        y_true = labels_flat[labels_flat==label]\n",
        "        print(f'Class: {label_dict_inverse[label]}')\n",
        "        print(f'Accuracy:{len(y_preds[y_preds==label])}/{len(y_true)}\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-f_I67IZWMkZ"
      },
      "source": [
        "import random\n",
        "\n",
        "seed_val = 15\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3ubZTjYWMkZ",
        "outputId": "80f063bd-e1a2-4a47-c8cb-2e242b318e8a"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDJKnHMuWMkZ"
      },
      "source": [
        "def evaluate(dataloader_val):\n",
        "\n",
        "    model.eval()\n",
        "    \n",
        "    loss_val_total = 0\n",
        "    predictions, true_vals = [], []\n",
        "    \n",
        "    for batch in tqdm(dataloader_val):\n",
        "        \n",
        "        batch = tuple(b.to(device) for b in batch)\n",
        "        \n",
        "        inputs = {'input_ids':      batch[0],\n",
        "                  'attention_mask': batch[1],\n",
        "                  'labels':         batch[2],\n",
        "                 }\n",
        "\n",
        "        with torch.no_grad():        \n",
        "            outputs = model(**inputs)\n",
        "            \n",
        "        loss = outputs[0]\n",
        "        logits = outputs[1]\n",
        "        loss_val_total += loss.item()\n",
        "\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = inputs['labels'].cpu().numpy()\n",
        "        predictions.append(logits)\n",
        "        true_vals.append(label_ids)\n",
        "    \n",
        "    loss_val_avg = loss_val_total/len(dataloader_val) \n",
        "    \n",
        "    predictions = np.concatenate(predictions, axis=0)\n",
        "    true_vals = np.concatenate(true_vals, axis=0)\n",
        "            \n",
        "    return loss_val_avg, predictions, true_vals"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165,
          "referenced_widgets": [
            "2dc42afdca1e42aba4baa6ed9981221f",
            "fe3b750233734081aa3ab3e30fe295ac",
            "dae2335918d94161ace565cadda181be",
            "a20d8b08cf944fd5afeb9a21d22e645c",
            "b1c959fee02b4a0bbff439491403adb4",
            "4bf466f1607c4d46874e63c058bb0fbf",
            "2bb1e6b0db7c4a81823ec1d4a516e61b",
            "2816c376692f45e8ad59d6871641f0d8",
            "f824e192b50440e29ba265319eae08d0",
            "e52923f0c5b54ea8a04aad22b31319da",
            "8816c9395ba34b8fb9fc5e086caedcdd",
            "f83d84a2541d41038fe5d73c0a70f1a9",
            "4e842b7fd3d04f90b53753278e34b34a",
            "9215472a42764e36a5ac1f97d73e373c",
            "4cf2d6fe540e4475a206b918f1bcb715",
            "0f1ec6806fd941b2888deda24ff7f02c",
            "eac7799efe664de99e188680fad3184b",
            "8d5181a827c94db381e78ecf8f2bf9e5",
            "9526259b550c49739f77cdd4bbab701c",
            "3638b84058534ed69d9b7f01d6893925",
            "f23870bed0b945b3a61b8cc38addb3ba",
            "4769efc450ec4c5499e1b78ff4c38fd9",
            "af34a1c4609b454b8f2d476033361d43",
            "892b31c40eff436ba907872810111475"
          ]
        },
        "id": "sXvVT6f3WMkZ",
        "outputId": "67738bb1-6f1b-4f98-95ad-a34ea98d3595"
      },
      "source": [
        "from tqdm.notebook import tqdm\n",
        "\n",
        "for epoch in tqdm(range(1, 2)):\n",
        "    model.train()\n",
        "    loss_train_total = 0\n",
        "    \n",
        "    progress_bar = tqdm(dataloader_train, \n",
        "                        desc='Epoch {:1d}'.format(epoch), \n",
        "                        leave=False, \n",
        "                        disable=False)\n",
        "    \n",
        "    for batch in progress_bar:\n",
        "        model.zero_grad()\n",
        "        batch = tuple(b.to(device) for b in batch)\n",
        "        inputs = {\n",
        "            'input_ids': batch[0],\n",
        "            'attention_mask': batch[1],\n",
        "            'labels': batch[2]\n",
        "        }\n",
        "        \n",
        "        outputs = model(**inputs)\n",
        "        loss = outputs[0]\n",
        "        loss_train_total +=loss.item()\n",
        "        loss.backward()\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        \n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        \n",
        "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})     \n",
        "    \n",
        "    \n",
        "    loss_train_avg = loss_train_total/len(dataloader_train)\n",
        "    tqdm.write(f'Training loss: {loss_train_avg}')\n",
        "    \n",
        "    val_loss, predictions, true_vals = evaluate(dataloader_val)\n",
        "    val_f1 = f1_score_func(predictions, true_vals)\n",
        "    print(f'Validation loss: {val_loss}')\n",
        "    print(f'F1 Score (weighted): {val_f1}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2dc42afdca1e42aba4baa6ed9981221f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f824e192b50440e29ba265319eae08d0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Epoch 1', max=93.0, style=ProgressStyle(description_width…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\rTraining loss: 0.8454795657627044\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eac7799efe664de99e188680fad3184b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=11.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Validation loss: 0.6791728721423582\n",
            "F1 Score (weighted): 0.7208224180360403\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqT9JcQqdKuD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53cce6fd-e192-4d74-a5f2-8a8cb307a159"
      },
      "source": [
        "accuracy_per_class(predictions, true_vals)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class: 1\n",
            "Accuracy:9/12\n",
            "\n",
            "Class: 2\n",
            "Accuracy:22/31\n",
            "\n",
            "Class: 0\n",
            "Accuracy:6/9\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mq2oa7thYXJF"
      },
      "source": [
        "## Climate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBQjqzs2YnNp"
      },
      "source": [
        "# Transforming the .txt files and creating the train dataset\n",
        "\n",
        "with open('./source/stance/climate/train_text.txt') as train_text, open('./source/stance/climate/train_labels.txt') as train_labels:\n",
        "  matrix = []\n",
        "  stances = pd.read_csv('./source/stance/mapping.csv')\n",
        "  for text, label in zip(train_text, train_labels):\n",
        "    stance = stances.loc[stances['Code'] == int(label), 'Stance'].item()\n",
        "    row = {}\n",
        "    row['text'] = text.rstrip()\n",
        "    row['stance'] = int(label)\n",
        "    row['target'] = stance\n",
        "    matrix.append(row)\n",
        "  train = pd.DataFrame(matrix)\n",
        "\n",
        "train.to_csv('./source/stance/climate/train.txt', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HG6GqgUe1nrf"
      },
      "source": [
        "# Transforming the .txt files and creating the test dataset\n",
        "\n",
        "with open('./source/stance/climate/test_text.txt') as test_text, open('./source/stance/climate/test_labels.txt') as test_labels:\n",
        "  matrix = []\n",
        "  stances = pd.read_csv('./source/stance/mapping.csv')\n",
        "  for text, label in zip(test_text, test_labels):\n",
        "    stance = stances.loc[stances['Code'] == int(label), 'Stance'].item()\n",
        "    row = {}\n",
        "    row['text'] = text.rstrip()\n",
        "    row['stance'] = int(label)\n",
        "    row['target'] = stance\n",
        "    matrix.append(row)\n",
        "  test = pd.DataFrame(matrix)\n",
        "\n",
        "test.to_csv('./source/stance/climate/test.txt', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVxi9XBHwvr_"
      },
      "source": [
        "# Transforming the .txt files and creating the val dataset\n",
        "\n",
        "with open('./source/stance/climate/val_text.txt') as val_text, open('./source/stance/climate/val_labels.txt') as val_labels:\n",
        "  matrix = []\n",
        "  stances = pd.read_csv('./source/stance/mapping.csv')\n",
        "  for text, label in zip(val_text, val_labels):\n",
        "    stance = stances.loc[stances['Code'] == int(label), 'Stance'].item()\n",
        "    row = {}\n",
        "    row['text'] = text.rstrip()\n",
        "    row['stance'] = int(label)\n",
        "    row['target'] = stance\n",
        "    matrix.append(row)\n",
        "  val = pd.DataFrame(matrix)\n",
        "\n",
        "val.to_csv('./source/stance/climate/val.txt', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmMs_MvlV3HG"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "from torch.utils.data import TensorDataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2U_m34HWPy4"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\n",
        "    'bert-large-cased-whole-word-masking-finetuned-squad',\n",
        "    do_lower_case = True\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sS-WKGgBWPy4",
        "outputId": "11ddfa0e-7caf-4817-a588-8c720c9847b3"
      },
      "source": [
        "import torch\n",
        "encoded_data_train = tokenizer.batch_encode_plus(\n",
        "    train.text.values,\n",
        "    add_special_tokens=True,\n",
        "    return_attention_mask=True,\n",
        "    pad_to_max_length=True,\n",
        "    max_length=256,\n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "encoded_data_val = tokenizer.batch_encode_plus(\n",
        "    val.text.values,\n",
        "    add_special_tokens=True,\n",
        "    return_attention_mask=True,\n",
        "    pad_to_max_length=True,\n",
        "    max_length=256,\n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "input_ids_train = encoded_data_train['input_ids']\n",
        "attention_masks_train = encoded_data_train['attention_mask']\n",
        "labels_train = torch.tensor(train.stance.values)\n",
        "\n",
        "input_ids_val = encoded_data_val['input_ids']\n",
        "attention_masks_val = encoded_data_val['attention_mask']\n",
        "labels_val = torch.tensor(val.stance.values)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nG1TcXbBWPy5",
        "outputId": "4e0bf3ca-7201-4e83-ef2e-729ae89a8a16"
      },
      "source": [
        "# Creating the tensor datasets\n",
        "\n",
        "dataset_train = TensorDataset(input_ids_train, \n",
        "                              attention_masks_train,\n",
        "                              labels_train)\n",
        "\n",
        "dataset_val = TensorDataset(input_ids_val, \n",
        "                            attention_masks_val,\n",
        "                            labels_val)\n",
        "\n",
        "\n",
        "dataset_val.tensors"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 101,  108, 2862,  ...,    0,    0,    0],\n",
              "         [ 101, 1169,  137,  ...,    0,    0,    0],\n",
              "         [ 101,  119,  137,  ...,    0,    0,    0],\n",
              "         ...,\n",
              "         [ 101,  137, 4795,  ...,    0,    0,    0],\n",
              "         [ 101, 8362,  117,  ...,    0,    0,    0],\n",
              "         [ 101, 1175,  112,  ...,    0,    0,    0]]),\n",
              " tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         ...,\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
              " tensor([2, 0, 0, 2, 2, 2, 2, 2, 0, 2, 0, 0, 2, 0, 2, 2, 0, 2, 0, 2, 2, 2, 2, 1,\n",
              "         0, 0, 2, 2, 1, 0, 2, 2, 0, 2, 0, 0, 0, 0, 2, 0]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1841
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9Q9wDN2WPy5"
      },
      "source": [
        "from transformers import BertForSequenceClassification "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1eTFO8opWPy5"
      },
      "source": [
        "label_dict = {}\n",
        "possible_labels = train.stance.unique()\n",
        "\n",
        "for index, possible_label in enumerate(possible_labels):\n",
        "  label_dict[possible_label] = index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qsDUT6fnWPy5",
        "outputId": "27ed271a-a299-489e-a942-b0565662a63b"
      },
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\n",
        "                                      'bert-large-cased-whole-word-masking-finetuned-squad', \n",
        "                                      num_labels = len(label_dict),\n",
        "                                      output_attentions = False,\n",
        "                                      output_hidden_states = False\n",
        "                                     )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-large-cased-whole-word-masking-finetuned-squad were not used when initializing BertForSequenceClassification: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-cased-whole-word-masking-finetuned-squad and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCxu0bJFWPy5"
      },
      "source": [
        "batch_size = 4\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "dataloader_train = DataLoader(\n",
        "    dataset_train,\n",
        "    sampler=RandomSampler(dataset_train),\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "dataloader_val = DataLoader(\n",
        "    dataset_val,\n",
        "    sampler=RandomSampler(dataset_val),\n",
        "    batch_size=4\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oa2cKOoSWPy6"
      },
      "source": [
        "from transformers import AdamW\n",
        "optimizer = AdamW(\n",
        "    model.parameters(),\n",
        "    lr = 2e-5,\n",
        "    eps = 4e-8\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sfh6gKdSWPy6"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "epochs = 1\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps = len(dataloader_train)*epochs\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGjS_dpMWPy6"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73gI8-0XWPy6"
      },
      "source": [
        "def f1_score_func(preds, labels):\n",
        "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return f1_score(labels_flat, preds_flat, average = 'weighted')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcHBmLFLWPy6"
      },
      "source": [
        "def accuracy_per_class(preds, labels):\n",
        "    label_dict_inverse = {v: k for k, v in label_dict.items()}\n",
        "    \n",
        "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    \n",
        "    for label in np.unique(labels_flat):\n",
        "        y_preds = preds_flat[labels_flat==label]\n",
        "        y_true = labels_flat[labels_flat==label]\n",
        "        print(f'Class: {label_dict_inverse[label]}')\n",
        "        print(f'Accuracy:{len(y_preds[y_preds==label])}/{len(y_true)}\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yg9aSbF7WPy6"
      },
      "source": [
        "import random\n",
        "\n",
        "seed_val = 15\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fQgrr3pWPy6",
        "outputId": "10ec86f1-6564-4462-ed69-b911b0d03dd2"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6XYFzTdWPy7"
      },
      "source": [
        "def evaluate(dataloader_val):\n",
        "\n",
        "    model.eval()\n",
        "    \n",
        "    loss_val_total = 0\n",
        "    predictions, true_vals = [], []\n",
        "    \n",
        "    for batch in tqdm(dataloader_val):\n",
        "        \n",
        "        batch = tuple(b.to(device) for b in batch)\n",
        "        \n",
        "        inputs = {'input_ids':      batch[0],\n",
        "                  'attention_mask': batch[1],\n",
        "                  'labels':         batch[2],\n",
        "                 }\n",
        "\n",
        "        with torch.no_grad():        \n",
        "            outputs = model(**inputs)\n",
        "            \n",
        "        loss = outputs[0]\n",
        "        logits = outputs[1]\n",
        "        loss_val_total += loss.item()\n",
        "\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = inputs['labels'].cpu().numpy()\n",
        "        predictions.append(logits)\n",
        "        true_vals.append(label_ids)\n",
        "    \n",
        "    loss_val_avg = loss_val_total/len(dataloader_val) \n",
        "    \n",
        "    predictions = np.concatenate(predictions, axis=0)\n",
        "    true_vals = np.concatenate(true_vals, axis=0)\n",
        "            \n",
        "    return loss_val_avg, predictions, true_vals"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165,
          "referenced_widgets": [
            "9b52c84612d84ebfa90b1a8b89f18d3a",
            "468b37a37c85467882c6197e611bf2a1",
            "562a6ecb39924a9ebaf57d3c04ad545a",
            "7ab950d681ed4dc9bcc00bdbf40511c4",
            "1a468fcb0b824d29aa7959cb6df08d5f",
            "9402c9da425541c2b8c2706e4defe659",
            "d2276964eb3a438c8aab7e89c101a58f",
            "1ee6ef4ad9564644ac464a0fc7fe2ce0",
            "3e548ab790f041dba21df9f1beb1e0b7",
            "03f67b257180434e85aa59c853f6b636",
            "a81ef7a6f40c41738e88fc792f8f469c",
            "958596f2b062471bb3ef893b715bc159",
            "6d1e39bcab344709bb6a76e858f76b2f",
            "6b5c5597b8c64a3b9fbfbc6240f0d3a9",
            "bb9d737da78a47748684eed61475d756",
            "4827ba4dcab643fd9615cb4f40c10ba4",
            "d5101866633d4abc894f95ad3ca1acb1",
            "8164e82c1e6e4f2abe6666cd99713416",
            "df4a35ecf15c47099b3898188b030add",
            "82930343d18a478687d30f37978806e6",
            "4dc669fd8adf4b8d9a80a7fb76b5fb88",
            "704baa9fd6174cd1a213975516515453",
            "0a1bbbb93c984991bfb1dd876d2af13a",
            "7ae699cd23bb4af7a35f117ca5bb4a16"
          ]
        },
        "id": "Nwedgl6iWPy7",
        "outputId": "5d219998-943c-4def-8ad4-623c9e017dae"
      },
      "source": [
        "from tqdm.notebook import tqdm\n",
        "\n",
        "for epoch in tqdm(range(1, 2)):\n",
        "    model.train()\n",
        "    loss_train_total = 0\n",
        "    \n",
        "    progress_bar = tqdm(dataloader_train, \n",
        "                        desc='Epoch {:1d}'.format(epoch), \n",
        "                        leave=False, \n",
        "                        disable=False)\n",
        "    \n",
        "    for batch in progress_bar:\n",
        "        model.zero_grad()\n",
        "        batch = tuple(b.to(device) for b in batch)\n",
        "        inputs = {\n",
        "            'input_ids': batch[0],\n",
        "            'attention_mask': batch[1],\n",
        "            'labels': batch[2]\n",
        "        }\n",
        "        \n",
        "        outputs = model(**inputs)\n",
        "        loss = outputs[0]\n",
        "        loss_train_total +=loss.item()\n",
        "        loss.backward()\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        \n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        \n",
        "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})     \n",
        "    \n",
        "    \n",
        "    loss_train_avg = loss_train_total/len(dataloader_train)\n",
        "    tqdm.write(f'Training loss: {loss_train_avg}')\n",
        "    \n",
        "    val_loss, predictions, true_vals = evaluate(dataloader_val)\n",
        "    val_f1 = f1_score_func(predictions, true_vals)\n",
        "    print(f'Validation loss: {val_loss}')\n",
        "    print(f'F1 Score (weighted): {val_f1}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9b52c84612d84ebfa90b1a8b89f18d3a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3e548ab790f041dba21df9f1beb1e0b7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Epoch 1', max=89.0, style=ProgressStyle(description_width…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\rTraining loss: 0.7867464731248577\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d5101866633d4abc894f95ad3ca1acb1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Validation loss: 0.7562374711036682\n",
            "F1 Score (weighted): 0.6820512820512821\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yaRjSNJNWPy7",
        "outputId": "f85e07f2-3d0c-49d5-a676-387945275554"
      },
      "source": [
        "accuracy_per_class(predictions, true_vals)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class: 0\n",
            "Accuracy:14/17\n",
            "\n",
            "Class: 2\n",
            "Accuracy:0/2\n",
            "\n",
            "Class: 1\n",
            "Accuracy:14/21\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkoXtv6gYYuF"
      },
      "source": [
        "## Feminist"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLtHgeyDYn5N"
      },
      "source": [
        "# Transforming the .txt files and creating the train dataset\n",
        "\n",
        "with open('./source/stance/feminist/train_text.txt') as train_text, open('./source/stance/feminist/train_labels.txt') as train_labels:\n",
        "  matrix = []\n",
        "  stances = pd.read_csv('./source/stance/mapping.csv')\n",
        "  for text, label in zip(train_text, train_labels):\n",
        "    stance = stances.loc[stances['Code'] == int(label), 'Stance'].item()\n",
        "    row = {}\n",
        "    row['text'] = text.rstrip()\n",
        "    row['stance'] = int(label)\n",
        "    row['target'] = stance\n",
        "    matrix.append(row)\n",
        "  train = pd.DataFrame(matrix)\n",
        "\n",
        "train.to_csv('./source/stance/feminist/train.txt', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxRf2NGVxNRY"
      },
      "source": [
        "# Transforming the .txt files and creating the test dataset\n",
        "\n",
        "with open('./source/stance/feminist/test_text.txt') as test_text, open('./source/stance/feminist/test_labels.txt') as test_labels:\n",
        "  matrix = []\n",
        "  stances = pd.read_csv('./source/stance/mapping.csv')\n",
        "  for text, label in zip(test_text, test_labels):\n",
        "    stance = stances.loc[stances['Code'] == int(label), 'Stance'].item()\n",
        "    row = {}\n",
        "    row['text'] = text.rstrip()\n",
        "    row['stance'] = int(label)\n",
        "    row['target'] = stance\n",
        "    matrix.append(row)\n",
        "  test = pd.DataFrame(matrix)\n",
        "\n",
        "test.to_csv('./source/stance/feminist/test.txt', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZdb9PeqxQxY"
      },
      "source": [
        "# Transforming the .txt files and creating the val dataset\n",
        "\n",
        "with open('./source/stance/feminist/val_text.txt') as val_text, open('./source/stance/feminist/val_labels.txt') as val_labels:\n",
        "  matrix = []\n",
        "  stances = pd.read_csv('./source/stance/mapping.csv')\n",
        "  for text, label in zip(val_text, val_labels):\n",
        "    stance = stances.loc[stances['Code'] == int(label), 'Stance'].item()\n",
        "    row = {}\n",
        "    row['text'] = text.rstrip()\n",
        "    row['stance'] = int(label)\n",
        "    row['target'] = stance\n",
        "    matrix.append(row)\n",
        "  val = pd.DataFrame(matrix)\n",
        "\n",
        "val.to_csv('./source/stance/feminist/val.txt', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPh2cU9jV5qC"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "from torch.utils.data import TensorDataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1niAzIBWSUZ"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\n",
        "    'bert-large-cased-whole-word-masking',\n",
        "    do_lower_case = True\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TG0VJfBmWSUZ",
        "outputId": "43601b0f-6090-467a-83dd-304fc05e05ad"
      },
      "source": [
        "import torch\n",
        "encoded_data_train = tokenizer.batch_encode_plus(\n",
        "    train.text.values,\n",
        "    add_special_tokens=True,\n",
        "    return_attention_mask=True,\n",
        "    pad_to_max_length=True,\n",
        "    max_length=256,\n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "encoded_data_val = tokenizer.batch_encode_plus(\n",
        "    val.text.values,\n",
        "    add_special_tokens=True,\n",
        "    return_attention_mask=True,\n",
        "    pad_to_max_length=True,\n",
        "    max_length=256,\n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "input_ids_train = encoded_data_train['input_ids']\n",
        "attention_masks_train = encoded_data_train['attention_mask']\n",
        "labels_train = torch.tensor(train.stance.values)\n",
        "\n",
        "input_ids_val = encoded_data_val['input_ids']\n",
        "attention_masks_val = encoded_data_val['attention_mask']\n",
        "labels_val = torch.tensor(val.stance.values)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EjODfrzQWSUa",
        "outputId": "99123309-be5e-45f7-f4bf-8c5f42f70008"
      },
      "source": [
        "# Creating the tensor datasets\n",
        "\n",
        "dataset_train = TensorDataset(input_ids_train, \n",
        "                              attention_masks_train,\n",
        "                              labels_train)\n",
        "\n",
        "dataset_val = TensorDataset(input_ids_val, \n",
        "                            attention_masks_val,\n",
        "                            labels_val)\n",
        "\n",
        "\n",
        "dataset_val.tensors"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 101,  178, 1321,  ...,    0,    0,    0],\n",
              "         [ 101, 1518, 8124,  ...,    0,    0,    0],\n",
              "         [ 101,  119,  137,  ...,    0,    0,    0],\n",
              "         ...,\n",
              "         [ 101, 1165, 1152,  ...,    0,    0,    0],\n",
              "         [ 101,  137, 4795,  ...,    0,    0,    0],\n",
              "         [ 101, 5540, 1225,  ...,    0,    0,    0]]),\n",
              " tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         ...,\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
              " tensor([2, 0, 1, 1, 1, 2, 2, 1, 1, 1, 1, 2, 1, 2, 0, 2, 1, 1, 1, 1, 2, 1, 1, 2,\n",
              "         0, 2, 0, 0, 0, 0, 2, 0, 1, 1, 1, 1, 1, 1, 2, 2, 1, 0, 0, 2, 2, 2, 1, 1,\n",
              "         1, 2, 0, 2, 1, 1, 0, 1, 2, 2, 1, 0, 1, 1, 1, 2, 2, 1, 1]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 895
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TD4XgfvoWSUa"
      },
      "source": [
        "from transformers import BertForSequenceClassification "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxpY51_nWSUa"
      },
      "source": [
        "label_dict = {}\n",
        "possible_labels = train.stance.unique()\n",
        "\n",
        "for index, possible_label in enumerate(possible_labels):\n",
        "  label_dict[possible_label] = index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "370QQWsmWSUa",
        "outputId": "ecd0c112-2254-46ae-f426-88418c7dc4e9"
      },
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\n",
        "                                      'bert-large-cased-whole-word-masking', \n",
        "                                      num_labels = len(label_dict),\n",
        "                                      output_attentions = False,\n",
        "                                      output_hidden_states = False\n",
        "                                     )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-large-cased-whole-word-masking were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-cased-whole-word-masking and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aoGalNDWSUa"
      },
      "source": [
        "batch_size = 5\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "dataloader_train = DataLoader(\n",
        "    dataset_train,\n",
        "    sampler=RandomSampler(dataset_train),\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "dataloader_val = DataLoader(\n",
        "    dataset_val,\n",
        "    sampler=RandomSampler(dataset_val),\n",
        "    batch_size = 5\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKrbW3WaWSUb"
      },
      "source": [
        "from transformers import AdamW\n",
        "optimizer = AdamW(\n",
        "    model.parameters(),\n",
        "    lr = 2e-5,\n",
        "    eps = 4e-9\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JqUpJDjWSUb"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "epochs = 1\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps = len(dataloader_train)*epochs\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysBVymoWWSUb"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuHvSsMaWSUb"
      },
      "source": [
        "def f1_score_func(preds, labels):\n",
        "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return f1_score(labels_flat, preds_flat, average = 'weighted')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GkAplq5WSUb"
      },
      "source": [
        "def accuracy_per_class(preds, labels):\n",
        "    label_dict_inverse = {v: k for k, v in label_dict.items()}\n",
        "    \n",
        "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    \n",
        "    for label in np.unique(labels_flat):\n",
        "        y_preds = preds_flat[labels_flat==label]\n",
        "        y_true = labels_flat[labels_flat==label]\n",
        "        print(f'Class: {label_dict_inverse[label]}')\n",
        "        print(f'Accuracy:{len(y_preds[y_preds==label])}/{len(y_true)}\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6G_Y9nBWSUb"
      },
      "source": [
        "import random\n",
        "\n",
        "seed_val = 15\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmzx3GBvWSUb",
        "outputId": "cf905519-eaee-4397-97be-0f8f2108d6ad"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8pv2KS8WSUc"
      },
      "source": [
        "def evaluate(dataloader_val):\n",
        "\n",
        "    model.eval()\n",
        "    \n",
        "    loss_val_total = 0\n",
        "    predictions, true_vals = [], []\n",
        "    \n",
        "    for batch in tqdm(dataloader_val):\n",
        "        \n",
        "        batch = tuple(b.to(device) for b in batch)\n",
        "        \n",
        "        inputs = {'input_ids':      batch[0],\n",
        "                  'attention_mask': batch[1],\n",
        "                  'labels':         batch[2],\n",
        "                 }\n",
        "\n",
        "        with torch.no_grad():        \n",
        "            outputs = model(**inputs)\n",
        "            \n",
        "        loss = outputs[0]\n",
        "        logits = outputs[1]\n",
        "        loss_val_total += loss.item()\n",
        "\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = inputs['labels'].cpu().numpy()\n",
        "        predictions.append(logits)\n",
        "        true_vals.append(label_ids)\n",
        "    \n",
        "    loss_val_avg = loss_val_total/len(dataloader_val) \n",
        "    \n",
        "    predictions = np.concatenate(predictions, axis=0)\n",
        "    true_vals = np.concatenate(true_vals, axis=0)\n",
        "            \n",
        "    return loss_val_avg, predictions, true_vals"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165,
          "referenced_widgets": [
            "490e296a66394c8bba55ca25e17b9a3e",
            "5be5a6f061654f64bb7684bb807cae61",
            "073d1caf21e345a69931145674e30fc1",
            "a5390b7414184d36baee172cf95f60ea",
            "5c994dd8b9654d2dbee58fb25d456284",
            "d98032c8f68a443893cb84de4b670af8",
            "4c298015fc49495bb9ff9a27ada430cd",
            "f2aab80696bf4e779e7d543f8efcff63",
            "3756eb40518b4236ba2ea307594a6c55",
            "2a0ceb59ff724e939531127580e142cb",
            "e9c8de34977648a69db7137356b91ea7",
            "abc5896ebfaa4f13bb8e9a65e78fc804",
            "89d76023d318499a99b1e1803ace94db",
            "832e2eced22a4ed28e890cb518c4e72d",
            "d43a172a56f440b5bb808458fcd4c157",
            "111b03fcff9f4880b6e28abf02f52b35",
            "551ef4c546014818a225cba7266d6d3e",
            "336fb194d8a647938afed62e2f279975",
            "46fc0c328b674342a1dec938f6548f81",
            "9d40dff3c6594f8f9b435c2958112547",
            "c47cdc3f2a8743db875275df11afdba0",
            "0d722fed8b00414cb72de7cca8fc41ae",
            "46f0c4ab4b41406cb2fafc9379d048f7",
            "eecee02783514e6cbe6c90d6531e87cb"
          ]
        },
        "id": "ERKYZvlsWSUc",
        "outputId": "f7a78298-b47c-41a5-c6b2-11471258c678"
      },
      "source": [
        "from tqdm.notebook import tqdm\n",
        "\n",
        "for epoch in tqdm(range(1, 2)):\n",
        "    model.train()\n",
        "    loss_train_total = 0\n",
        "    \n",
        "    progress_bar = tqdm(dataloader_train, \n",
        "                        desc='Epoch {:1d}'.format(epoch), \n",
        "                        leave=False, \n",
        "                        disable=False)\n",
        "    \n",
        "    for batch in progress_bar:\n",
        "        model.zero_grad()\n",
        "        batch = tuple(b.to(device) for b in batch)\n",
        "        inputs = {\n",
        "            'input_ids': batch[0],\n",
        "            'attention_mask': batch[1],\n",
        "            'labels': batch[2]\n",
        "        }\n",
        "        \n",
        "        outputs = model(**inputs)\n",
        "        loss = outputs[0]\n",
        "        loss_train_total +=loss.item()\n",
        "        loss.backward()\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        \n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        \n",
        "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})     \n",
        "    \n",
        "    \n",
        "    loss_train_avg = loss_train_total/len(dataloader_train)\n",
        "    tqdm.write(f'Training loss: {loss_train_avg}')\n",
        "    \n",
        "    val_loss, predictions, true_vals = evaluate(dataloader_val)\n",
        "    val_f1 = f1_score_func(predictions, true_vals)\n",
        "    print(f'Validation loss: {val_loss}')\n",
        "    print(f'F1 Score (weighted): {val_f1}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "490e296a66394c8bba55ca25e17b9a3e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3756eb40518b4236ba2ea307594a6c55",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Epoch 1', max=120.0, style=ProgressStyle(description_widt…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\r\r\rTraining loss: 0.9626638859510421\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "551ef4c546014818a225cba7266d6d3e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=14.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Validation loss: 0.9222281788076673\n",
            "F1 Score (weighted): 0.4795588309196739\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-7HAqiLWSUc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11cd54a8-4c69-46f4-be04-e0778fa718a1"
      },
      "source": [
        "accuracy_per_class(predictions, true_vals)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class: 1\n",
            "Accuracy:8/13\n",
            "\n",
            "Class: 0\n",
            "Accuracy:29/33\n",
            "\n",
            "Class: 2\n",
            "Accuracy:1/21\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vkb1nHw8YccQ"
      },
      "source": [
        "## Hillary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcE_Bs-eYqYe"
      },
      "source": [
        "# Transforming the .txt files and creating the train dataset\n",
        "\n",
        "with open('./source/stance/hillary/train_text.txt') as train_text, open('./source/stance/hillary/train_labels.txt') as train_labels:\n",
        "  matrix = []\n",
        "  stances = pd.read_csv('./source/stance/mapping.csv')\n",
        "  for text, label in zip(train_text, train_labels):\n",
        "    stance = stances.loc[stances['Code'] == int(label), 'Stance'].item()\n",
        "    row = {}\n",
        "    row['text'] = text.rstrip()\n",
        "    row['stance'] = int(label)\n",
        "    row['target'] = stance\n",
        "    matrix.append(row)\n",
        "  train = pd.DataFrame(matrix)\n",
        "\n",
        "train.to_csv('./source/stance/hillary/train.txt', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwnmmwf0xN3I"
      },
      "source": [
        "# Transforming the .txt files and creating the test dataset\n",
        "\n",
        "with open('./source/stance/hillary/test_text.txt') as test_text, open('./source/stance/hillary/test_labels.txt') as test_labels:\n",
        "  matrix = []\n",
        "  stances = pd.read_csv('./source/stance/mapping.csv')\n",
        "  for text, label in zip(test_text, test_labels):\n",
        "    stance = stances.loc[stances['Code'] == int(label), 'Stance'].item()\n",
        "    row = {}\n",
        "    row['text'] = text.rstrip()\n",
        "    row['stance'] = int(label)\n",
        "    row['target'] = stance\n",
        "    matrix.append(row)\n",
        "  test = pd.DataFrame(matrix)\n",
        "\n",
        "test.to_csv('./source/stance/hillary/test.txt', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMuIjXWhxRgv"
      },
      "source": [
        "# Transforming the .txt files and creating the val dataset\n",
        "\n",
        "with open('./source/stance/hillary/val_text.txt') as val_text, open('./source/stance/hillary/val_labels.txt') as val_labels:\n",
        "  matrix = []\n",
        "  stances = pd.read_csv('./source/stance/mapping.csv')\n",
        "  for text, label in zip(val_text, val_labels):\n",
        "    stance = stances.loc[stances['Code'] == int(label), 'Stance'].item()\n",
        "    row = {}\n",
        "    row['text'] = text.rstrip()\n",
        "    row['stance'] = int(label)\n",
        "    row['target'] = stance\n",
        "    matrix.append(row)\n",
        "  val = pd.DataFrame(matrix)\n",
        "\n",
        "val.to_csv('./source/stance/hillary/val.txt', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MK3KSg7fV6_s"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "from torch.utils.data import TensorDataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpYm6BvOWUir",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163,
          "referenced_widgets": [
            "65e0c0b1f36c4fc69b4d983005cc5495",
            "b1c8eb716d584b38b17e41417feb2fcc",
            "dafc968fcdf14276b95dcfa60630e7a5",
            "5d7028cd1112450b952c665be35f04d5",
            "5c7c159aa8104556ac996bffe476f90e",
            "2261830383534cbc8a702207a7c254c3",
            "20a3a8289e6043d0b45f5862acfd5977",
            "34015516afd448b3b1ad37b526656f51",
            "c855eb7e0d9649be818a68ea4e81e81a",
            "48d3f5b845eb4ea08ff03d71f46796cb",
            "e9906c99cdfe4464add1bb6cac0fb045",
            "915ca0f1a66547e1913534343cb6b318",
            "0f19a402f24946f2ac36dfaf1d385fda",
            "9aa6f054d15d4d12bf86e23bae0be18c",
            "be6df7abeb544c5b8000f8bd6ee16173",
            "85e02359b2eb403ba530cbb72747d5b3",
            "2cbc6b4c98c44e2997632ec38063be28",
            "1c0ad95b77a241348f3ad3b13ae29845",
            "bf69f01b1425413db0b9c684ca1504e8",
            "87d00c4e0666400fa3d057a9acf1fecb",
            "641097f9a7c74c238ec338f0e5008217",
            "3856d16acfbc46019e317081d8e6b312",
            "28a66b19ca83422596a78b51ea4c2ede",
            "7fb25c05ee5347f6a87d9da8fc3d5892"
          ]
        },
        "outputId": "825e91a1-2a35-4366-a719-a32da3ee1858"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\n",
        "    'bert-large-cased-whole-word-masking',\n",
        "    do_lower_case = False\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "65e0c0b1f36c4fc69b4d983005cc5495",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=213450.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c855eb7e0d9649be818a68ea4e81e81a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=29.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2cbc6b4c98c44e2997632ec38063be28",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=435797.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChHfGeqoWUir",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d66eb3c-dc0a-46a9-d510-5ba4ef70c6c9"
      },
      "source": [
        "import torch\n",
        "encoded_data_train = tokenizer.batch_encode_plus(\n",
        "    train.text.values,\n",
        "    add_special_tokens=True,\n",
        "    return_attention_mask=True,\n",
        "    pad_to_max_length=True,\n",
        "    max_length=256,\n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "encoded_data_val = tokenizer.batch_encode_plus(\n",
        "    val.text.values,\n",
        "    add_special_tokens=True,\n",
        "    return_attention_mask=True,\n",
        "    pad_to_max_length=True,\n",
        "    max_length=256,\n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "input_ids_train = encoded_data_train['input_ids']\n",
        "attention_masks_train = encoded_data_train['attention_mask']\n",
        "labels_train = torch.tensor(train.stance.values)\n",
        "\n",
        "input_ids_val = encoded_data_val['input_ids']\n",
        "attention_masks_val = encoded_data_val['attention_mask']\n",
        "labels_val = torch.tensor(val.stance.values)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vRSxf5AWUis",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31197bc5-6ac1-4fb5-daf1-c496b13aa219"
      },
      "source": [
        "# Creating the tensor datasets\n",
        "\n",
        "dataset_train = TensorDataset(input_ids_train, \n",
        "                              attention_masks_train,\n",
        "                              labels_train)\n",
        "\n",
        "dataset_val = TensorDataset(input_ids_val, \n",
        "                            attention_masks_val,\n",
        "                            labels_val)\n",
        "\n",
        "\n",
        "dataset_val.tensors"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[  101,   143, 20356,  ...,     0,     0,     0],\n",
              "         [  101,  7102,  1612,  ...,     0,     0,     0],\n",
              "         [  101,  1135,   112,  ...,     0,     0,     0],\n",
              "         ...,\n",
              "         [  101,  6466,  1242,  ...,     0,     0,     0],\n",
              "         [  101,  1130,  1692,  ...,     0,     0,     0],\n",
              "         [  101,   137,  4795,  ...,     0,     0,     0]]),\n",
              " tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         ...,\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
              " tensor([2, 1, 1, 1, 1, 1, 2, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 2, 1, 2, 1, 2, 0, 0,\n",
              "         1, 2, 1, 1, 0, 1, 1, 2, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 2, 1, 2, 1, 1,\n",
              "         2, 2, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 2, 0, 1]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMVrLgZtWUis"
      },
      "source": [
        "from transformers import BertForSequenceClassification "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tk0tSzjsWUis"
      },
      "source": [
        "label_dict = {}\n",
        "possible_labels = train.stance.unique()\n",
        "\n",
        "for index, possible_label in enumerate(possible_labels):\n",
        "  label_dict[possible_label] = index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXr6h4uCWUis",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218,
          "referenced_widgets": [
            "8687ebe478cb4edb9acdf76f609e7785",
            "ea9970ed44cd4aeda33a994c666933ef",
            "d2a3b6a193cd418cb4ffd55629f4753f",
            "2f5d66bc86fd4841b09d81bbd49f4b2f",
            "020f9079f4d54df9bfc32661630893ba",
            "ec73ee4118e442ecb6644a193ab21343",
            "82a81eeb43f449a983510ea0ee8c8d27",
            "83828dafd55f43f9a93d92170811b837",
            "da422cdb85b24df8b518f51c5bfa8ce2",
            "103f2ab841d743089c846d48a0f5a3f6",
            "2c8046bbd9aa40428f2ef78ab8abedcb",
            "c94c3f7aba9540ec862bba9a519059e2",
            "64fb38cf13e34a6db81900f682b674c8",
            "4b4371bddc4b437fa8be2ba57fc8d7b7",
            "fa0b22085fa14663bea573c8f1878863",
            "83595da8874a4821ac036f9ed4f2b53c"
          ]
        },
        "outputId": "22cb9e6d-00b6-47fe-95a1-69e9886eecfb"
      },
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\n",
        "                                      'bert-large-cased-whole-word-masking-finetuned-squad', \n",
        "                                      num_labels = len(label_dict),\n",
        "                                      output_attentions = False,\n",
        "                                      output_hidden_states = False\n",
        "                                     )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8687ebe478cb4edb9acdf76f609e7785",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=634.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "da422cdb85b24df8b518f51c5bfa8ce2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1334424802.0, style=ProgressStyle(descr…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-large-cased-whole-word-masking-finetuned-squad were not used when initializing BertForSequenceClassification: ['qa_outputs.weight', 'qa_outputs.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-cased-whole-word-masking-finetuned-squad and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdBjzW-aWUis"
      },
      "source": [
        "batch_size = 5\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "dataloader_train = DataLoader(\n",
        "    dataset_train,\n",
        "    sampler=RandomSampler(dataset_train),\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "dataloader_val = DataLoader(\n",
        "    dataset_val,\n",
        "    sampler=RandomSampler(dataset_val),\n",
        "    batch_size=5\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXSAaRL0WUit"
      },
      "source": [
        "from transformers import AdamW\n",
        "optimizer = AdamW(\n",
        "    model.parameters(),\n",
        "    lr = 3e-5,\n",
        "    eps = 1e-9\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dalwpyF4WUit"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "epochs = 2\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps = len(dataloader_train)*epochs\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwC78JT2WUit"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BANLPWXLWUit"
      },
      "source": [
        "def f1_score_func(preds, labels):\n",
        "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return f1_score(labels_flat, preds_flat, average = 'weighted')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKT48ZQlWUit"
      },
      "source": [
        "def accuracy_per_class(preds, labels):\n",
        "    label_dict_inverse = {v: k for k, v in label_dict.items()}\n",
        "    \n",
        "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    \n",
        "    for label in np.unique(labels_flat):\n",
        "        y_preds = preds_flat[labels_flat==label]\n",
        "        y_true = labels_flat[labels_flat==label]\n",
        "        print(f'Class: {label_dict_inverse[label]}')\n",
        "        print(f'Accuracy:{len(y_preds[y_preds==label])}/{len(y_true)}\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CS0ew56sWUit"
      },
      "source": [
        "import random\n",
        "\n",
        "seed_val = 10\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SMn7gPMWUit",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "539bd9bb-a285-4e48-a501-a15307fd70e8"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWZXV4KCWUit"
      },
      "source": [
        "def evaluate(dataloader_val):\n",
        "\n",
        "    model.eval()\n",
        "    \n",
        "    loss_val_total = 0\n",
        "    predictions, true_vals = [], []\n",
        "    \n",
        "    for batch in tqdm(dataloader_val):\n",
        "        \n",
        "        batch = tuple(b.to(device) for b in batch)\n",
        "        \n",
        "        inputs = {'input_ids':      batch[0],\n",
        "                  'attention_mask': batch[1],\n",
        "                  'labels':         batch[2],\n",
        "                 }\n",
        "\n",
        "        with torch.no_grad():        \n",
        "            outputs = model(**inputs)\n",
        "            \n",
        "        loss = outputs[0]\n",
        "        logits = outputs[1]\n",
        "        loss_val_total += loss.item()\n",
        "\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = inputs['labels'].cpu().numpy()\n",
        "        predictions.append(logits)\n",
        "        true_vals.append(label_ids)\n",
        "    \n",
        "    loss_val_avg = loss_val_total/len(dataloader_val) \n",
        "    \n",
        "    predictions = np.concatenate(predictions, axis=0)\n",
        "    true_vals = np.concatenate(true_vals, axis=0)\n",
        "            \n",
        "    return loss_val_avg, predictions, true_vals"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pU1FZblkWUiu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165,
          "referenced_widgets": [
            "b4bd3294ca2240f0998e09dd68118e71",
            "361cf508f3fa4b4c91a267df5032e850",
            "1996395748c84080b44baa6a2f2c2d74",
            "a879d6cdb06f4e0b931d45676fa0516e",
            "ea86de3d1eb74302b6f38f3b76f2a13d",
            "7b0cbcd24e1b47f38b2cc194f1f03be0",
            "7fed31618e174e26a69c1b6accd6bdfd",
            "e3a7f04bc36c472f8421518f461aab25",
            "0f31d2fb5802490089698c231bd5e7ff",
            "7ac8ca3a321a4ae28d6f997454de989e",
            "779b9c44934b470fa2af7b4f374eb33e",
            "b80712b33a6b4050a716447c2ddff33d",
            "7d171dc4a34c4d5eab37845ea987a8a4",
            "43ee8826e213453187cc0f5a2ddbb4ce",
            "cd68d7585f7b435b8400f8b6d22a5d69",
            "aa09e2b85049487ca1fc7adf28cbe6b6",
            "f3564028631447918069a5478054ff92",
            "b77a26c16bfc43f6ba2701852f0c0714",
            "6dd7ae8f4a7d4609a00227b19055f6a2",
            "f031933d515d4505bb1b1d10e5a64485",
            "e1d0919bbfe94cfa9a0ab321b0c4a039",
            "81d06efe8cdb4ac4b6fbaf3aa4191ebb",
            "32496eaa154642de8df5771e8fc6091c",
            "786f78e1d12447a585b24aa9210037e1"
          ]
        },
        "outputId": "835b001d-a5a0-402b-cc51-00985ba91f57"
      },
      "source": [
        "from tqdm.notebook import tqdm\n",
        "\n",
        "for epoch in tqdm(range(1, 2)):\n",
        "    model.train()\n",
        "    loss_train_total = 0\n",
        "    \n",
        "    progress_bar = tqdm(dataloader_train, \n",
        "                        desc='Epoch {:1d}'.format(epoch), \n",
        "                        leave=False, \n",
        "                        disable=False)\n",
        "    \n",
        "    for batch in progress_bar:\n",
        "        model.zero_grad()\n",
        "        batch = tuple(b.to(device) for b in batch)\n",
        "        inputs = {\n",
        "            'input_ids': batch[0],\n",
        "            'attention_mask': batch[1],\n",
        "            'labels': batch[2]\n",
        "        }\n",
        "        \n",
        "        outputs = model(**inputs)\n",
        "        loss = outputs[0]\n",
        "        loss_train_total +=loss.item()\n",
        "        loss.backward()\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        \n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        \n",
        "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})     \n",
        "    \n",
        "    \n",
        "    loss_train_avg = loss_train_total/len(dataloader_train)\n",
        "    tqdm.write(f'Training loss: {loss_train_avg}')\n",
        "    \n",
        "    val_loss, predictions, true_vals = evaluate(dataloader_val)\n",
        "    val_f1 = f1_score_func(predictions, true_vals)\n",
        "    print(f'Validation loss: {val_loss}')\n",
        "    print(f'F1 Score (weighted): {val_f1}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b4bd3294ca2240f0998e09dd68118e71",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0f31d2fb5802490089698c231bd5e7ff",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Epoch 1', max=124.0, style=ProgressStyle(description_widt…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\rTraining loss: 0.9761226097902944\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f3564028631447918069a5478054ff92",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=14.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Validation loss: 0.8319676348141262\n",
            "F1 Score (weighted): 0.5160348887341227\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aftiBE4OWUiu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "694a155b-94e4-4c8d-8e2d-3a1597ca128b"
      },
      "source": [
        "accuracy_per_class(predictions, true_vals)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class: 1\n",
            "Accuracy:17/18\n",
            "\n",
            "Class: 0\n",
            "Accuracy:22/39\n",
            "\n",
            "Class: 2\n",
            "Accuracy:0/12\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yuN8vXFmlVC"
      },
      "source": [
        ""
      ]
    }
  ]
}